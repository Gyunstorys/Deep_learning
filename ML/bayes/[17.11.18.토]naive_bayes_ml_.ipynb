{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나이브 베이즈 Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 베이즈 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.safaribooksonline.com/library/view/doing-data-science/9781449363871/images/dnds_0403.png\" align=\"center\" height=\"600\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ $p(sick \\ | \\ plus)= \\ \\frac{p(plus \\ | \\ sick) \\ p(sick)}{p(plus)} \\ = \\ \\frac{0.99*0.01}{0.99*0.01+0.01*0.99} \\ = \\ 0.5 = 50\\% \\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "혹은 spam mail 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 한 단어만 확인\n",
    "+ $p(spam \\ | \\ word)= \\ \\frac{p(word \\ | \\ spam) \\ p(spam)}{p(word)}$\n",
    "+ $p(word) \\ = \\ p(word \\ |\\ spam)p(spam) \\ + \\ p(word \\ | \\ ham)p(ham)$  ,,,,,,where  $p(ham)=1-p(spam)$\n",
    "+ $P(spam \\ | \\ word) \\ = \\ [P(word \\ | \\ spam)P(spam)] \\ / \\ [P(word \\ | \\ spam)P(spam) \\ + \\ P(word \\ | \\  ham)P(ham)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 나이브 베이즈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 앞의 spam mail 예시를 n 단어로 확장 $w_1, \\ w_2, \\ ... \\ w_n$\n",
    "+ 나이브 베이즈 : '메시지가 스팸이냐 아니냐가 주어졌다는 조건 하에 각 단어의 존재는 서로 조건부 독립이다.'\n",
    "+ 나이즈(단순한) 베이즈 : 말이 안되는 가정, 극단적인 가정.\n",
    "+ 어떤 스팸 메세지에 meeting 이라는 단어를 포함한다는 점이 같은 메시지가 coupon 이라는 단어를 포함하고 있는지 판단하는데 도움을 주지 않는다.  \n",
    "  \n",
    "+ $P(X_1=x_1, \\ ... \\ X_n=x_n \\ | \\ S) \\ = \\ P(X_1=x_1 \\ | \\ S) \\times \\ ... \\ \\times P(X_n=x_n \\ | \\ S)$ \n",
    "+ $X_i$ : 단어 $w_i$ 가 메세지에 포함되는 경우의 수 \n",
    "+ $P(X_i \\ | \\ S) \\ , \\ P(X_i \\ | \\ H)$ : 스팸메일에 단어 $w_i$가 포함될 확률, 스팸메일이 아닌 메일에 포함될 확률  \n",
    "  \n",
    "+ 말이 안되는 가정으로 만들어진 모델이지만 성능이 뛰어나다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ $P(S \\ | \\ X=x) \\ = \\ P(X=x \\ | \\ S) \\ / \\ [P(X=x \\ | \\ S) \\ + \\ P(X=x \\ | \\  ham)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현 & 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 코드 : https://github.com/Insight-book/data-science-from-scratch/blob/master/notebook/ch13_naive_bayes.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 다운로드 : http://csmining.org/index.php/spam-assassin-datasets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import math, random, re, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_subject_data(path):\n",
    "    data = []\n",
    "\n",
    "    # 맨 앞의 \"Subject:\" 를 지우는 정규식 \n",
    "    subject_regex = re.compile(r\"^Subject:\\s+\")\n",
    "\n",
    "    # glob.glob은 주어진 경로에 해당하는 모든 파일 이름 반환\n",
    "    for fn in glob.glob(path):\n",
    "        is_spam = \"ham\" not in fn\n",
    "\n",
    "        with open(fn,'r',encoding='ISO-8859-1') as file:\n",
    "            for line in file:\n",
    "                if line.startswith(\"Subject:\"):\n",
    "                    subject = subject_regex.sub(\"\", line).strip()\n",
    "                    data.append((subject, is_spam))\n",
    "                    # 폴더에서 하나의 파일의 제목을 subject에 그 파일의 스팸 여부를 is_spamn에 저장\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Re: New Sequences Window', False),\n",
       " ('[zzzzteana] RE: Alexander', False),\n",
       " ('[zzzzteana] Moscow bomber', False),\n",
       " (\"[IRR] Klez: The Virus That  Won't Die\", False),\n",
       " ('Re: Insert signature', False)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#위에 주제 추출 함수에 파일경로를 입력, 해당 경로의 모든 파일 data에 담기\n",
    "data = get_subject_data(r\"C:/Users/Administrator/Desktop/ML_bayesian/naive_spam/*/*\")\n",
    "data[:5]\n",
    "\n",
    "#(제목, spam여부) ---현재는 모두 false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train, test 비율로 나누기\n",
    "def split_data(data, prob):\n",
    "    \"\"\"split data into fractions [prob, 1 - prob]\"\"\"\n",
    "    results = [], []\n",
    "    for row in data:\n",
    "        results[0 if random.random() < prob else 1].append(row)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('[zzzzteana] Moscow bomber', False),\n",
       "  (\"[IRR] Klez: The Virus That  Won't Die\", False),\n",
       "  ('Re: Insert signature', False),\n",
       "  ('Re: [zzzzteana] Nothing like mama used to make', False),\n",
       "  ('[zzzzteana] Playboy wants to go out with a bang', False)],\n",
       " [('Re: New Sequences Window', False),\n",
       "  ('[zzzzteana] RE: Alexander', False),\n",
       "  ('Re: [zzzzteana] Nothing like mama used to make', False),\n",
       "  ('Re: [zzzzteana] Nothing like mama used to make', False),\n",
       "  ('[SAtalk] SA CGI Configurator Scripts', False)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train, test 비율 3 : 1 \n",
    "train_data, test_data = split_data(data, 0.75)\n",
    "train_data[:5], test_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2590, 833)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#string을 단어단위로 끊기\n",
    "def tokenize(message):\n",
    "    message = message.lower()                       # 소문자 변환\n",
    "    all_words = re.findall(\"[a-z0-9']+\", message)   # 단어 추출\n",
    "    return set(all_words)                           # set함수 : 중복제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bomber', 'moscow', 'zzzzteana'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('[zzzzteana] Moscow bomber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'die', 'irr', 'klez', 'that', 'the', 'virus', \"won't\"}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(\"[IRR] Klez: The Virus That  Won't Die\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'counts', 'into', 'list', 'of', 'the', 'triplets', 'turn', 'word'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize함수 예시\n",
    "tokenize(\"turn the word_counts into a list of triplets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#단어 횟수 반환\n",
    "def count_words(training_set):\n",
    "    \"\"\"training set consists of pairs (message, is_spam)\"\"\"\n",
    "    counts = defaultdict(lambda: [0, 0])\n",
    "    for message, is_spam in training_set:\n",
    "        for word in tokenize(message):\n",
    "            counts[word][0 if is_spam else 1] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[zzzzteana] Moscow bomber', False),\n",
       " (\"[IRR] Klez: The Virus That  Won't Die\", False),\n",
       " ('Re: Insert signature', False),\n",
       " ('Re: [zzzzteana] Nothing like mama used to make', False),\n",
       " ('[zzzzteana] Playboy wants to go out with a bang', False)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.count_words.<locals>.<lambda>>,\n",
       "            {'a': [0, 1],\n",
       "             'bang': [0, 1],\n",
       "             'bomber': [0, 1],\n",
       "             'die': [0, 1],\n",
       "             'go': [0, 1],\n",
       "             'insert': [0, 1],\n",
       "             'irr': [0, 1],\n",
       "             'klez': [0, 1],\n",
       "             'like': [0, 1],\n",
       "             'make': [0, 1],\n",
       "             'mama': [0, 1],\n",
       "             'moscow': [0, 1],\n",
       "             'nothing': [0, 1],\n",
       "             'out': [0, 1],\n",
       "             'playboy': [0, 1],\n",
       "             're': [0, 2],\n",
       "             'signature': [0, 1],\n",
       "             'that': [0, 1],\n",
       "             'the': [0, 1],\n",
       "             'to': [0, 2],\n",
       "             'used': [0, 1],\n",
       "             'virus': [0, 1],\n",
       "             'wants': [0, 1],\n",
       "             'with': [0, 1],\n",
       "             \"won't\": [0, 1],\n",
       "             'zzzzteana': [0, 3]})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 딕셔너리 .. key : 단어 , [스팸메시지에서 나온 빈도수, 햄메세지에서 나온 빈도수]\n",
    "count_words(train_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 평활화(smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 만약 주어진 train set에 '데이터'라는 단어는 스팸이 아닌 메세지에만 포함된다라고 가정한다면  \n",
    "+ $P('data' \\ | \\ Spam)=0$  \n",
    "+ 이 경우 나이브 베이즈 분류기는 '데이터'라는 단어가 들어간 메시지를 항상 스팸메시지가 아니라고 예측  \n",
    "+ '만남 주선 쿠폰에 대한 데이터' 라는 메시지를 스팸이 아니라고 예측하게 됨. \n",
    "+ 이러한 문제를 해결하기 위해 일종의 평활화가 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ smoothing을 위해 가짜 빈도수 (psedocount) k 를 결정하고 스팸 메세지에서 i 번째 단어가 나올 확률을 아래와 같이 추정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ $P(X_i \\ | \\ Spam) \\ = \\ (k \\ + \\ number \\ of \\ spam \\ massage \\ including \\ w_i) \\ / \\ (2k \\ + \\ number \\ of \\  spam \\ massage)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 예를 들어 '데이터'라는 단어는 98개의 스팸문서에서 단 한번도 나타나지 않았음\n",
    "+ 그러나 k가 1이라면 P('데이터|S)를 1/100 = 0.01 로 계산할 수 있음\n",
    "+ 즉, '데이터'라는 단어가 포함된 메세지가 스팸메세지일 확률을 0이 아닌 다른 확률값으로 설정할 수 있게 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#평활화\n",
    "#단어의 빈도수를 [단어,p(w|spam),p(w|ham)]의 형태로 변환\n",
    "def word_probabilities(counts, total_spams, total_non_spams, k=0.5):\n",
    "    \"\"\"turn the word_counts into a list of triplets\n",
    "    w, p(w | spam) and p(w | ~spam)\"\"\"\n",
    "    return [(w,\n",
    "             (spam + k) / (total_spams + 2 * k),\n",
    "             (non_spam + k) / (total_non_spams + 2 * k))\n",
    "             for w, (spam, non_spam) in counts.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('outstanding', 0.004087193460490463, -0.0013736263736263737),\n",
       " ('pl', 0.0013623978201634877, -0.006868131868131868),\n",
       " ('slouch', 0.0013623978201634877, -0.004120879120879121),\n",
       " ('nr', 0.004087193460490463, -0.0013736263736263737),\n",
       " ('fire', 0.0013623978201634877, -0.009615384615384616)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#평활화 결과\n",
    "word_probabilities(\n",
    "    count_words(train_data), len(\n",
    "        [is_spam for message, is_spam in train_data if is_spam]), \n",
    "    1-len([is_spam for message, is_spam in train_data if is_spam]))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spam_probability(word_probs, message):\n",
    "    message_words = tokenize(message)\n",
    "    log_prob_if_spam = log_prob_if_not_spam = 0.0\n",
    "\n",
    "    for word, prob_if_spam, prob_if_not_spam in word_probs:\n",
    "\n",
    "        # for each word in the message,\n",
    "        # add the log probability of seeing it\n",
    "        if word in message_words:\n",
    "            log_prob_if_spam += math.log(prob_if_spam)\n",
    "            log_prob_if_not_spam += math.log(prob_if_not_spam)\n",
    "\n",
    "        # for each word that's not in the message\n",
    "        # add the log probability of _not_ seeing it\n",
    "        else:\n",
    "            log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
    "            log_prob_if_not_spam += math.log(1.0 - prob_if_not_spam)\n",
    "\n",
    "    prob_if_spam = math.exp(log_prob_if_spam)\n",
    "    prob_if_not_spam = math.exp(log_prob_if_not_spam)\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_not_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p_spam_given_word(word_prob):\n",
    "    #베이즈 정리 : p(spam|메세지가 해당 단어를 포함)을 계산\n",
    "    #word_prob은 word_probabilities에서 계산된 결과\n",
    "    word, prob_if_spam, prob_if_not_spam = word_prob\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_not_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#나이브 베이즈 분류기 클래스 생성\n",
    "class NaiveBayesClassifier:\n",
    "    #생성자 --> 초기화\n",
    "    def __init__(self, k=0.5):\n",
    "        self.k = k\n",
    "        self.word_probs = []\n",
    "\n",
    "    def train(self, training_set):\n",
    "        #스팸 메시지와 스팸이 아닌 메시지의 개수 세기\n",
    "        # count spam and non-spam messages\n",
    "        num_spams = len([is_spam\n",
    "                         for message, is_spam in training_set\n",
    "                         if is_spam])\n",
    "        num_non_spams = len(training_set) - num_spams\n",
    "        \n",
    "        #지금까지 만든 함수에 train set 적용\n",
    "        # run training data through our \"pipeline\"\n",
    "        #단어 횟수 반환\n",
    "        word_counts = count_words(training_set)\n",
    "        #평활화 함수\n",
    "        self.word_probs = word_probabilities(word_counts,\n",
    "                                             num_spams,\n",
    "                                             num_non_spams,\n",
    "                                             self.k)\n",
    "\n",
    "    def classify(self, message):\n",
    "        return spam_probability(self.word_probs, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_test_model(path):\n",
    "\n",
    "    data = get_subject_data(path)\n",
    "    random.seed(0)      # just so you get the same answers as me\n",
    "    train_data, test_data = split_data(data, 0.75)\n",
    "\n",
    "    classifier = NaiveBayesClassifier()\n",
    "    classifier.train(train_data)\n",
    "    \n",
    "    #[제목, 실제 스팸 여부, 예측 스팸 확률]\n",
    "    classified = [(subject, is_spam, classifier.classify(subject))\n",
    "              for subject, is_spam in test_data]\n",
    "    \n",
    "    #메세지가 스팸일 확률이 0.5 보다 크면 스팸!\n",
    "    counts = Counter((is_spam, spam_probability > 0.5) # (actual, predicted)\n",
    "                     for _, is_spam, spam_probability in classified)\n",
    "\n",
    "    print(counts)\n",
    "    \n",
    "    #스팸일 확률을 오름차순 정렬\n",
    "    classified.sort(key=lambda row: row[2])\n",
    "    \n",
    "    #스팸이 아닌 메시지 중에서 스팸일 확률이 가장 높은 메시지\n",
    "    spammiest_hams = list(filter(lambda row: not row[1], classified))[-5:]\n",
    "    \n",
    "    #스팸 중에서 스팸일 확률이 가장 낮은 메시지\n",
    "    hammiest_spams = list(filter(lambda row: row[1], classified))[:5]\n",
    "\n",
    "    print(\"spammiest_hams\", spammiest_hams)\n",
    "    print(\"hammiest_spams\", hammiest_spams)\n",
    "\n",
    "    words = sorted(classifier.word_probs, key=p_spam_given_word)\n",
    "\n",
    "    spammiest_words = words[-5:]\n",
    "    hammiest_words = words[:5]\n",
    "\n",
    "    print(\"spammiest_words\", spammiest_words)\n",
    "    print(\"hammiest_words\", hammiest_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({(False, False): 704, (True, True): 101, (True, False): 38, (False, True): 33})\n",
      "spammiest_hams [('Attn programmers: support offered [FLOSS-Sarai Initiative]', False, 0.975612960514211), ('2000+ year old Greek computer reinterpreted', False, 0.9835355008104786), ('What to look for in your next smart phone (Tech Update)', False, 0.9898719206903309), ('[ILUG-Social] Re: Important - reenactor insurance needed', False, 0.9995349057803384), ('[ILUG-Social] Re: Important - reenactor insurance needed', False, 0.9995349057803384)]\n",
      "hammiest_spams [('Re: girls', True, 0.0009525186158414364), ('Introducing Chase Platinum for Students with a 0% Introductory APR', True, 0.0012566691211088627), ('.Message report from your contact page....//ytu855 rkq', True, 0.0015109358288608922), ('Testing a system, please delete', True, 0.0026920538836805305), ('Never pay for the goodz again (8SimUgQ)', True, 0.005911623221926722)]\n",
      "spammiest_words [('year', 0.028767123287671233, 0.00022893772893772894), ('sale', 0.031506849315068496, 0.00022893772893772894), ('rates', 0.031506849315068496, 0.00022893772893772894), ('systemworks', 0.036986301369863014, 0.00022893772893772894), ('money', 0.03972602739726028, 0.00022893772893772894)]\n",
      "hammiest_words [('spambayes', 0.0013698630136986301, 0.04601648351648352), ('users', 0.0013698630136986301, 0.036401098901098904), ('razor', 0.0013698630136986301, 0.030906593406593408), ('zzzzteana', 0.0013698630136986301, 0.029075091575091576), ('sadev', 0.0013698630136986301, 0.026785714285714284)]\n"
     ]
    }
   ],
   "source": [
    "#실행\n",
    "if __name__ == \"__main__\":\n",
    "    #train_and_test_model(r\"c:\\spam\\*\\*\")\n",
    "    train_and_test_model(r\"C:/Users/Administrator/Desktop/ML_bayesian/naive_spam/*/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
