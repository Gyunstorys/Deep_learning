{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YBIGTA 10기 노혜미 박승리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. RNN with long sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어를 벡터화시키는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 'if you want you'\n",
    "idx2char = list(set(sample)) # index -> char(고유값)\n",
    "char2idx = {c : i for i, c in enumerate(idx2char)} # char -> index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hyper parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_size = len(char2idx) # RNN input size(one hot vector size)\n",
    "rnn_hidden_size = len(char2idx) # RNN output size(one hot vector size) \n",
    "num_classes = len(char2idx) # final output size\n",
    "batch_size = 1 # one sample data(one batch)\n",
    "sequence_length = len(sample) - 1 # X_data, Y_label에 사용되는 char의 length는 실제 길이 - 1\n",
    "\n",
    "sample_idx = [char2idx[c] for c in sample] # sample의 character를 vector화 하여 list에 넣는다.\n",
    "x_data = [sample_idx[:-1]] # X data sample (0 ~ n-1) ex) 'if you want you' : if you want yo\n",
    "y_data = [sample_idx[1:]] # Y data sample (1 ~ n) ex) 'if you want you' : f you want you\n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, sequence_length]) # X data\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length]) # Y label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 벡터화된 단어를 one hot vector로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_one_hot = tf.one_hot(X, num_classes) # 자동으로 벡터를 one_hot으로 변환시켜준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_hidden_size, state_is_tuple=True)\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "with tf.variable_scope('first'):\n",
    "    outputs, _states = tf.nn.dynamic_rnn(cell, X_one_hot, initial_state=initial_state, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight, Loss, Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.ones([batch_size, sequence_length]) # [1, sequence_length]\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits = outputs, targets = Y, weights = weights) # sequence data\n",
    "loss = tf.reduce_mean(sequence_loss) # sequence loss -> 실수형\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "prediction = tf.argmax(outputs, axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss : 2.33074 Prediction : f      t u    \n",
      "10 loss : 1.56128 Prediction : f you wwn  you\n",
      "20 loss : 1.23079 Prediction : f you want you\n",
      "30 loss : 1.11762 Prediction : f you want you\n",
      "40 loss : 1.07443 Prediction : f you want you\n",
      "50 loss : 1.04878 Prediction : f you want you\n",
      "60 loss : 1.03247 Prediction : f you want you\n",
      "70 loss : 1.0262 Prediction : f you want you\n",
      "80 loss : 1.02168 Prediction : f you want you\n",
      "90 loss : 1.01807 Prediction : f you want you\n",
      "100 loss : 1.01144 Prediction : f you want you\n",
      "110 loss : 1.00835 Prediction : f you want you\n",
      "120 loss : 1.0066 Prediction : f you want you\n",
      "130 loss : 1.00514 Prediction : f you want you\n",
      "140 loss : 1.0043 Prediction : f you want you\n",
      "150 loss : 1.00357 Prediction : f you want you\n",
      "160 loss : 1.00282 Prediction : f you want you\n",
      "170 loss : 1.00208 Prediction : f you want you\n",
      "180 loss : 1.00163 Prediction : f you want you\n",
      "190 loss : 1.0013 Prediction : f you want you\n",
      "200 loss : 1.00104 Prediction : f you want you\n",
      "210 loss : 1.00083 Prediction : f you want you\n",
      "220 loss : 1.00064 Prediction : f you want you\n",
      "230 loss : 1.00047 Prediction : f you want you\n",
      "240 loss : 1.00033 Prediction : f you want you\n",
      "250 loss : 1.0002 Prediction : f you want you\n",
      "260 loss : 1.00008 Prediction : f you want you\n",
      "270 loss : 0.999968 Prediction : f you want you\n",
      "280 loss : 0.999865 Prediction : f you want you\n",
      "290 loss : 0.999764 Prediction : f you want you\n",
      "300 loss : 0.999656 Prediction : f you want you\n",
      "310 loss : 0.999515 Prediction : f you want you\n",
      "320 loss : 0.999251 Prediction : f you want you\n",
      "330 loss : 0.998859 Prediction : f you want you\n",
      "340 loss : 0.998671 Prediction : f you want you\n",
      "350 loss : 0.998582 Prediction : f you want you\n",
      "360 loss : 0.998517 Prediction : f you want you\n",
      "370 loss : 0.998462 Prediction : f you want you\n",
      "380 loss : 0.998414 Prediction : f you want you\n",
      "390 loss : 0.998369 Prediction : f you want you\n",
      "400 loss : 0.998328 Prediction : f you want you\n",
      "410 loss : 0.998289 Prediction : f you want you\n",
      "420 loss : 0.998253 Prediction : f you want you\n",
      "430 loss : 0.99822 Prediction : f you want you\n",
      "440 loss : 0.998188 Prediction : f you want you\n",
      "450 loss : 0.998158 Prediction : f you want you\n",
      "460 loss : 0.99813 Prediction : f you want you\n",
      "470 loss : 0.998103 Prediction : f you want you\n",
      "480 loss : 0.998078 Prediction : f you want you\n",
      "490 loss : 0.998054 Prediction : f you want you\n",
      "500 loss : 0.998032 Prediction : f you want you\n",
      "510 loss : 0.99801 Prediction : f you want you\n",
      "520 loss : 0.997989 Prediction : f you want you\n",
      "530 loss : 0.99797 Prediction : f you want you\n",
      "540 loss : 0.997951 Prediction : f you want you\n",
      "550 loss : 0.997933 Prediction : f you want you\n",
      "560 loss : 0.997916 Prediction : f you want you\n",
      "570 loss : 0.9979 Prediction : f you want you\n",
      "580 loss : 0.997884 Prediction : f you want you\n",
      "590 loss : 0.997869 Prediction : f you want you\n",
      "600 loss : 0.997855 Prediction : f you want you\n",
      "610 loss : 0.997841 Prediction : f you want you\n",
      "620 loss : 0.997828 Prediction : f you want you\n",
      "630 loss : 0.997815 Prediction : f you want you\n",
      "640 loss : 0.997803 Prediction : f you want you\n",
      "650 loss : 0.997791 Prediction : f you want you\n",
      "660 loss : 0.99778 Prediction : f you want you\n",
      "670 loss : 0.997769 Prediction : f you want you\n",
      "680 loss : 0.997758 Prediction : f you want you\n",
      "690 loss : 0.997748 Prediction : f you want you\n",
      "700 loss : 0.997738 Prediction : f you want you\n",
      "710 loss : 0.997729 Prediction : f you want you\n",
      "720 loss : 0.99772 Prediction : f you want you\n",
      "730 loss : 0.997711 Prediction : f you want you\n",
      "740 loss : 0.997702 Prediction : f you want you\n",
      "750 loss : 0.997694 Prediction : f you want you\n",
      "760 loss : 0.997686 Prediction : f you want you\n",
      "770 loss : 0.997678 Prediction : f you want you\n",
      "780 loss : 0.997671 Prediction : f you want you\n",
      "790 loss : 0.997663 Prediction : f you want you\n",
      "800 loss : 0.997656 Prediction : f you want you\n",
      "810 loss : 0.997649 Prediction : f you want you\n",
      "820 loss : 0.997643 Prediction : f you want you\n",
      "830 loss : 0.997636 Prediction : f you want you\n",
      "840 loss : 0.99763 Prediction : f you want you\n",
      "850 loss : 0.997624 Prediction : f you want you\n",
      "860 loss : 0.997618 Prediction : f you want you\n",
      "870 loss : 0.997612 Prediction : f you want you\n",
      "880 loss : 0.997607 Prediction : f you want you\n",
      "890 loss : 0.997601 Prediction : f you want you\n",
      "900 loss : 0.997596 Prediction : f you want you\n",
      "910 loss : 0.997591 Prediction : f you want you\n",
      "920 loss : 0.997586 Prediction : f you want you\n",
      "930 loss : 0.997581 Prediction : f you want you\n",
      "940 loss : 0.997576 Prediction : f you want you\n",
      "950 loss : 0.997572 Prediction : f you want you\n",
      "960 loss : 0.997567 Prediction : f you want you\n",
      "970 loss : 0.997563 Prediction : f you want you\n",
      "980 loss : 0.997558 Prediction : f you want you\n",
      "990 loss : 0.997554 Prediction : f you want you\n",
      "1000 loss : 0.99755 Prediction : f you want you\n",
      "1010 loss : 0.997546 Prediction : f you want you\n",
      "1020 loss : 0.997542 Prediction : f you want you\n",
      "1030 loss : 0.997538 Prediction : f you want you\n",
      "1040 loss : 0.997535 Prediction : f you want you\n",
      "1050 loss : 0.997531 Prediction : f you want you\n",
      "1060 loss : 0.997527 Prediction : f you want you\n",
      "1070 loss : 0.997524 Prediction : f you want you\n",
      "1080 loss : 0.997521 Prediction : f you want you\n",
      "1090 loss : 0.997517 Prediction : f you want you\n",
      "1100 loss : 0.997514 Prediction : f you want you\n",
      "1110 loss : 0.997511 Prediction : f you want you\n",
      "1120 loss : 0.997508 Prediction : f you want you\n",
      "1130 loss : 0.997505 Prediction : f you want you\n",
      "1140 loss : 0.997502 Prediction : f you want you\n",
      "1150 loss : 0.997499 Prediction : f you want you\n",
      "1160 loss : 0.997496 Prediction : f you want you\n",
      "1170 loss : 0.997493 Prediction : f you want you\n",
      "1180 loss : 0.997491 Prediction : f you want you\n",
      "1190 loss : 0.997488 Prediction : f you want you\n",
      "1200 loss : 0.997485 Prediction : f you want you\n",
      "1210 loss : 0.997483 Prediction : f you want you\n",
      "1220 loss : 0.99748 Prediction : f you want you\n",
      "1230 loss : 0.997478 Prediction : f you want you\n",
      "1240 loss : 0.997476 Prediction : f you want you\n",
      "1250 loss : 0.997473 Prediction : f you want you\n",
      "1260 loss : 0.997471 Prediction : f you want you\n",
      "1270 loss : 0.997469 Prediction : f you want you\n",
      "1280 loss : 0.997466 Prediction : f you want you\n",
      "1290 loss : 0.997464 Prediction : f you want you\n",
      "1300 loss : 0.997462 Prediction : f you want you\n",
      "1310 loss : 0.99746 Prediction : f you want you\n",
      "1320 loss : 0.997458 Prediction : f you want you\n",
      "1330 loss : 0.997456 Prediction : f you want you\n",
      "1340 loss : 0.997454 Prediction : f you want you\n",
      "1350 loss : 0.997452 Prediction : f you want you\n",
      "1360 loss : 0.99745 Prediction : f you want you\n",
      "1370 loss : 0.997448 Prediction : f you want you\n",
      "1380 loss : 0.997446 Prediction : f you want you\n",
      "1390 loss : 0.997445 Prediction : f you want you\n",
      "1400 loss : 0.997443 Prediction : f you want you\n",
      "1410 loss : 0.997441 Prediction : f you want you\n",
      "1420 loss : 0.997439 Prediction : f you want you\n",
      "1430 loss : 0.997438 Prediction : f you want you\n",
      "1440 loss : 0.997436 Prediction : f you want you\n",
      "1450 loss : 0.997434 Prediction : f you want you\n",
      "1460 loss : 0.997433 Prediction : f you want you\n",
      "1470 loss : 0.997431 Prediction : f you want you\n",
      "1480 loss : 0.99743 Prediction : f you want you\n",
      "1490 loss : 0.997428 Prediction : f you want you\n",
      "1500 loss : 0.997427 Prediction : f you want you\n",
      "1510 loss : 0.997425 Prediction : f you want you\n",
      "1520 loss : 0.997424 Prediction : f you want you\n",
      "1530 loss : 0.997422 Prediction : f you want you\n",
      "1540 loss : 0.997421 Prediction : f you want you\n",
      "1550 loss : 0.997419 Prediction : f you want you\n",
      "1560 loss : 0.997418 Prediction : f you want you\n",
      "1570 loss : 0.997417 Prediction : f you want you\n",
      "1580 loss : 0.997415 Prediction : f you want you\n",
      "1590 loss : 0.997414 Prediction : f you want you\n",
      "1600 loss : 0.997413 Prediction : f you want you\n",
      "1610 loss : 0.997412 Prediction : f you want you\n",
      "1620 loss : 0.99741 Prediction : f you want you\n",
      "1630 loss : 0.997409 Prediction : f you want you\n",
      "1640 loss : 0.997408 Prediction : f you want you\n",
      "1650 loss : 0.997407 Prediction : f you want you\n",
      "1660 loss : 0.997406 Prediction : f you want you\n",
      "1670 loss : 0.997405 Prediction : f you want you\n",
      "1680 loss : 0.997403 Prediction : f you want you\n",
      "1690 loss : 0.997402 Prediction : f you want you\n",
      "1700 loss : 0.997401 Prediction : f you want you\n",
      "1710 loss : 0.9974 Prediction : f you want you\n",
      "1720 loss : 0.997399 Prediction : f you want you\n",
      "1730 loss : 0.997398 Prediction : f you want you\n",
      "1740 loss : 0.997397 Prediction : f you want you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750 loss : 0.997396 Prediction : f you want you\n",
      "1760 loss : 0.997395 Prediction : f you want you\n",
      "1770 loss : 0.997394 Prediction : f you want you\n",
      "1780 loss : 0.997393 Prediction : f you want you\n",
      "1790 loss : 0.997392 Prediction : f you want you\n",
      "1800 loss : 0.997391 Prediction : f you want you\n",
      "1810 loss : 0.99739 Prediction : f you want you\n",
      "1820 loss : 0.997389 Prediction : f you want you\n",
      "1830 loss : 0.997388 Prediction : f you want you\n",
      "1840 loss : 0.997387 Prediction : f you want you\n",
      "1850 loss : 0.997387 Prediction : f you want you\n",
      "1860 loss : 0.997386 Prediction : f you want you\n",
      "1870 loss : 0.997385 Prediction : f you want you\n",
      "1880 loss : 0.997384 Prediction : f you want you\n",
      "1890 loss : 0.997383 Prediction : f you want you\n",
      "1900 loss : 0.997382 Prediction : f you want you\n",
      "1910 loss : 0.997382 Prediction : f you want you\n",
      "1920 loss : 0.997381 Prediction : f you want you\n",
      "1930 loss : 0.99738 Prediction : f you want you\n",
      "1940 loss : 0.997379 Prediction : f you want you\n",
      "1950 loss : 0.997378 Prediction : f you want you\n",
      "1960 loss : 0.997377 Prediction : f you want you\n",
      "1970 loss : 0.997377 Prediction : f you want you\n",
      "1980 loss : 0.997376 Prediction : f you want you\n",
      "1990 loss : 0.997375 Prediction : f you want you\n",
      "2000 loss : 0.997375 Prediction : f you want you\n",
      "2010 loss : 0.997374 Prediction : f you want you\n",
      "2020 loss : 0.997373 Prediction : f you want you\n",
      "2030 loss : 0.997372 Prediction : f you want you\n",
      "2040 loss : 0.997372 Prediction : f you want you\n",
      "2050 loss : 0.997371 Prediction : f you want you\n",
      "2060 loss : 0.99737 Prediction : f you want you\n",
      "2070 loss : 0.99737 Prediction : f you want you\n",
      "2080 loss : 0.997369 Prediction : f you want you\n",
      "2090 loss : 0.997368 Prediction : f you want you\n",
      "2100 loss : 0.997368 Prediction : f you want you\n",
      "2110 loss : 0.997367 Prediction : f you want you\n",
      "2120 loss : 0.997367 Prediction : f you want you\n",
      "2130 loss : 0.997366 Prediction : f you want you\n",
      "2140 loss : 0.997365 Prediction : f you want you\n",
      "2150 loss : 0.997365 Prediction : f you want you\n",
      "2160 loss : 0.997364 Prediction : f you want you\n",
      "2170 loss : 0.997364 Prediction : f you want you\n",
      "2180 loss : 0.997363 Prediction : f you want you\n",
      "2190 loss : 0.997362 Prediction : f you want you\n",
      "2200 loss : 0.997362 Prediction : f you want you\n",
      "2210 loss : 0.997361 Prediction : f you want you\n",
      "2220 loss : 0.997361 Prediction : f you want you\n",
      "2230 loss : 0.99736 Prediction : f you want you\n",
      "2240 loss : 0.99736 Prediction : f you want you\n",
      "2250 loss : 0.997359 Prediction : f you want you\n",
      "2260 loss : 0.997359 Prediction : f you want you\n",
      "2270 loss : 0.997358 Prediction : f you want you\n",
      "2280 loss : 0.997358 Prediction : f you want you\n",
      "2290 loss : 0.997357 Prediction : f you want you\n",
      "2300 loss : 0.997356 Prediction : f you want you\n",
      "2310 loss : 0.997356 Prediction : f you want you\n",
      "2320 loss : 0.997356 Prediction : f you want you\n",
      "2330 loss : 0.997355 Prediction : f you want you\n",
      "2340 loss : 0.997355 Prediction : f you want you\n",
      "2350 loss : 0.997354 Prediction : f you want you\n",
      "2360 loss : 0.997354 Prediction : f you want you\n",
      "2370 loss : 0.997353 Prediction : f you want you\n",
      "2380 loss : 0.997353 Prediction : f you want you\n",
      "2390 loss : 0.997352 Prediction : f you want you\n",
      "2400 loss : 0.997352 Prediction : f you want you\n",
      "2410 loss : 0.997351 Prediction : f you want you\n",
      "2420 loss : 0.997351 Prediction : f you want you\n",
      "2430 loss : 0.99735 Prediction : f you want you\n",
      "2440 loss : 0.99735 Prediction : f you want you\n",
      "2450 loss : 0.99735 Prediction : f you want you\n",
      "2460 loss : 0.997349 Prediction : f you want you\n",
      "2470 loss : 0.997349 Prediction : f you want you\n",
      "2480 loss : 0.997348 Prediction : f you want you\n",
      "2490 loss : 0.997348 Prediction : f you want you\n",
      "2500 loss : 0.997348 Prediction : f you want you\n",
      "2510 loss : 0.997347 Prediction : f you want you\n",
      "2520 loss : 0.997347 Prediction : f you want you\n",
      "2530 loss : 0.997346 Prediction : f you want you\n",
      "2540 loss : 0.997346 Prediction : f you want you\n",
      "2550 loss : 0.997346 Prediction : f you want you\n",
      "2560 loss : 0.997345 Prediction : f you want you\n",
      "2570 loss : 0.997345 Prediction : f you want you\n",
      "2580 loss : 0.997344 Prediction : f you want you\n",
      "2590 loss : 0.997344 Prediction : f you want you\n",
      "2600 loss : 0.997344 Prediction : f you want you\n",
      "2610 loss : 0.997343 Prediction : f you want you\n",
      "2620 loss : 0.997344 Prediction : f you want you\n",
      "2630 loss : 0.997398 Prediction : f you want you\n",
      "2640 loss : 0.997343 Prediction : f you want you\n",
      "2650 loss : 0.997353 Prediction : f you want you\n",
      "2660 loss : 0.997346 Prediction : f you want you\n",
      "2670 loss : 0.997343 Prediction : f you want you\n",
      "2680 loss : 0.997347 Prediction : f you want you\n",
      "2690 loss : 0.997359 Prediction : f you want you\n",
      "2700 loss : 0.997344 Prediction : f you want you\n",
      "2710 loss : 0.997345 Prediction : f you want you\n",
      "2720 loss : 0.997356 Prediction : f you want you\n",
      "2730 loss : 0.997346 Prediction : f you want you\n",
      "2740 loss : 0.997345 Prediction : f you want you\n",
      "2750 loss : 0.997354 Prediction : f you want you\n",
      "2760 loss : 0.997346 Prediction : f you want you\n",
      "2770 loss : 0.997346 Prediction : f you want you\n",
      "2780 loss : 0.997352 Prediction : f you want you\n",
      "2790 loss : 0.997346 Prediction : f you want you\n",
      "2800 loss : 0.997346 Prediction : f you want you\n",
      "2810 loss : 0.99735 Prediction : f you want you\n",
      "2820 loss : 0.997345 Prediction : f you want you\n",
      "2830 loss : 0.997347 Prediction : f you want you\n",
      "2840 loss : 0.997348 Prediction : f you want you\n",
      "2850 loss : 0.997345 Prediction : f you want you\n",
      "2860 loss : 0.997347 Prediction : f you want you\n",
      "2870 loss : 0.997347 Prediction : f you want you\n",
      "2880 loss : 0.997345 Prediction : f you want you\n",
      "2890 loss : 0.997346 Prediction : f you want you\n",
      "2900 loss : 0.997346 Prediction : f you want you\n",
      "2910 loss : 0.997345 Prediction : f you want you\n",
      "2920 loss : 0.997346 Prediction : f you want you\n",
      "2930 loss : 0.997345 Prediction : f you want you\n",
      "2940 loss : 0.997345 Prediction : f you want you\n",
      "2950 loss : 0.997345 Prediction : f you want you\n",
      "2960 loss : 0.997344 Prediction : f you want you\n",
      "2970 loss : 0.997344 Prediction : f you want you\n",
      "2980 loss : 0.997344 Prediction : f you want you\n",
      "2990 loss : 0.997344 Prediction : f you want you\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(3000):\n",
    "        l, _ = sess.run([loss, train], feed_dict = {X : x_data, Y : y_data})\n",
    "        result = sess.run(prediction, feed_dict = {X : x_data})\n",
    "        \n",
    "        if i%10 == 0:\n",
    "            result_str = [idx2char[c] for c in np.squeeze(result)]\n",
    "            print(i, 'loss :', l, 'Prediction :', ''.join(result_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. RNN with really long sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = (\"if you want to build a ship, don't drum up people together to \"\n",
    "           \"collect wood and don't assign them tasks and work, but rather \"\n",
    "           \"teach them to long for the endless immensity of the sea.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"if you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어를 벡터화시키는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_set = list(set(sentence))\n",
    "char_dic = {w : i for i, w in enumerate(char_set)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hyper parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dim = len(char_set)\n",
    "hidden_size = len(char_set)\n",
    "num_classes = len(char_set)\n",
    "sequence_length = 10 # 문장이 너무 길어서, 순차적으로 10개씩 골라서 batch size를 늘리려고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### batch 만드는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 if you wan -> f you want\n",
      "1 f you want ->  you want \n",
      "2  you want  -> you want t\n",
      "3 you want t -> ou want to\n",
      "4 ou want to -> u want to \n",
      "5 u want to  ->  want to b\n",
      "6  want to b -> want to bu\n",
      "7 want to bu -> ant to bui\n",
      "8 ant to bui -> nt to buil\n",
      "9 nt to buil -> t to build\n",
      "10 t to build ->  to build \n",
      "11  to build  -> to build a\n",
      "12 to build a -> o build a \n",
      "13 o build a  ->  build a s\n",
      "14  build a s -> build a sh\n",
      "15 build a sh -> uild a shi\n",
      "16 uild a shi -> ild a ship\n",
      "17 ild a ship -> ld a ship,\n",
      "18 ld a ship, -> d a ship, \n",
      "19 d a ship,  ->  a ship, d\n",
      "20  a ship, d -> a ship, do\n",
      "21 a ship, do ->  ship, don\n",
      "22  ship, don -> ship, don'\n",
      "23 ship, don' -> hip, don't\n",
      "24 hip, don't -> ip, don't \n",
      "25 ip, don't  -> p, don't d\n",
      "26 p, don't d -> , don't dr\n",
      "27 , don't dr ->  don't dru\n",
      "28  don't dru -> don't drum\n",
      "29 don't drum -> on't drum \n",
      "30 on't drum  -> n't drum u\n",
      "31 n't drum u -> 't drum up\n",
      "32 't drum up -> t drum up \n",
      "33 t drum up  ->  drum up p\n",
      "34  drum up p -> drum up pe\n",
      "35 drum up pe -> rum up peo\n",
      "36 rum up peo -> um up peop\n",
      "37 um up peop -> m up peopl\n",
      "38 m up peopl ->  up people\n",
      "39  up people -> up people \n",
      "40 up people  -> p people t\n",
      "41 p people t ->  people to\n",
      "42  people to -> people tog\n",
      "43 people tog -> eople toge\n",
      "44 eople toge -> ople toget\n",
      "45 ople toget -> ple togeth\n",
      "46 ple togeth -> le togethe\n",
      "47 le togethe -> e together\n",
      "48 e together ->  together \n",
      "49  together  -> together t\n",
      "50 together t -> ogether to\n",
      "51 ogether to -> gether to \n",
      "52 gether to  -> ether to c\n",
      "53 ether to c -> ther to co\n",
      "54 ther to co -> her to col\n",
      "55 her to col -> er to coll\n",
      "56 er to coll -> r to colle\n",
      "57 r to colle ->  to collec\n",
      "58  to collec -> to collect\n",
      "59 to collect -> o collect \n",
      "60 o collect  ->  collect w\n",
      "61  collect w -> collect wo\n",
      "62 collect wo -> ollect woo\n",
      "63 ollect woo -> llect wood\n",
      "64 llect wood -> lect wood \n",
      "65 lect wood  -> ect wood a\n",
      "66 ect wood a -> ct wood an\n",
      "67 ct wood an -> t wood and\n",
      "68 t wood and ->  wood and \n",
      "69  wood and  -> wood and d\n",
      "70 wood and d -> ood and do\n",
      "71 ood and do -> od and don\n",
      "72 od and don -> d and don'\n",
      "73 d and don' ->  and don't\n",
      "74  and don't -> and don't \n",
      "75 and don't  -> nd don't a\n",
      "76 nd don't a -> d don't as\n",
      "77 d don't as ->  don't ass\n",
      "78  don't ass -> don't assi\n",
      "79 don't assi -> on't assig\n",
      "80 on't assig -> n't assign\n",
      "81 n't assign -> 't assign \n",
      "82 't assign  -> t assign t\n",
      "83 t assign t ->  assign th\n",
      "84  assign th -> assign the\n",
      "85 assign the -> ssign them\n",
      "86 ssign them -> sign them \n",
      "87 sign them  -> ign them t\n",
      "88 ign them t -> gn them ta\n",
      "89 gn them ta -> n them tas\n",
      "90 n them tas ->  them task\n",
      "91  them task -> them tasks\n",
      "92 them tasks -> hem tasks \n",
      "93 hem tasks  -> em tasks a\n",
      "94 em tasks a -> m tasks an\n",
      "95 m tasks an ->  tasks and\n",
      "96  tasks and -> tasks and \n",
      "97 tasks and  -> asks and w\n",
      "98 asks and w -> sks and wo\n",
      "99 sks and wo -> ks and wor\n",
      "100 ks and wor -> s and work\n",
      "101 s and work ->  and work,\n",
      "102  and work, -> and work, \n",
      "103 and work,  -> nd work, b\n",
      "104 nd work, b -> d work, bu\n",
      "105 d work, bu ->  work, but\n",
      "106  work, but -> work, but \n",
      "107 work, but  -> ork, but r\n",
      "108 ork, but r -> rk, but ra\n",
      "109 rk, but ra -> k, but rat\n",
      "110 k, but rat -> , but rath\n",
      "111 , but rath ->  but rathe\n",
      "112  but rathe -> but rather\n",
      "113 but rather -> ut rather \n",
      "114 ut rather  -> t rather t\n",
      "115 t rather t ->  rather te\n",
      "116  rather te -> rather tea\n",
      "117 rather tea -> ather teac\n",
      "118 ather teac -> ther teach\n",
      "119 ther teach -> her teach \n",
      "120 her teach  -> er teach t\n",
      "121 er teach t -> r teach th\n",
      "122 r teach th ->  teach the\n",
      "123  teach the -> teach them\n",
      "124 teach them -> each them \n",
      "125 each them  -> ach them t\n",
      "126 ach them t -> ch them to\n",
      "127 ch them to -> h them to \n",
      "128 h them to  ->  them to l\n",
      "129  them to l -> them to lo\n",
      "130 them to lo -> hem to lon\n",
      "131 hem to lon -> em to long\n",
      "132 em to long -> m to long \n",
      "133 m to long  ->  to long f\n",
      "134  to long f -> to long fo\n",
      "135 to long fo -> o long for\n",
      "136 o long for ->  long for \n",
      "137  long for  -> long for t\n",
      "138 long for t -> ong for th\n",
      "139 ong for th -> ng for the\n",
      "140 ng for the -> g for the \n",
      "141 g for the  ->  for the e\n",
      "142  for the e -> for the en\n",
      "143 for the en -> or the end\n",
      "144 or the end -> r the endl\n",
      "145 r the endl ->  the endle\n",
      "146  the endle -> the endles\n",
      "147 the endles -> he endless\n",
      "148 he endless -> e endless \n",
      "149 e endless  ->  endless i\n",
      "150  endless i -> endless im\n",
      "151 endless im -> ndless imm\n",
      "152 ndless imm -> dless imme\n",
      "153 dless imme -> less immen\n",
      "154 less immen -> ess immens\n",
      "155 ess immens -> ss immensi\n",
      "156 ss immensi -> s immensit\n",
      "157 s immensit ->  immensity\n",
      "158  immensity -> immensity \n",
      "159 immensity  -> mmensity o\n",
      "160 mmensity o -> mensity of\n",
      "161 mensity of -> ensity of \n",
      "162 ensity of  -> nsity of t\n",
      "163 nsity of t -> sity of th\n",
      "164 sity of th -> ity of the\n",
      "165 ity of the -> ty of the \n",
      "166 ty of the  -> y of the s\n",
      "167 y of the s ->  of the se\n",
      "168  of the se -> of the sea\n",
      "169 of the sea -> f the sea.\n"
     ]
    }
   ],
   "source": [
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(sentence) - sequence_length): # 문장의 처음부터, 마지막 10개 단어 전까지\n",
    "    x_str = sentence[i : i+sequence_length]\n",
    "    y_str = sentence[i+1 : i+sequence_length+1] # y_label은 x_data의 하나 뒤\n",
    "    print(i, x_str, '->', y_str)\n",
    "    \n",
    "    x = [char_dic[c] for c in x_str]\n",
    "    y = [char_dic[c] for c in y_str]\n",
    "    \n",
    "    dataX.append(x)\n",
    "    dataY.append(y)\n",
    "    \n",
    "X = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "\n",
    "X_one_hot = tf.one_hot(X, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[24, 15, 3, 18, 1, 22, 3, 8, 11, 13],\n",
       " [15, 3, 18, 1, 22, 3, 8, 11, 13, 9],\n",
       " [3, 18, 1, 22, 3, 8, 11, 13, 9, 3],\n",
       " [18, 1, 22, 3, 8, 11, 13, 9, 3, 9],\n",
       " [1, 22, 3, 8, 11, 13, 9, 3, 9, 1],\n",
       " [22, 3, 8, 11, 13, 9, 3, 9, 1, 3],\n",
       " [3, 8, 11, 13, 9, 3, 9, 1, 3, 21],\n",
       " [8, 11, 13, 9, 3, 9, 1, 3, 21, 22],\n",
       " [11, 13, 9, 3, 9, 1, 3, 21, 22, 24],\n",
       " [13, 9, 3, 9, 1, 3, 21, 22, 24, 6],\n",
       " [9, 3, 9, 1, 3, 21, 22, 24, 6, 16],\n",
       " [3, 9, 1, 3, 21, 22, 24, 6, 16, 3],\n",
       " [9, 1, 3, 21, 22, 24, 6, 16, 3, 11],\n",
       " [1, 3, 21, 22, 24, 6, 16, 3, 11, 3],\n",
       " [3, 21, 22, 24, 6, 16, 3, 11, 3, 7],\n",
       " [21, 22, 24, 6, 16, 3, 11, 3, 7, 5],\n",
       " [22, 24, 6, 16, 3, 11, 3, 7, 5, 24],\n",
       " [24, 6, 16, 3, 11, 3, 7, 5, 24, 17],\n",
       " [6, 16, 3, 11, 3, 7, 5, 24, 17, 20],\n",
       " [16, 3, 11, 3, 7, 5, 24, 17, 20, 3],\n",
       " [3, 11, 3, 7, 5, 24, 17, 20, 3, 16],\n",
       " [11, 3, 7, 5, 24, 17, 20, 3, 16, 1],\n",
       " [3, 7, 5, 24, 17, 20, 3, 16, 1, 13],\n",
       " [7, 5, 24, 17, 20, 3, 16, 1, 13, 14],\n",
       " [5, 24, 17, 20, 3, 16, 1, 13, 14, 9],\n",
       " [24, 17, 20, 3, 16, 1, 13, 14, 9, 3],\n",
       " [17, 20, 3, 16, 1, 13, 14, 9, 3, 16],\n",
       " [20, 3, 16, 1, 13, 14, 9, 3, 16, 2],\n",
       " [3, 16, 1, 13, 14, 9, 3, 16, 2, 22],\n",
       " [16, 1, 13, 14, 9, 3, 16, 2, 22, 19],\n",
       " [1, 13, 14, 9, 3, 16, 2, 22, 19, 3],\n",
       " [13, 14, 9, 3, 16, 2, 22, 19, 3, 22],\n",
       " [14, 9, 3, 16, 2, 22, 19, 3, 22, 17],\n",
       " [9, 3, 16, 2, 22, 19, 3, 22, 17, 3],\n",
       " [3, 16, 2, 22, 19, 3, 22, 17, 3, 17],\n",
       " [16, 2, 22, 19, 3, 22, 17, 3, 17, 23],\n",
       " [2, 22, 19, 3, 22, 17, 3, 17, 23, 1],\n",
       " [22, 19, 3, 22, 17, 3, 17, 23, 1, 17],\n",
       " [19, 3, 22, 17, 3, 17, 23, 1, 17, 6],\n",
       " [3, 22, 17, 3, 17, 23, 1, 17, 6, 23],\n",
       " [22, 17, 3, 17, 23, 1, 17, 6, 23, 3],\n",
       " [17, 3, 17, 23, 1, 17, 6, 23, 3, 9],\n",
       " [3, 17, 23, 1, 17, 6, 23, 3, 9, 1],\n",
       " [17, 23, 1, 17, 6, 23, 3, 9, 1, 12],\n",
       " [23, 1, 17, 6, 23, 3, 9, 1, 12, 23],\n",
       " [1, 17, 6, 23, 3, 9, 1, 12, 23, 9],\n",
       " [17, 6, 23, 3, 9, 1, 12, 23, 9, 5],\n",
       " [6, 23, 3, 9, 1, 12, 23, 9, 5, 23],\n",
       " [23, 3, 9, 1, 12, 23, 9, 5, 23, 2],\n",
       " [3, 9, 1, 12, 23, 9, 5, 23, 2, 3],\n",
       " [9, 1, 12, 23, 9, 5, 23, 2, 3, 9],\n",
       " [1, 12, 23, 9, 5, 23, 2, 3, 9, 1],\n",
       " [12, 23, 9, 5, 23, 2, 3, 9, 1, 3],\n",
       " [23, 9, 5, 23, 2, 3, 9, 1, 3, 4],\n",
       " [9, 5, 23, 2, 3, 9, 1, 3, 4, 1],\n",
       " [5, 23, 2, 3, 9, 1, 3, 4, 1, 6],\n",
       " [23, 2, 3, 9, 1, 3, 4, 1, 6, 6],\n",
       " [2, 3, 9, 1, 3, 4, 1, 6, 6, 23],\n",
       " [3, 9, 1, 3, 4, 1, 6, 6, 23, 4],\n",
       " [9, 1, 3, 4, 1, 6, 6, 23, 4, 9],\n",
       " [1, 3, 4, 1, 6, 6, 23, 4, 9, 3],\n",
       " [3, 4, 1, 6, 6, 23, 4, 9, 3, 8],\n",
       " [4, 1, 6, 6, 23, 4, 9, 3, 8, 1],\n",
       " [1, 6, 6, 23, 4, 9, 3, 8, 1, 1],\n",
       " [6, 6, 23, 4, 9, 3, 8, 1, 1, 16],\n",
       " [6, 23, 4, 9, 3, 8, 1, 1, 16, 3],\n",
       " [23, 4, 9, 3, 8, 1, 1, 16, 3, 11],\n",
       " [4, 9, 3, 8, 1, 1, 16, 3, 11, 13],\n",
       " [9, 3, 8, 1, 1, 16, 3, 11, 13, 16],\n",
       " [3, 8, 1, 1, 16, 3, 11, 13, 16, 3],\n",
       " [8, 1, 1, 16, 3, 11, 13, 16, 3, 16],\n",
       " [1, 1, 16, 3, 11, 13, 16, 3, 16, 1],\n",
       " [1, 16, 3, 11, 13, 16, 3, 16, 1, 13],\n",
       " [16, 3, 11, 13, 16, 3, 16, 1, 13, 14],\n",
       " [3, 11, 13, 16, 3, 16, 1, 13, 14, 9],\n",
       " [11, 13, 16, 3, 16, 1, 13, 14, 9, 3],\n",
       " [13, 16, 3, 16, 1, 13, 14, 9, 3, 11],\n",
       " [16, 3, 16, 1, 13, 14, 9, 3, 11, 7],\n",
       " [3, 16, 1, 13, 14, 9, 3, 11, 7, 7],\n",
       " [16, 1, 13, 14, 9, 3, 11, 7, 7, 24],\n",
       " [1, 13, 14, 9, 3, 11, 7, 7, 24, 12],\n",
       " [13, 14, 9, 3, 11, 7, 7, 24, 12, 13],\n",
       " [14, 9, 3, 11, 7, 7, 24, 12, 13, 3],\n",
       " [9, 3, 11, 7, 7, 24, 12, 13, 3, 9],\n",
       " [3, 11, 7, 7, 24, 12, 13, 3, 9, 5],\n",
       " [11, 7, 7, 24, 12, 13, 3, 9, 5, 23],\n",
       " [7, 7, 24, 12, 13, 3, 9, 5, 23, 19],\n",
       " [7, 24, 12, 13, 3, 9, 5, 23, 19, 3],\n",
       " [24, 12, 13, 3, 9, 5, 23, 19, 3, 9],\n",
       " [12, 13, 3, 9, 5, 23, 19, 3, 9, 11],\n",
       " [13, 3, 9, 5, 23, 19, 3, 9, 11, 7],\n",
       " [3, 9, 5, 23, 19, 3, 9, 11, 7, 0],\n",
       " [9, 5, 23, 19, 3, 9, 11, 7, 0, 7],\n",
       " [5, 23, 19, 3, 9, 11, 7, 0, 7, 3],\n",
       " [23, 19, 3, 9, 11, 7, 0, 7, 3, 11],\n",
       " [19, 3, 9, 11, 7, 0, 7, 3, 11, 13],\n",
       " [3, 9, 11, 7, 0, 7, 3, 11, 13, 16],\n",
       " [9, 11, 7, 0, 7, 3, 11, 13, 16, 3],\n",
       " [11, 7, 0, 7, 3, 11, 13, 16, 3, 8],\n",
       " [7, 0, 7, 3, 11, 13, 16, 3, 8, 1],\n",
       " [0, 7, 3, 11, 13, 16, 3, 8, 1, 2],\n",
       " [7, 3, 11, 13, 16, 3, 8, 1, 2, 0],\n",
       " [3, 11, 13, 16, 3, 8, 1, 2, 0, 20],\n",
       " [11, 13, 16, 3, 8, 1, 2, 0, 20, 3],\n",
       " [13, 16, 3, 8, 1, 2, 0, 20, 3, 21],\n",
       " [16, 3, 8, 1, 2, 0, 20, 3, 21, 22],\n",
       " [3, 8, 1, 2, 0, 20, 3, 21, 22, 9],\n",
       " [8, 1, 2, 0, 20, 3, 21, 22, 9, 3],\n",
       " [1, 2, 0, 20, 3, 21, 22, 9, 3, 2],\n",
       " [2, 0, 20, 3, 21, 22, 9, 3, 2, 11],\n",
       " [0, 20, 3, 21, 22, 9, 3, 2, 11, 9],\n",
       " [20, 3, 21, 22, 9, 3, 2, 11, 9, 5],\n",
       " [3, 21, 22, 9, 3, 2, 11, 9, 5, 23],\n",
       " [21, 22, 9, 3, 2, 11, 9, 5, 23, 2],\n",
       " [22, 9, 3, 2, 11, 9, 5, 23, 2, 3],\n",
       " [9, 3, 2, 11, 9, 5, 23, 2, 3, 9],\n",
       " [3, 2, 11, 9, 5, 23, 2, 3, 9, 23],\n",
       " [2, 11, 9, 5, 23, 2, 3, 9, 23, 11],\n",
       " [11, 9, 5, 23, 2, 3, 9, 23, 11, 4],\n",
       " [9, 5, 23, 2, 3, 9, 23, 11, 4, 5],\n",
       " [5, 23, 2, 3, 9, 23, 11, 4, 5, 3],\n",
       " [23, 2, 3, 9, 23, 11, 4, 5, 3, 9],\n",
       " [2, 3, 9, 23, 11, 4, 5, 3, 9, 5],\n",
       " [3, 9, 23, 11, 4, 5, 3, 9, 5, 23],\n",
       " [9, 23, 11, 4, 5, 3, 9, 5, 23, 19],\n",
       " [23, 11, 4, 5, 3, 9, 5, 23, 19, 3],\n",
       " [11, 4, 5, 3, 9, 5, 23, 19, 3, 9],\n",
       " [4, 5, 3, 9, 5, 23, 19, 3, 9, 1],\n",
       " [5, 3, 9, 5, 23, 19, 3, 9, 1, 3],\n",
       " [3, 9, 5, 23, 19, 3, 9, 1, 3, 6],\n",
       " [9, 5, 23, 19, 3, 9, 1, 3, 6, 1],\n",
       " [5, 23, 19, 3, 9, 1, 3, 6, 1, 13],\n",
       " [23, 19, 3, 9, 1, 3, 6, 1, 13, 12],\n",
       " [19, 3, 9, 1, 3, 6, 1, 13, 12, 3],\n",
       " [3, 9, 1, 3, 6, 1, 13, 12, 3, 15],\n",
       " [9, 1, 3, 6, 1, 13, 12, 3, 15, 1],\n",
       " [1, 3, 6, 1, 13, 12, 3, 15, 1, 2],\n",
       " [3, 6, 1, 13, 12, 3, 15, 1, 2, 3],\n",
       " [6, 1, 13, 12, 3, 15, 1, 2, 3, 9],\n",
       " [1, 13, 12, 3, 15, 1, 2, 3, 9, 5],\n",
       " [13, 12, 3, 15, 1, 2, 3, 9, 5, 23],\n",
       " [12, 3, 15, 1, 2, 3, 9, 5, 23, 3],\n",
       " [3, 15, 1, 2, 3, 9, 5, 23, 3, 23],\n",
       " [15, 1, 2, 3, 9, 5, 23, 3, 23, 13],\n",
       " [1, 2, 3, 9, 5, 23, 3, 23, 13, 16],\n",
       " [2, 3, 9, 5, 23, 3, 23, 13, 16, 6],\n",
       " [3, 9, 5, 23, 3, 23, 13, 16, 6, 23],\n",
       " [9, 5, 23, 3, 23, 13, 16, 6, 23, 7],\n",
       " [5, 23, 3, 23, 13, 16, 6, 23, 7, 7],\n",
       " [23, 3, 23, 13, 16, 6, 23, 7, 7, 3],\n",
       " [3, 23, 13, 16, 6, 23, 7, 7, 3, 24],\n",
       " [23, 13, 16, 6, 23, 7, 7, 3, 24, 19],\n",
       " [13, 16, 6, 23, 7, 7, 3, 24, 19, 19],\n",
       " [16, 6, 23, 7, 7, 3, 24, 19, 19, 23],\n",
       " [6, 23, 7, 7, 3, 24, 19, 19, 23, 13],\n",
       " [23, 7, 7, 3, 24, 19, 19, 23, 13, 7],\n",
       " [7, 7, 3, 24, 19, 19, 23, 13, 7, 24],\n",
       " [7, 3, 24, 19, 19, 23, 13, 7, 24, 9],\n",
       " [3, 24, 19, 19, 23, 13, 7, 24, 9, 18],\n",
       " [24, 19, 19, 23, 13, 7, 24, 9, 18, 3],\n",
       " [19, 19, 23, 13, 7, 24, 9, 18, 3, 1],\n",
       " [19, 23, 13, 7, 24, 9, 18, 3, 1, 15],\n",
       " [23, 13, 7, 24, 9, 18, 3, 1, 15, 3],\n",
       " [13, 7, 24, 9, 18, 3, 1, 15, 3, 9],\n",
       " [7, 24, 9, 18, 3, 1, 15, 3, 9, 5],\n",
       " [24, 9, 18, 3, 1, 15, 3, 9, 5, 23],\n",
       " [9, 18, 3, 1, 15, 3, 9, 5, 23, 3],\n",
       " [18, 3, 1, 15, 3, 9, 5, 23, 3, 7],\n",
       " [3, 1, 15, 3, 9, 5, 23, 3, 7, 23],\n",
       " [1, 15, 3, 9, 5, 23, 3, 7, 23, 11]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = len(dataX)\n",
    "dataX # batch 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell= tf.contrib.rnn.BasicLSTMCell(num_units = hidden_size)\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "with tf.variable_scope('second'):\n",
    "    outputs, _states = tf.nn.dynamic_rnn(cell, X_one_hot, initial_state = initial_state, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight, Loss, Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.ones([batch_size, sequence_length])\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits = outputs, targets = Y, weights=weights)\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.train.AdamOptimizer(learning_rate = 0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 k bhuohooo 3.2202\n",
      "0 10 dddoo,hyaa 3.2202\n",
      "0 20 .m.bbbbbbb 3.2202\n",
      "0 30 uiaahmmar' 3.2202\n",
      "0 40 hthooooolh 3.2202\n",
      "0 50 dooccoammo 3.2202\n",
      "0 60 um'i''aaad 3.2202\n",
      "0 70  oomomobbb 3.2202\n",
      "0 80 uiaahh,kkk 3.2202\n",
      "0 90 ahdoar'do, 3.2202\n",
      "0 100 ds'mbbbmmm 3.2202\n",
      "0 110 dudfaahdmo 3.2202\n",
      "0 120 'ammdmm.o. 3.2202\n",
      "0 130 doal'doo'o 3.2202\n",
      "0 140 ac.bmmmmmm 3.2202\n",
      "0 150 .maaaayy'y 3.2202\n",
      "0 160 rrlrrl,hhh 3.2202\n",
      "100 0 t t u aa t 2.02257\n",
      "100 10 ha  lu ld  2.02257\n",
      "100 20 t t  t  d  2.02257\n",
      "100 30  gt a    t 2.02257\n",
      "100 40   p  oee t 2.02257\n",
      "100 50 h       t  2.02257\n",
      "100 60  lllle t t 2.02257\n",
      "100 70 or  a t d  2.02257\n",
      "100 80  gt a s t  2.02257\n",
      "100 90 dt    t  s 2.02257\n",
      "100 100 s a d do   2.02257\n",
      "100 110 s but r    2.02257\n",
      "100 120 e  t   t t 2.02257\n",
      "100 130 h   t  lo  2.02257\n",
      "100 140 d t   t    2.02257\n",
      "100 150 ta  e s im 2.02257\n",
      "100 160 e ns t  oo 2.02257\n",
      "200 0 t y u tant 1.95872\n",
      "200 10  a  luild  1.95872\n",
      "200 20 t t it  d  1.95872\n",
      "200 30 l't a am t 1.95872\n",
      "200 40   peopee t 1.95872\n",
      "200 50    t e  t  1.95872\n",
      "200 60 lllllo t o 1.95872\n",
      "200 70 ord and d  1.95872\n",
      "200 80 l't a s nn 1.95872\n",
      "200 90 't e  t ss 1.95872\n",
      "200 100 s ind dor  1.95872\n",
      "200 110 s but r t  1.95872\n",
      "200 120 e  t  ht t 1.95872\n",
      "200 130  er t  lo  1.95872\n",
      "200 140 ' t r t e  1.95872\n",
      "200 150 t e e s im 1.95872\n",
      "200 160   ns ty od 1.95872\n",
      "300 0 t y u aant 1.92936\n",
      "300 10  ao luild  1.92936\n",
      "300 20 tnt it  d  1.92936\n",
      "300 30  't a am t 1.92936\n",
      "300 40   peopee t 1.92936\n",
      "300 50    t er t  1.92936\n",
      "300 60  lolle t o 1.92936\n",
      "300 70 ord and d  1.92936\n",
      "300 80  't a s nn 1.92936\n",
      "300 90 't e  t ss 1.92936\n",
      "300 100 s ind dor  1.92936\n",
      "300 110 s but r th 1.92936\n",
      "300 120 e  t  tt t 1.92936\n",
      "300 130  er t  lo  1.92936\n",
      "300 140 ' t r t e  1.92936\n",
      "300 150 tad e s im 1.92936\n",
      "300 160   ns ty od 1.92936\n",
      "400 0 t y u aant 1.91927\n",
      "400 10  ao ouild  1.91927\n",
      "400 20 tss it  d  1.91927\n",
      "400 30  't a am t 1.91927\n",
      "400 40   peopee t 1.91927\n",
      "400 50    t er t  1.91927\n",
      "400 60  lollent o 1.91927\n",
      "400 70 ord and d  1.91927\n",
      "400 80  't a s nn 1.91927\n",
      "400 90 't e  t ss 1.91927\n",
      "400 100 s ind dor  1.91927\n",
      "400 110 s but r th 1.91927\n",
      "400 120 e  t att t 1.91927\n",
      "400 130  er t  lon 1.91927\n",
      "400 140 ' t r t e  1.91927\n",
      "400 150 tae e s im 1.91927\n",
      "400 160   ns ty od 1.91927\n",
      "500 0 t y u aant 1.96401\n",
      "500 10  ao luild  1.96401\n",
      "500 20 tss it  d  1.96401\n",
      "500 30  't a am t 1.96401\n",
      "500 40   peopee t 1.96401\n",
      "500 50    t e  to 1.96401\n",
      "500 60  lollent d 1.96401\n",
      "500 70 ood and d  1.96401\n",
      "500 80  't a s nn 1.96401\n",
      "500 90 't e  t ss 1.96401\n",
      "500 100 s ind dook 1.96401\n",
      "500 110 s but a th 1.96401\n",
      "500 120 e  toatt t 1.96401\n",
      "500 130  e  t  lon 1.96401\n",
      "500 140 ' t e t e  1.96401\n",
      "500 150 t e ess im 1.96401\n",
      "500 160 e ns ty o  1.96401\n",
      "600 0 t y u aant 1.95758\n",
      "600 10  ao tuild  1.95758\n",
      "600 20 tss it  d  1.95758\n",
      "600 30  't a am t 1.95758\n",
      "600 40   peopee t 1.95758\n",
      "600 50    t e  to 1.95758\n",
      "600 60  lollent o 1.95758\n",
      "600 70 ood and d  1.95758\n",
      "600 80  't a s nn 1.95758\n",
      "600 90 't e  tass 1.95758\n",
      "600 100 s and dook 1.95758\n",
      "600 110 s but a th 1.95758\n",
      "600 120 e  teatt t 1.95758\n",
      "600 130  e  te lon 1.95758\n",
      "600 140 ' t   t e  1.95758\n",
      "600 150 tad ess im 1.95758\n",
      "600 160 eens ty o  1.95758\n",
      "700 0 t you aant 1.94794\n",
      "700 10 hao tuild  1.94794\n",
      "700 20 tss it  d  1.94794\n",
      "700 30  't a am t 1.94794\n",
      "700 40   peopee t 1.94794\n",
      "700 50 h  t e  to 1.94794\n",
      "700 60  lollent o 1.94794\n",
      "700 70 ood and d  1.94794\n",
      "700 80  't a s nn 1.94794\n",
      "700 90 'the  toss 1.94794\n",
      "700 100 s and do k 1.94794\n",
      "700 110 s but a th 1.94794\n",
      "700 120 e  toaht t 1.94794\n",
      "700 130 he  to lon 1.94794\n",
      "700 140 ' t   t e  1.94794\n",
      "700 150 tae ess im 1.94794\n",
      "700 160 eens ty o  1.94794\n",
      "800 0 t you tant 1.94587\n",
      "800 10  ao tuild  1.94587\n",
      "800 20 tss it  d  1.94587\n",
      "800 30  't a am t 1.94587\n",
      "800 40   peopee t 1.94587\n",
      "800 50    t e  to 1.94587\n",
      "800 60  lollent o 1.94587\n",
      "800 70 ood and d  1.94587\n",
      "800 80  't a s nn 1.94587\n",
      "800 90 'the  tess 1.94587\n",
      "800 100 s and do k 1.94587\n",
      "800 110 s but a th 1.94587\n",
      "800 120 e  toatt t 1.94587\n",
      "800 130  e  to lon 1.94587\n",
      "800 140 ' t   t e  1.94587\n",
      "800 150 tae ess im 1.94587\n",
      "800 160 eens ty o  1.94587\n",
      "900 0 t you tant 1.94903\n",
      "900 10 hto tuild  1.94903\n",
      "900 20 tss it  d  1.94903\n",
      "900 30  't a am t 1.94903\n",
      "900 40   peopee t 1.94903\n",
      "900 50 h  t e  to 1.94903\n",
      "900 60  lollent o 1.94903\n",
      "900 70 ood and d  1.94903\n",
      "900 80  't a s nn 1.94903\n",
      "900 90 'the  tess 1.94903\n",
      "900 100 s and do k 1.94903\n",
      "900 110 s but a th 1.94903\n",
      "900 120 e  toatt t 1.94903\n",
      "900 130 he  te lon 1.94903\n",
      "900 140 ' t   t e  1.94903\n",
      "900 150 tad ess im 1.94903\n",
      "900 160 eens ty o  1.94903\n",
      "1000 0 t sout ant 1.97929\n",
      "1000 10 hao outld  1.97929\n",
      "1000 20 tst it  d  1.97929\n",
      "1000 30  't a am t 1.97929\n",
      "1000 40   peopee t 1.97929\n",
      "1000 50 h  t e  to 1.97929\n",
      "1000 60  lollent o 1.97929\n",
      "1000 70 ool and d  1.97929\n",
      "1000 80  't a s nn 1.97929\n",
      "1000 90 't e  toss 1.97929\n",
      "1000 100 s and do k 1.97929\n",
      "1000 110 s but a th 1.97929\n",
      "1000 120 e  teatt t 1.97929\n",
      "1000 130 he  to lon 1.97929\n",
      "1000 140 ' t   t e  1.97929\n",
      "1000 150 tae e s in 1.97929\n",
      "1000 160 eens nt o  1.97929\n",
      "1100 0 t y u  ant 1.96305\n",
      "1100 10 hao tuild  1.96305\n",
      "1100 20 tss it  d  1.96305\n",
      "1100 30  't a am t 1.96305\n",
      "1100 40   peppee t 1.96305\n",
      "1100 50 h  t e  to 1.96305\n",
      "1100 60  lolle t o 1.96305\n",
      "1100 70 aod and d  1.96305\n",
      "1100 80  't a sinn 1.96305\n",
      "1100 90 't e  toss 1.96305\n",
      "1100 100 s and do k 1.96305\n",
      "1100 110 s but a th 1.96305\n",
      "1100 120 e  teatt t 1.96305\n",
      "1100 130 he eto lon 1.96305\n",
      "1100 140 ' t   t e  1.96305\n",
      "1100 150 tae ess im 1.96305\n",
      "1100 160 eens t  o  1.96305\n",
      "1200 0 t y u tant 1.94717\n",
      "1200 10 hao tuild  1.94717\n",
      "1200 20 tss it  d  1.94717\n",
      "1200 30  't d am t 1.94717\n",
      "1200 40   peopee t 1.94717\n",
      "1200 50 h  t e  to 1.94717\n",
      "1200 60  lolle t o 1.94717\n",
      "1200 70 aod and d  1.94717\n",
      "1200 80  't d sinn 1.94717\n",
      "1200 90 'the  toss 1.94717\n",
      "1200 100 s and do k 1.94717\n",
      "1200 110 s but a th 1.94717\n",
      "1200 120 e  teatt t 1.94717\n",
      "1200 130 he eto lon 1.94717\n",
      "1200 140 ' t   t e  1.94717\n",
      "1200 150 tae ess im 1.94717\n",
      "1200 160 eens t  o  1.94717\n",
      "1300 0 t y u tant 1.94358\n",
      "1300 10 hao tuild  1.94358\n",
      "1300 20 tss it  d  1.94358\n",
      "1300 30  't d um t 1.94358\n",
      "1300 40   peopee t 1.94358\n",
      "1300 50 h  t em to 1.94358\n",
      "1300 60  lollent o 1.94358\n",
      "1300 70 aod and d  1.94358\n",
      "1300 80  't d sinn 1.94358\n",
      "1300 90 'the  tass 1.94358\n",
      "1300 100 s and oo k 1.94358\n",
      "1300 110 s but a th 1.94358\n",
      "1300 120 e  teatt t 1.94358\n",
      "1300 130 hemeto lon 1.94358\n",
      "1300 140 ' t e t e  1.94358\n",
      "1300 150 tad ess im 1.94358\n",
      "1300 160 eens t  o  1.94358\n",
      "1400 0 t y u tant 1.94873\n",
      "1400 10 hao tuild  1.94873\n",
      "1400 20 tss it  d  1.94873\n",
      "1400 30  't d am t 1.94873\n",
      "1400 40   peppee t 1.94873\n",
      "1400 50 h  t e  to 1.94873\n",
      "1400 60  lollent o 1.94873\n",
      "1400 70 aod and d  1.94873\n",
      "1400 80  't d sinn 1.94873\n",
      "1400 90 'the  tass 1.94873\n",
      "1400 100 s and do k 1.94873\n",
      "1400 110 s but a th 1.94873\n",
      "1400 120 e  teaht t 1.94873\n",
      "1400 130 he eto lon 1.94873\n",
      "1400 140 ' t e t e  1.94873\n",
      "1400 150 tae ess am 1.94873\n",
      "1400 160 eens t  o  1.94873\n",
      "1500 0 t y u  ant 1.9507\n",
      "1500 10 hao tuild  1.9507\n",
      "1500 20 tss ito d  1.9507\n",
      "1500 30 l't a am t 1.9507\n",
      "1500 40   peopee t 1.9507\n",
      "1500 50 h  t e  to 1.9507\n",
      "1500 60 llollent o 1.9507\n",
      "1500 70 ard and d  1.9507\n",
      "1500 80 l't a sinn 1.9507\n",
      "1500 90  the  toss 1.9507\n",
      "1500 100 s and oo k 1.9507\n",
      "1500 110 s but a th 1.9507\n",
      "1500 120 em teaht t 1.9507\n",
      "1500 130 he eto lon 1.9507\n",
      "1500 140   t   t e  1.9507\n",
      "1500 150 tae ess am 1.9507\n",
      "1500 160 eens t  o  1.9507\n",
      "1600 0 t t   dont 2.32966\n",
      "1600 10 oao tut e  2.32966\n",
      "1600 20 tsthet  t  2.32966\n",
      "1600 30 r t d am t 2.32966\n",
      "1600 40 p p p up t 2.32966\n",
      "1600 50 o  tae  t  2.32966\n",
      "1600 60 rdt ehkt t 2.32966\n",
      "1600 70 a   a t t  2.32966\n",
      "1600 80 r t dn itn 2.32966\n",
      "1600 90 dt e  tosh 2.32966\n",
      "1600 100 s ast ta   2.32966\n",
      "1600 110 s sut a th 2.32966\n",
      "1600 120 e  t  et t 2.32966\n",
      "1600 130 oe  to td  2.32966\n",
      "1600 140 d t   t e  2.32966\n",
      "1600 150 toe e   an 2.32966\n",
      "1600 160 emme ts t  2.32966\n",
      "1700 0 tmeo  dont 2.2131\n",
      "1700 10  ao tutme  2.2131\n",
      "1700 20 tstsen  do 2.2131\n",
      "1700 30 rut anam t 2.2131\n",
      "1700 40 t pep  e t 2.2131\n",
      "1700 50    t e  to 2.2131\n",
      "1700 60 rdo ee t t 2.2131\n",
      "1700 70 a   a d to 2.2131\n",
      "1700 80 rut ass nn 2.2131\n",
      "1700 90 'the  toss 2.2131\n",
      "1700 100 s and tod  2.2131\n",
      "1700 110 s sut aot  2.2131\n",
      "1700 120 e  toaet t 2.2131\n",
      "1700 130  e  to te  2.2131\n",
      "1700 140 ' to  toe  2.2131\n",
      "1700 150 toe e s ae 2.2131\n",
      "1700 160 emmests sd 2.2131\n",
      "1800 0 t eododont 2.17091\n",
      "1800 10 hao  utme  2.17091\n",
      "1800 20 tsthem  do 2.17091\n",
      "1800 30 rut daum t 2.17091\n",
      "1800 40 p pep  e t 2.17091\n",
      "1800 50 h  t e  to 2.17091\n",
      "1800 60 rdo ee t t 2.17091\n",
      "1800 70 ao  and to 2.17091\n",
      "1800 80 rut dns nn 2.17091\n",
      "1800 90 'the etoss 2.17091\n",
      "1800 100 s and tod  2.17091\n",
      "1800 110 s sut aath 2.17091\n",
      "1800 120 e  toant t 2.17091\n",
      "1800 130 he  to te  2.17091\n",
      "1800 140 ' to  the  2.17091\n",
      "1800 150 tae e s in 2.17091\n",
      "1800 160 emms ts sd 2.17091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 0 t eod dont 2.16259\n",
      "1900 10 oao tutme  2.16259\n",
      "1900 20 tsthin  do 2.16259\n",
      "1900 30  ut aaum t 2.16259\n",
      "1900 40 p pepe e t 2.16259\n",
      "1900 50 o  t e  to 2.16259\n",
      "1900 60  do eent t 2.16259\n",
      "1900 70 ao  a d to 2.16259\n",
      "1900 80  ut a sinn 2.16259\n",
      "1900 90 'the etoss 2.16259\n",
      "1900 100 s and tod  2.16259\n",
      "1900 110 s sut aath 2.16259\n",
      "1900 120 e  toaet t 2.16259\n",
      "1900 130 oe eto te  2.16259\n",
      "1900 140 ' to  the  2.16259\n",
      "1900 150 tae e s in 2.16259\n",
      "1900 160 emmssss sd 2.16259\n",
      "2000 0 t eod eont 2.14575\n",
      "2000 10 oao tutme  2.14575\n",
      "2000 20 tsthim  do 2.14575\n",
      "2000 30  ut arum t 2.14575\n",
      "2000 40 p pepp e t 2.14575\n",
      "2000 50 o  t e  to 2.14575\n",
      "2000 60  do eent t 2.14575\n",
      "2000 70 ao  and to 2.14575\n",
      "2000 80  ut ansinn 2.14575\n",
      "2000 90 'the etoss 2.14575\n",
      "2000 100 s and to   2.14575\n",
      "2000 110 s sut aath 2.14575\n",
      "2000 120 e  toant t 2.14575\n",
      "2000 130 oe eto se  2.14575\n",
      "2000 140 ' to  the  2.14575\n",
      "2000 150 tae e s im 2.14575\n",
      "2000 160 emmssts sd 2.14575\n",
      "2100 0 t eod dont 2.14054\n",
      "2100 10 oao tutme  2.14054\n",
      "2100 20 tsthine do 2.14054\n",
      "2100 30  ut arum t 2.14054\n",
      "2100 40 p pepp e t 2.14054\n",
      "2100 50 o  t e  to 2.14054\n",
      "2100 60  do eent t 2.14054\n",
      "2100 70 ao  and to 2.14054\n",
      "2100 80  ut ansinn 2.14054\n",
      "2100 90 'the etoss 2.14054\n",
      "2100 100 s and to   2.14054\n",
      "2100 110 s sut aath 2.14054\n",
      "2100 120 e  toant t 2.14054\n",
      "2100 130 oe eto sen 2.14054\n",
      "2100 140 ' to  the  2.14054\n",
      "2100 150 tae e s im 2.14054\n",
      "2100 160 emmsst  td 2.14054\n",
      "2200 0 t eod dont 2.12806\n",
      "2200 10 oao tutee  2.12806\n",
      "2200 20 tsthite do 2.12806\n",
      "2200 30  dt drum t 2.12806\n",
      "2200 40 p peppee t 2.12806\n",
      "2200 50 o  t e  to 2.12806\n",
      "2200 60  do eent t 2.12806\n",
      "2200 70 ao  a d to 2.12806\n",
      "2200 80  dt dnsinn 2.12806\n",
      "2200 90 'the etoss 2.12806\n",
      "2200 100 s and to   2.12806\n",
      "2200 110 s sut aath 2.12806\n",
      "2200 120 e  toant t 2.12806\n",
      "2200 130 oe eto sen 2.12806\n",
      "2200 140 ' to  the  2.12806\n",
      "2200 150 toe e s im 2.12806\n",
      "2200 160 eemsste td 2.12806\n",
      "2300 0 t eod dont 2.11588\n",
      "2300 10 oao tut e  2.11588\n",
      "2300 20 tsthite do 2.11588\n",
      "2300 30 ndt drum t 2.11588\n",
      "2300 40 p peppee t 2.11588\n",
      "2300 50 o  t e  to 2.11588\n",
      "2300 60 ndo eent t 2.11588\n",
      "2300 70 ao  a d do 2.11588\n",
      "2300 80 ndt dnsinn 2.11588\n",
      "2300 90 'the etoss 2.11588\n",
      "2300 100 s and dod  2.11588\n",
      "2300 110 s tut aath 2.11588\n",
      "2300 120 e  toant t 2.11588\n",
      "2300 130 oe eto te  2.11588\n",
      "2300 140 ' to  the  2.11588\n",
      "2300 150 tod e s im 2.11588\n",
      "2300 160 emmsste td 2.11588\n",
      "2400 0 t eod dont 2.11685\n",
      "2400 10 oao tut e  2.11685\n",
      "2400 20 tsthite do 2.11685\n",
      "2400 30  dt arum t 2.11685\n",
      "2400 40 p peppee t 2.11685\n",
      "2400 50 o  t e  to 2.11685\n",
      "2400 60  do eent t 2.11685\n",
      "2400 70 ao  and do 2.11685\n",
      "2400 80  dt asssnn 2.11685\n",
      "2400 90 'the etoss 2.11685\n",
      "2400 100 s and tod  2.11685\n",
      "2400 110 s tut aath 2.11685\n",
      "2400 120 e  toantet 2.11685\n",
      "2400 130 oe eto te  2.11685\n",
      "2400 140 ' to  the  2.11685\n",
      "2400 150 tod e s in 2.11685\n",
      "2400 160 emmsste td 2.11685\n",
      "2500 0 t eod dont 2.10167\n",
      "2500 10 oao tut e  2.10167\n",
      "2500 20 tsthite do 2.10167\n",
      "2500 30  dt drum t 2.10167\n",
      "2500 40 p pepp e t 2.10167\n",
      "2500 50 o  t e  to 2.10167\n",
      "2500 60  do ee t t 2.10167\n",
      "2500 70 oo  a d do 2.10167\n",
      "2500 80  dt dssinn 2.10167\n",
      "2500 90 'the etoss 2.10167\n",
      "2500 100 s and dod  2.10167\n",
      "2500 110 s tut aath 2.10167\n",
      "2500 120 e  toant t 2.10167\n",
      "2500 130 oe eto te  2.10167\n",
      "2500 140 ' to  the  2.10167\n",
      "2500 150 toe e s am 2.10167\n",
      "2500 160 emmsst  td 2.10167\n",
      "2600 0 t eod dont 2.0967\n",
      "2600 10 oao tut e  2.0967\n",
      "2600 20 tsthite do 2.0967\n",
      "2600 30 ndt drum t 2.0967\n",
      "2600 40 p peppee t 2.0967\n",
      "2600 50 o  t e  to 2.0967\n",
      "2600 60 ndo ee t d 2.0967\n",
      "2600 70 oo  and do 2.0967\n",
      "2600 80 ndt dssinn 2.0967\n",
      "2600 90 'the etoss 2.0967\n",
      "2600 100 s and dod  2.0967\n",
      "2600 110 s dut aath 2.0967\n",
      "2600 120 e  toant t 2.0967\n",
      "2600 130 oe eto te  2.0967\n",
      "2600 140 'eto  the  2.0967\n",
      "2600 150 tad e s am 2.0967\n",
      "2600 160 emmsst  td 2.0967\n",
      "2700 0 t eod dont 2.0954\n",
      "2700 10 oao eut e  2.0954\n",
      "2700 20 tsthite do 2.0954\n",
      "2700 30 ndt arum t 2.0954\n",
      "2700 40 p peppee t 2.0954\n",
      "2700 50 o et e  to 2.0954\n",
      "2700 60 ndo ee t d 2.0954\n",
      "2700 70 oo  and do 2.0954\n",
      "2700 80 ndt assinn 2.0954\n",
      "2700 90 dthe etoss 2.0954\n",
      "2700 100 s ind dod  2.0954\n",
      "2700 110 s dut aath 2.0954\n",
      "2700 120 e  toant t 2.0954\n",
      "2700 130 oe eto ten 2.0954\n",
      "2700 140 deto  the  2.0954\n",
      "2700 150 tod e s am 2.0954\n",
      "2700 160 eemsst  td 2.0954\n",
      "2800 0 t eod dont 2.0897\n",
      "2800 10 oao eut e  2.0897\n",
      "2800 20 tsthite do 2.0897\n",
      "2800 30 ndt arum t 2.0897\n",
      "2800 40 p peppee t 2.0897\n",
      "2800 50 o  t e  to 2.0897\n",
      "2800 60 ndo ee t d 2.0897\n",
      "2800 70 oo  and do 2.0897\n",
      "2800 80 ndt assinn 2.0897\n",
      "2800 90 dthe etoss 2.0897\n",
      "2800 100 s ind dod  2.0897\n",
      "2800 110 s dut aath 2.0897\n",
      "2800 120 e  toant t 2.0897\n",
      "2800 130 oe eto ten 2.0897\n",
      "2800 140 detod the  2.0897\n",
      "2800 150 tod e s im 2.0897\n",
      "2800 160 eemsst  td 2.0897\n",
      "2900 0 t eod dont 2.08928\n",
      "2900 10 oto tut e  2.08928\n",
      "2900 20 tsthite do 2.08928\n",
      "2900 30 ndt drum t 2.08928\n",
      "2900 40 p peppee t 2.08928\n",
      "2900 50 o  t e  to 2.08928\n",
      "2900 60 ndo ee t d 2.08928\n",
      "2900 70 oo  and do 2.08928\n",
      "2900 80 ndt dssinn 2.08928\n",
      "2900 90 dthe etoss 2.08928\n",
      "2900 100 s ind dod  2.08928\n",
      "2900 110 s dut aath 2.08928\n",
      "2900 120 e  toant t 2.08928\n",
      "2900 130 oe eto ten 2.08928\n",
      "2900 140 d tod the  2.08928\n",
      "2900 150 tod ess im 2.08928\n",
      "2900 160 eemsst  t  2.08928\n",
      "t dod dont to tui e a thite don't aoam toepeppee to et er to ttdee t dodd and don't ansinn the etosss ind dod e dut aathe  toant the eto een' to  the end ess immemsit  t  the eaae"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(3000):\n",
    "        l, _, results = sess.run([loss, train, outputs], feed_dict = {X : dataX, Y : dataY})\n",
    "        for j, result in enumerate(results):\n",
    "            index = np.argmax(result, axis=1)\n",
    "            if i%100 == 0:\n",
    "                if j%10 == 0:\n",
    "                    print(i, j, ''.join([char_set[t] for t in index]), l)\n",
    "                    \n",
    "    for j, result in enumerate(results):\n",
    "        index = np.argmax(result, axis = 1)\n",
    "        if j is 0:\n",
    "            print(''.join([char_set[t] for t in index]), end='')\n",
    "        else:\n",
    "            print(char_set[index[-1]], end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습이 잘 되지 않는다. 왜 그런 것일까? ㅠㅠ\n",
    "\n",
    "해답은 **deep**하게 Neural Network를 쌓지 않았기 때문이다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Stacked RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"if you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = (\"if you want to build a ship, don't drum up people together to \"\n",
    "           \"collect wood and don't assign them tasks and work, but rather \"\n",
    "           \"teach them to long for the endless immensity of the sea.\")\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어를 벡터화시키는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_set = list(set(sentence))\n",
    "char_dic = {w : i for i, w in enumerate(char_set)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hyper parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dim = len(char_set)\n",
    "hidden_size = len(char_set)\n",
    "num_classes = len(char_set)\n",
    "sequence_length = 10 # 문장이 너무 길어서, 순차적으로 10개씩 골라서 batch size를 늘리려고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### batch 만드는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 if you wan -> f you want\n",
      "1 f you want ->  you want \n",
      "2  you want  -> you want t\n",
      "3 you want t -> ou want to\n",
      "4 ou want to -> u want to \n",
      "5 u want to  ->  want to b\n",
      "6  want to b -> want to bu\n",
      "7 want to bu -> ant to bui\n",
      "8 ant to bui -> nt to buil\n",
      "9 nt to buil -> t to build\n",
      "10 t to build ->  to build \n",
      "11  to build  -> to build a\n",
      "12 to build a -> o build a \n",
      "13 o build a  ->  build a s\n",
      "14  build a s -> build a sh\n",
      "15 build a sh -> uild a shi\n",
      "16 uild a shi -> ild a ship\n",
      "17 ild a ship -> ld a ship,\n",
      "18 ld a ship, -> d a ship, \n",
      "19 d a ship,  ->  a ship, d\n",
      "20  a ship, d -> a ship, do\n",
      "21 a ship, do ->  ship, don\n",
      "22  ship, don -> ship, don'\n",
      "23 ship, don' -> hip, don't\n",
      "24 hip, don't -> ip, don't \n",
      "25 ip, don't  -> p, don't d\n",
      "26 p, don't d -> , don't dr\n",
      "27 , don't dr ->  don't dru\n",
      "28  don't dru -> don't drum\n",
      "29 don't drum -> on't drum \n",
      "30 on't drum  -> n't drum u\n",
      "31 n't drum u -> 't drum up\n",
      "32 't drum up -> t drum up \n",
      "33 t drum up  ->  drum up p\n",
      "34  drum up p -> drum up pe\n",
      "35 drum up pe -> rum up peo\n",
      "36 rum up peo -> um up peop\n",
      "37 um up peop -> m up peopl\n",
      "38 m up peopl ->  up people\n",
      "39  up people -> up people \n",
      "40 up people  -> p people t\n",
      "41 p people t ->  people to\n",
      "42  people to -> people tog\n",
      "43 people tog -> eople toge\n",
      "44 eople toge -> ople toget\n",
      "45 ople toget -> ple togeth\n",
      "46 ple togeth -> le togethe\n",
      "47 le togethe -> e together\n",
      "48 e together ->  together \n",
      "49  together  -> together t\n",
      "50 together t -> ogether to\n",
      "51 ogether to -> gether to \n",
      "52 gether to  -> ether to c\n",
      "53 ether to c -> ther to co\n",
      "54 ther to co -> her to col\n",
      "55 her to col -> er to coll\n",
      "56 er to coll -> r to colle\n",
      "57 r to colle ->  to collec\n",
      "58  to collec -> to collect\n",
      "59 to collect -> o collect \n",
      "60 o collect  ->  collect w\n",
      "61  collect w -> collect wo\n",
      "62 collect wo -> ollect woo\n",
      "63 ollect woo -> llect wood\n",
      "64 llect wood -> lect wood \n",
      "65 lect wood  -> ect wood a\n",
      "66 ect wood a -> ct wood an\n",
      "67 ct wood an -> t wood and\n",
      "68 t wood and ->  wood and \n",
      "69  wood and  -> wood and d\n",
      "70 wood and d -> ood and do\n",
      "71 ood and do -> od and don\n",
      "72 od and don -> d and don'\n",
      "73 d and don' ->  and don't\n",
      "74  and don't -> and don't \n",
      "75 and don't  -> nd don't a\n",
      "76 nd don't a -> d don't as\n",
      "77 d don't as ->  don't ass\n",
      "78  don't ass -> don't assi\n",
      "79 don't assi -> on't assig\n",
      "80 on't assig -> n't assign\n",
      "81 n't assign -> 't assign \n",
      "82 't assign  -> t assign t\n",
      "83 t assign t ->  assign th\n",
      "84  assign th -> assign the\n",
      "85 assign the -> ssign them\n",
      "86 ssign them -> sign them \n",
      "87 sign them  -> ign them t\n",
      "88 ign them t -> gn them ta\n",
      "89 gn them ta -> n them tas\n",
      "90 n them tas ->  them task\n",
      "91  them task -> them tasks\n",
      "92 them tasks -> hem tasks \n",
      "93 hem tasks  -> em tasks a\n",
      "94 em tasks a -> m tasks an\n",
      "95 m tasks an ->  tasks and\n",
      "96  tasks and -> tasks and \n",
      "97 tasks and  -> asks and w\n",
      "98 asks and w -> sks and wo\n",
      "99 sks and wo -> ks and wor\n",
      "100 ks and wor -> s and work\n",
      "101 s and work ->  and work,\n",
      "102  and work, -> and work, \n",
      "103 and work,  -> nd work, b\n",
      "104 nd work, b -> d work, bu\n",
      "105 d work, bu ->  work, but\n",
      "106  work, but -> work, but \n",
      "107 work, but  -> ork, but r\n",
      "108 ork, but r -> rk, but ra\n",
      "109 rk, but ra -> k, but rat\n",
      "110 k, but rat -> , but rath\n",
      "111 , but rath ->  but rathe\n",
      "112  but rathe -> but rather\n",
      "113 but rather -> ut rather \n",
      "114 ut rather  -> t rather t\n",
      "115 t rather t ->  rather te\n",
      "116  rather te -> rather tea\n",
      "117 rather tea -> ather teac\n",
      "118 ather teac -> ther teach\n",
      "119 ther teach -> her teach \n",
      "120 her teach  -> er teach t\n",
      "121 er teach t -> r teach th\n",
      "122 r teach th ->  teach the\n",
      "123  teach the -> teach them\n",
      "124 teach them -> each them \n",
      "125 each them  -> ach them t\n",
      "126 ach them t -> ch them to\n",
      "127 ch them to -> h them to \n",
      "128 h them to  ->  them to l\n",
      "129  them to l -> them to lo\n",
      "130 them to lo -> hem to lon\n",
      "131 hem to lon -> em to long\n",
      "132 em to long -> m to long \n",
      "133 m to long  ->  to long f\n",
      "134  to long f -> to long fo\n",
      "135 to long fo -> o long for\n",
      "136 o long for ->  long for \n",
      "137  long for  -> long for t\n",
      "138 long for t -> ong for th\n",
      "139 ong for th -> ng for the\n",
      "140 ng for the -> g for the \n",
      "141 g for the  ->  for the e\n",
      "142  for the e -> for the en\n",
      "143 for the en -> or the end\n",
      "144 or the end -> r the endl\n",
      "145 r the endl ->  the endle\n",
      "146  the endle -> the endles\n",
      "147 the endles -> he endless\n",
      "148 he endless -> e endless \n",
      "149 e endless  ->  endless i\n",
      "150  endless i -> endless im\n",
      "151 endless im -> ndless imm\n",
      "152 ndless imm -> dless imme\n",
      "153 dless imme -> less immen\n",
      "154 less immen -> ess immens\n",
      "155 ess immens -> ss immensi\n",
      "156 ss immensi -> s immensit\n",
      "157 s immensit ->  immensity\n",
      "158  immensity -> immensity \n",
      "159 immensity  -> mmensity o\n",
      "160 mmensity o -> mensity of\n",
      "161 mensity of -> ensity of \n",
      "162 ensity of  -> nsity of t\n",
      "163 nsity of t -> sity of th\n",
      "164 sity of th -> ity of the\n",
      "165 ity of the -> ty of the \n",
      "166 ty of the  -> y of the s\n",
      "167 y of the s ->  of the se\n",
      "168  of the se -> of the sea\n",
      "169 of the sea -> f the sea.\n"
     ]
    }
   ],
   "source": [
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(sentence) - sequence_length): # 문장의 처음부터, 마지막 10개 단어 전까지\n",
    "    x_str = sentence[i : i+sequence_length]\n",
    "    y_str = sentence[i+1 : i+sequence_length+1] # y_label은 x_data의 하나 뒤\n",
    "    print(i, x_str, '->', y_str)\n",
    "    \n",
    "    x = [char_dic[c] for c in x_str]\n",
    "    y = [char_dic[c] for c in y_str]\n",
    "    \n",
    "    dataX.append(x)\n",
    "    dataY.append(y)\n",
    "    \n",
    "X = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "\n",
    "X_one_hot = tf.one_hot(X, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"one_hot_3:0\", shape=(?, 10, 25), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(X_one_hot) # batch : 주는대로 / sequence_length = 10, input_dimension = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[24, 15, 3, 18, 1, 22, 3, 8, 11, 13],\n",
       " [15, 3, 18, 1, 22, 3, 8, 11, 13, 9],\n",
       " [3, 18, 1, 22, 3, 8, 11, 13, 9, 3],\n",
       " [18, 1, 22, 3, 8, 11, 13, 9, 3, 9],\n",
       " [1, 22, 3, 8, 11, 13, 9, 3, 9, 1],\n",
       " [22, 3, 8, 11, 13, 9, 3, 9, 1, 3],\n",
       " [3, 8, 11, 13, 9, 3, 9, 1, 3, 21],\n",
       " [8, 11, 13, 9, 3, 9, 1, 3, 21, 22],\n",
       " [11, 13, 9, 3, 9, 1, 3, 21, 22, 24],\n",
       " [13, 9, 3, 9, 1, 3, 21, 22, 24, 6],\n",
       " [9, 3, 9, 1, 3, 21, 22, 24, 6, 16],\n",
       " [3, 9, 1, 3, 21, 22, 24, 6, 16, 3],\n",
       " [9, 1, 3, 21, 22, 24, 6, 16, 3, 11],\n",
       " [1, 3, 21, 22, 24, 6, 16, 3, 11, 3],\n",
       " [3, 21, 22, 24, 6, 16, 3, 11, 3, 7],\n",
       " [21, 22, 24, 6, 16, 3, 11, 3, 7, 5],\n",
       " [22, 24, 6, 16, 3, 11, 3, 7, 5, 24],\n",
       " [24, 6, 16, 3, 11, 3, 7, 5, 24, 17],\n",
       " [6, 16, 3, 11, 3, 7, 5, 24, 17, 20],\n",
       " [16, 3, 11, 3, 7, 5, 24, 17, 20, 3],\n",
       " [3, 11, 3, 7, 5, 24, 17, 20, 3, 16],\n",
       " [11, 3, 7, 5, 24, 17, 20, 3, 16, 1],\n",
       " [3, 7, 5, 24, 17, 20, 3, 16, 1, 13],\n",
       " [7, 5, 24, 17, 20, 3, 16, 1, 13, 14],\n",
       " [5, 24, 17, 20, 3, 16, 1, 13, 14, 9],\n",
       " [24, 17, 20, 3, 16, 1, 13, 14, 9, 3],\n",
       " [17, 20, 3, 16, 1, 13, 14, 9, 3, 16],\n",
       " [20, 3, 16, 1, 13, 14, 9, 3, 16, 2],\n",
       " [3, 16, 1, 13, 14, 9, 3, 16, 2, 22],\n",
       " [16, 1, 13, 14, 9, 3, 16, 2, 22, 19],\n",
       " [1, 13, 14, 9, 3, 16, 2, 22, 19, 3],\n",
       " [13, 14, 9, 3, 16, 2, 22, 19, 3, 22],\n",
       " [14, 9, 3, 16, 2, 22, 19, 3, 22, 17],\n",
       " [9, 3, 16, 2, 22, 19, 3, 22, 17, 3],\n",
       " [3, 16, 2, 22, 19, 3, 22, 17, 3, 17],\n",
       " [16, 2, 22, 19, 3, 22, 17, 3, 17, 23],\n",
       " [2, 22, 19, 3, 22, 17, 3, 17, 23, 1],\n",
       " [22, 19, 3, 22, 17, 3, 17, 23, 1, 17],\n",
       " [19, 3, 22, 17, 3, 17, 23, 1, 17, 6],\n",
       " [3, 22, 17, 3, 17, 23, 1, 17, 6, 23],\n",
       " [22, 17, 3, 17, 23, 1, 17, 6, 23, 3],\n",
       " [17, 3, 17, 23, 1, 17, 6, 23, 3, 9],\n",
       " [3, 17, 23, 1, 17, 6, 23, 3, 9, 1],\n",
       " [17, 23, 1, 17, 6, 23, 3, 9, 1, 12],\n",
       " [23, 1, 17, 6, 23, 3, 9, 1, 12, 23],\n",
       " [1, 17, 6, 23, 3, 9, 1, 12, 23, 9],\n",
       " [17, 6, 23, 3, 9, 1, 12, 23, 9, 5],\n",
       " [6, 23, 3, 9, 1, 12, 23, 9, 5, 23],\n",
       " [23, 3, 9, 1, 12, 23, 9, 5, 23, 2],\n",
       " [3, 9, 1, 12, 23, 9, 5, 23, 2, 3],\n",
       " [9, 1, 12, 23, 9, 5, 23, 2, 3, 9],\n",
       " [1, 12, 23, 9, 5, 23, 2, 3, 9, 1],\n",
       " [12, 23, 9, 5, 23, 2, 3, 9, 1, 3],\n",
       " [23, 9, 5, 23, 2, 3, 9, 1, 3, 4],\n",
       " [9, 5, 23, 2, 3, 9, 1, 3, 4, 1],\n",
       " [5, 23, 2, 3, 9, 1, 3, 4, 1, 6],\n",
       " [23, 2, 3, 9, 1, 3, 4, 1, 6, 6],\n",
       " [2, 3, 9, 1, 3, 4, 1, 6, 6, 23],\n",
       " [3, 9, 1, 3, 4, 1, 6, 6, 23, 4],\n",
       " [9, 1, 3, 4, 1, 6, 6, 23, 4, 9],\n",
       " [1, 3, 4, 1, 6, 6, 23, 4, 9, 3],\n",
       " [3, 4, 1, 6, 6, 23, 4, 9, 3, 8],\n",
       " [4, 1, 6, 6, 23, 4, 9, 3, 8, 1],\n",
       " [1, 6, 6, 23, 4, 9, 3, 8, 1, 1],\n",
       " [6, 6, 23, 4, 9, 3, 8, 1, 1, 16],\n",
       " [6, 23, 4, 9, 3, 8, 1, 1, 16, 3],\n",
       " [23, 4, 9, 3, 8, 1, 1, 16, 3, 11],\n",
       " [4, 9, 3, 8, 1, 1, 16, 3, 11, 13],\n",
       " [9, 3, 8, 1, 1, 16, 3, 11, 13, 16],\n",
       " [3, 8, 1, 1, 16, 3, 11, 13, 16, 3],\n",
       " [8, 1, 1, 16, 3, 11, 13, 16, 3, 16],\n",
       " [1, 1, 16, 3, 11, 13, 16, 3, 16, 1],\n",
       " [1, 16, 3, 11, 13, 16, 3, 16, 1, 13],\n",
       " [16, 3, 11, 13, 16, 3, 16, 1, 13, 14],\n",
       " [3, 11, 13, 16, 3, 16, 1, 13, 14, 9],\n",
       " [11, 13, 16, 3, 16, 1, 13, 14, 9, 3],\n",
       " [13, 16, 3, 16, 1, 13, 14, 9, 3, 11],\n",
       " [16, 3, 16, 1, 13, 14, 9, 3, 11, 7],\n",
       " [3, 16, 1, 13, 14, 9, 3, 11, 7, 7],\n",
       " [16, 1, 13, 14, 9, 3, 11, 7, 7, 24],\n",
       " [1, 13, 14, 9, 3, 11, 7, 7, 24, 12],\n",
       " [13, 14, 9, 3, 11, 7, 7, 24, 12, 13],\n",
       " [14, 9, 3, 11, 7, 7, 24, 12, 13, 3],\n",
       " [9, 3, 11, 7, 7, 24, 12, 13, 3, 9],\n",
       " [3, 11, 7, 7, 24, 12, 13, 3, 9, 5],\n",
       " [11, 7, 7, 24, 12, 13, 3, 9, 5, 23],\n",
       " [7, 7, 24, 12, 13, 3, 9, 5, 23, 19],\n",
       " [7, 24, 12, 13, 3, 9, 5, 23, 19, 3],\n",
       " [24, 12, 13, 3, 9, 5, 23, 19, 3, 9],\n",
       " [12, 13, 3, 9, 5, 23, 19, 3, 9, 11],\n",
       " [13, 3, 9, 5, 23, 19, 3, 9, 11, 7],\n",
       " [3, 9, 5, 23, 19, 3, 9, 11, 7, 0],\n",
       " [9, 5, 23, 19, 3, 9, 11, 7, 0, 7],\n",
       " [5, 23, 19, 3, 9, 11, 7, 0, 7, 3],\n",
       " [23, 19, 3, 9, 11, 7, 0, 7, 3, 11],\n",
       " [19, 3, 9, 11, 7, 0, 7, 3, 11, 13],\n",
       " [3, 9, 11, 7, 0, 7, 3, 11, 13, 16],\n",
       " [9, 11, 7, 0, 7, 3, 11, 13, 16, 3],\n",
       " [11, 7, 0, 7, 3, 11, 13, 16, 3, 8],\n",
       " [7, 0, 7, 3, 11, 13, 16, 3, 8, 1],\n",
       " [0, 7, 3, 11, 13, 16, 3, 8, 1, 2],\n",
       " [7, 3, 11, 13, 16, 3, 8, 1, 2, 0],\n",
       " [3, 11, 13, 16, 3, 8, 1, 2, 0, 20],\n",
       " [11, 13, 16, 3, 8, 1, 2, 0, 20, 3],\n",
       " [13, 16, 3, 8, 1, 2, 0, 20, 3, 21],\n",
       " [16, 3, 8, 1, 2, 0, 20, 3, 21, 22],\n",
       " [3, 8, 1, 2, 0, 20, 3, 21, 22, 9],\n",
       " [8, 1, 2, 0, 20, 3, 21, 22, 9, 3],\n",
       " [1, 2, 0, 20, 3, 21, 22, 9, 3, 2],\n",
       " [2, 0, 20, 3, 21, 22, 9, 3, 2, 11],\n",
       " [0, 20, 3, 21, 22, 9, 3, 2, 11, 9],\n",
       " [20, 3, 21, 22, 9, 3, 2, 11, 9, 5],\n",
       " [3, 21, 22, 9, 3, 2, 11, 9, 5, 23],\n",
       " [21, 22, 9, 3, 2, 11, 9, 5, 23, 2],\n",
       " [22, 9, 3, 2, 11, 9, 5, 23, 2, 3],\n",
       " [9, 3, 2, 11, 9, 5, 23, 2, 3, 9],\n",
       " [3, 2, 11, 9, 5, 23, 2, 3, 9, 23],\n",
       " [2, 11, 9, 5, 23, 2, 3, 9, 23, 11],\n",
       " [11, 9, 5, 23, 2, 3, 9, 23, 11, 4],\n",
       " [9, 5, 23, 2, 3, 9, 23, 11, 4, 5],\n",
       " [5, 23, 2, 3, 9, 23, 11, 4, 5, 3],\n",
       " [23, 2, 3, 9, 23, 11, 4, 5, 3, 9],\n",
       " [2, 3, 9, 23, 11, 4, 5, 3, 9, 5],\n",
       " [3, 9, 23, 11, 4, 5, 3, 9, 5, 23],\n",
       " [9, 23, 11, 4, 5, 3, 9, 5, 23, 19],\n",
       " [23, 11, 4, 5, 3, 9, 5, 23, 19, 3],\n",
       " [11, 4, 5, 3, 9, 5, 23, 19, 3, 9],\n",
       " [4, 5, 3, 9, 5, 23, 19, 3, 9, 1],\n",
       " [5, 3, 9, 5, 23, 19, 3, 9, 1, 3],\n",
       " [3, 9, 5, 23, 19, 3, 9, 1, 3, 6],\n",
       " [9, 5, 23, 19, 3, 9, 1, 3, 6, 1],\n",
       " [5, 23, 19, 3, 9, 1, 3, 6, 1, 13],\n",
       " [23, 19, 3, 9, 1, 3, 6, 1, 13, 12],\n",
       " [19, 3, 9, 1, 3, 6, 1, 13, 12, 3],\n",
       " [3, 9, 1, 3, 6, 1, 13, 12, 3, 15],\n",
       " [9, 1, 3, 6, 1, 13, 12, 3, 15, 1],\n",
       " [1, 3, 6, 1, 13, 12, 3, 15, 1, 2],\n",
       " [3, 6, 1, 13, 12, 3, 15, 1, 2, 3],\n",
       " [6, 1, 13, 12, 3, 15, 1, 2, 3, 9],\n",
       " [1, 13, 12, 3, 15, 1, 2, 3, 9, 5],\n",
       " [13, 12, 3, 15, 1, 2, 3, 9, 5, 23],\n",
       " [12, 3, 15, 1, 2, 3, 9, 5, 23, 3],\n",
       " [3, 15, 1, 2, 3, 9, 5, 23, 3, 23],\n",
       " [15, 1, 2, 3, 9, 5, 23, 3, 23, 13],\n",
       " [1, 2, 3, 9, 5, 23, 3, 23, 13, 16],\n",
       " [2, 3, 9, 5, 23, 3, 23, 13, 16, 6],\n",
       " [3, 9, 5, 23, 3, 23, 13, 16, 6, 23],\n",
       " [9, 5, 23, 3, 23, 13, 16, 6, 23, 7],\n",
       " [5, 23, 3, 23, 13, 16, 6, 23, 7, 7],\n",
       " [23, 3, 23, 13, 16, 6, 23, 7, 7, 3],\n",
       " [3, 23, 13, 16, 6, 23, 7, 7, 3, 24],\n",
       " [23, 13, 16, 6, 23, 7, 7, 3, 24, 19],\n",
       " [13, 16, 6, 23, 7, 7, 3, 24, 19, 19],\n",
       " [16, 6, 23, 7, 7, 3, 24, 19, 19, 23],\n",
       " [6, 23, 7, 7, 3, 24, 19, 19, 23, 13],\n",
       " [23, 7, 7, 3, 24, 19, 19, 23, 13, 7],\n",
       " [7, 7, 3, 24, 19, 19, 23, 13, 7, 24],\n",
       " [7, 3, 24, 19, 19, 23, 13, 7, 24, 9],\n",
       " [3, 24, 19, 19, 23, 13, 7, 24, 9, 18],\n",
       " [24, 19, 19, 23, 13, 7, 24, 9, 18, 3],\n",
       " [19, 19, 23, 13, 7, 24, 9, 18, 3, 1],\n",
       " [19, 23, 13, 7, 24, 9, 18, 3, 1, 15],\n",
       " [23, 13, 7, 24, 9, 18, 3, 1, 15, 3],\n",
       " [13, 7, 24, 9, 18, 3, 1, 15, 3, 9],\n",
       " [7, 24, 9, 18, 3, 1, 15, 3, 9, 5],\n",
       " [24, 9, 18, 3, 1, 15, 3, 9, 5, 23],\n",
       " [9, 18, 3, 1, 15, 3, 9, 5, 23, 3],\n",
       " [18, 3, 1, 15, 3, 9, 5, 23, 3, 7],\n",
       " [3, 1, 15, 3, 9, 5, 23, 3, 7, 23],\n",
       " [1, 15, 3, 9, 5, 23, 3, 7, 23, 11]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = len(dataX)\n",
    "dataX # batch 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기까지는 1 layer RNN과 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적인 1 layer LSTM cell을 만든 뒤에, 이를 MultiRNNCell로 쌓아야 한다.\n",
    "\n",
    "(기본 MultiLSTMCell과 같은 모듈이 존재하지 않는다.)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell():\n",
    "    cell = rnn.BasicLSTMCell(hidden_size, state_is_tuple=True)\n",
    "    return cell\n",
    "\n",
    "multi_cells = rnn.MultiRNNCell([lstm_cell() for _ in range(5)], state_is_tuple=True)\n",
    "\n",
    "initial_state = multi_cells.zero_state(batch_size, tf.float32)\n",
    "with tf.variable_scope('third'):\n",
    "    outputs, _states = tf.nn.dynamic_rnn(multi_cells, X_one_hot, initial_state = initial_state, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight, Loss, Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = tf.ones([batch_size, sequence_length])\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits = outputs, targets = Y, weights=weights)\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.train.AdamOptimizer(learning_rate = 0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 cnnnnnnnnn 3.21899\n",
      "0 10 ,,,iiiiiii 3.21899\n",
      "0 20 ffyyyyyfff 3.21899\n",
      "0 30 dymyllllyy 3.21899\n",
      "0 40 .....yyyyy 3.21899\n",
      "0 50 ,cwwnnn''' 3.21899\n",
      "0 60 dyyyyyyyyy 3.21899\n",
      "0 70 gg'mmmmmmm 3.21899\n",
      "0 80 dymyllllll 3.21899\n",
      "0 90    rrtuuuu 3.21899\n",
      "0 100 '''''yyyyy 3.21899\n",
      "0 110 '''''''''' 3.21899\n",
      "0 120 fffffffyyy 3.21899\n",
      "0 130 ,,gggggfff 3.21899\n",
      "0 140     rrrttn 3.21899\n",
      "0 150 ffffffyyyy 3.21899\n",
      "0 160 ffffffffff 3.21899\n",
      "100 0  t   t tt  2.89676\n",
      "100 10  t   t tt  2.89676\n",
      "100 20  t   t tt  2.89676\n",
      "100 30  t   t tt  2.89676\n",
      "100 40  t   t tt  2.89676\n",
      "100 50  t   t tt  2.89676\n",
      "100 60  t   t tt  2.89676\n",
      "100 70  t   t tt  2.89676\n",
      "100 80  t   t tt  2.89676\n",
      "100 90  t t t tt  2.89676\n",
      "100 100  t   t tt  2.89676\n",
      "100 110  t   t tt  2.89676\n",
      "100 120  t   t tt  2.89676\n",
      "100 130  t   t tt  2.89676\n",
      "100 140  t t t tt  2.89676\n",
      "100 150  t   t tt  2.89676\n",
      "100 160  t   t tt  2.89676\n",
      "200 0  ttt t t   2.89659\n",
      "200 10  tt   t    2.89659\n",
      "200 20  tt   t    2.89659\n",
      "200 30  tt   t    2.89659\n",
      "200 40  tt  t t   2.89659\n",
      "200 50  tt   t    2.89659\n",
      "200 60  tt   t    2.89659\n",
      "200 70  tt   t    2.89659\n",
      "200 80  tt   t    2.89659\n",
      "200 90  tt   t    2.89659\n",
      "200 100  tt   t    2.89659\n",
      "200 110  tt   t    2.89659\n",
      "200 120  tt   t    2.89659\n",
      "200 130  tt   t    2.89659\n",
      "200 140  tt   t    2.89659\n",
      "200 150  tt   t    2.89659\n",
      "200 160  tt   t    2.89659\n",
      "300 0 otttt  t   2.78098\n",
      "300 10 ottt tt    2.78098\n",
      "300 20 ott t t    2.78098\n",
      "300 30 ottt t  t  2.78098\n",
      "300 40 ottt   tt  2.78098\n",
      "300 50 ottt    t  2.78098\n",
      "300 60 ottt  ttt  2.78098\n",
      "300 70 otttt      2.78098\n",
      "300 80 ottt t tt  2.78098\n",
      "300 90 ottt  t    2.78098\n",
      "300 100  tt    t   2.78098\n",
      "300 110  ttt   tt  2.78098\n",
      "300 120 ottt       2.78098\n",
      "300 130 ottt tttt  2.78098\n",
      "300 140 ott   ttt  2.78098\n",
      "300 150 ottt   tt  2.78098\n",
      "300 160 otttttt    2.78098\n",
      "400 0 ottttt  t  2.73667\n",
      "400 10 nttt   tt  2.73667\n",
      "400 20 ottt       2.73667\n",
      "400 30 nttt   tt  2.73667\n",
      "400 40 ntt        2.73667\n",
      "400 50 ntt t t t  2.73667\n",
      "400 60 ntt   t t  2.73667\n",
      "400 70 ott  t  t  2.73667\n",
      "400 80 nttt   t   2.73667\n",
      "400 90 nttttt     2.73667\n",
      "400 100 nttt t     2.73667\n",
      "400 110 nttt   t   2.73667\n",
      "400 120 ott        2.73667\n",
      "400 130 nttt       2.73667\n",
      "400 140 nttt  t    2.73667\n",
      "400 150 ottt  t t  2.73667\n",
      "400 160 ntttt      2.73667\n",
      "500 0 tttt t  t  2.65617\n",
      "500 10 ntt    t   2.65617\n",
      "500 20  ttt   t   2.65617\n",
      "500 30 nttttt t   2.65617\n",
      "500 40 ntt  t et  2.65617\n",
      "500 50 ntt t t    2.65617\n",
      "500 60 ntt    t   2.65617\n",
      "500 70  ttttt tt  2.65617\n",
      "500 80 ntttt t    2.65617\n",
      "500 90 'ttttt t   2.65617\n",
      "500 100 s          2.65617\n",
      "500 110 s          2.65617\n",
      "500 120 ttt  ttt   2.65617\n",
      "500 130 ntt t   t  2.65617\n",
      "500 140 'ttttt t   2.65617\n",
      "500 150  ttt       2.65617\n",
      "500 160 ntt  tt t  2.65617\n",
      "600 0 e          2.59865\n",
      "600 10            2.59865\n",
      "600 20 t          2.59865\n",
      "600 30 n          2.59865\n",
      "600 40  tt        2.59865\n",
      "600 50            2.59865\n",
      "600 60 n          2.59865\n",
      "600 70 t e        2.59865\n",
      "600 80 n          2.59865\n",
      "600 90 st         2.59865\n",
      "600 100 s          2.59865\n",
      "600 110 s          2.59865\n",
      "600 120 e          2.59865\n",
      "600 130  t         2.59865\n",
      "600 140 s          2.59865\n",
      "600 150 t          2.59865\n",
      "600 160 n          2.59865\n",
      "700 0            2.57464\n",
      "700 10            2.57464\n",
      "700 20            2.57464\n",
      "700 30 n          2.57464\n",
      "700 40            2.57464\n",
      "700 50            2.57464\n",
      "700 60 n          2.57464\n",
      "700 70            2.57464\n",
      "700 80 n          2.57464\n",
      "700 90 s          2.57464\n",
      "700 100 s          2.57464\n",
      "700 110 s          2.57464\n",
      "700 120            2.57464\n",
      "700 130            2.57464\n",
      "700 140 s          2.57464\n",
      "700 150            2.57464\n",
      "700 160            2.57464\n",
      "800 0 t          2.56821\n",
      "800 10 o          2.56821\n",
      "800 20            2.56821\n",
      "800 30 o    o     2.56821\n",
      "800 40 o   o      2.56821\n",
      "800 50 o          2.56821\n",
      "800 60 o o        2.56821\n",
      "800 70   e        2.56821\n",
      "800 80 o          2.56821\n",
      "800 90 s          2.56821\n",
      "800 100 s     d    2.56821\n",
      "800 110 s          2.56821\n",
      "800 120 t          2.56821\n",
      "800 130 o          2.56821\n",
      "800 140 s          2.56821\n",
      "800 150            2.56821\n",
      "800 160 n          2.56821\n",
      "900 0 eoe        2.62598\n",
      "900 10 o o        2.62598\n",
      "900 20 e          2.62598\n",
      "900 30 ot         2.62598\n",
      "900 40 ot         2.62598\n",
      "900 50 o        o 2.62598\n",
      "900 60 oto        2.62598\n",
      "900 70 eoe      o 2.62598\n",
      "900 80 ot         2.62598\n",
      "900 90 st         2.62598\n",
      "900 100 o          2.62598\n",
      "900 110 o          2.62598\n",
      "900 120 e   o      2.62598\n",
      "900 130 ot   o  o  2.62598\n",
      "900 140 s          2.62598\n",
      "900 150 e          2.62598\n",
      "900 160 ot         2.62598\n",
      "1000 0 ttt  t  t  2.65514\n",
      "1000 10 ttt t   t  2.65514\n",
      "1000 20 ttt        2.65514\n",
      "1000 30 tttt t     2.65514\n",
      "1000 40 ttt  t tt  2.65514\n",
      "1000 50 tttt t  t  2.65514\n",
      "1000 60 tttt    t  2.65514\n",
      "1000 70 tt   t     2.65514\n",
      "1000 80 tttt  t    2.65514\n",
      "1000 90 s          2.65514\n",
      "1000 100 o          2.65514\n",
      "1000 110 o     e    2.65514\n",
      "1000 120 ttt  tt    2.65514\n",
      "1000 130 tttt t  t  2.65514\n",
      "1000 140 s          2.65514\n",
      "1000 150 ttt        2.65514\n",
      "1000 160 tttt       2.65514\n",
      "1100 0 ttt  t  t  2.62235\n",
      "1100 10 ttt        2.62235\n",
      "1100 20 tt         2.62235\n",
      "1100 30 ttt  t     2.62235\n",
      "1100 40 tttt t     2.62235\n",
      "1100 50 ttt  t     2.62235\n",
      "1100 60 ttt  t  t  2.62235\n",
      "1100 70 tt   t     2.62235\n",
      "1100 80 ttt        2.62235\n",
      "1100 90 s     tt   2.62235\n",
      "1100 100 o          2.62235\n",
      "1100 110 o          2.62235\n",
      "1100 120 tt  o      2.62235\n",
      "1100 130 ttt  t  t  2.62235\n",
      "1100 140 s          2.62235\n",
      "1100 150 tttttt     2.62235\n",
      "1100 160 tttt       2.62235\n",
      "1200 0 tt         2.61117\n",
      "1200 10 tttt       2.61117\n",
      "1200 20 tt         2.61117\n",
      "1200 30 tttt       2.61117\n",
      "1200 40  tt  t     2.61117\n",
      "1200 50 ttt  t   o 2.61117\n",
      "1200 60 ttt    t   2.61117\n",
      "1200 70 tttt t     2.61117\n",
      "1200 80 tttt       2.61117\n",
      "1200 90 tttttt     2.61117\n",
      "1200 100 o          2.61117\n",
      "1200 110 o          2.61117\n",
      "1200 120 tt         2.61117\n",
      "1200 130 tttt t     2.61117\n",
      "1200 140 ttttt tt   2.61117\n",
      "1200 150 tttttt     2.61117\n",
      "1200 160 ottt       2.61117\n",
      "1300 0 t  o       2.60318\n",
      "1300 10 ttt    t   2.60318\n",
      "1300 20 tn         2.60318\n",
      "1300 30 tttt t     2.60318\n",
      "1300 40 tttttt  t  2.60318\n",
      "1300 50 t          2.60318\n",
      "1300 60 tttttt     2.60318\n",
      "1300 70 ttttt      2.60318\n",
      "1300 80 tttt       2.60318\n",
      "1300 90 tt         2.60318\n",
      "1300 100 o          2.60318\n",
      "1300 110 o          2.60318\n",
      "1300 120 tt  o      2.60318\n",
      "1300 130 ttt  t     2.60318\n",
      "1300 140 ttttt      2.60318\n",
      "1300 150 tttttt     2.60318\n",
      "1300 160 tt         2.60318\n",
      "1400 0 t          2.59104\n",
      "1400 10 ttt        2.59104\n",
      "1400 20 tn         2.59104\n",
      "1400 30 tttt       2.59104\n",
      "1400 40 ttt  t     2.59104\n",
      "1400 50 t          2.59104\n",
      "1400 60 tttt t     2.59104\n",
      "1400 70 tttt       2.59104\n",
      "1400 80 tttt       2.59104\n",
      "1400 90 tt         2.59104\n",
      "1400 100 o          2.59104\n",
      "1400 110 o          2.59104\n",
      "1400 120 tt         2.59104\n",
      "1400 130 ttt        2.59104\n",
      "1400 140 tttt       2.59104\n",
      "1400 150 tndttt     2.59104\n",
      "1400 160 tt         2.59104\n",
      "1500 0 t  o       2.58932\n",
      "1500 10 t          2.58932\n",
      "1500 20 tn         2.58932\n",
      "1500 30 tttt       2.58932\n",
      "1500 40 ttt        2.58932\n",
      "1500 50 t          2.58932\n",
      "1500 60 tttt t     2.58932\n",
      "1500 70 tttt       2.58932\n",
      "1500 80 tttt       2.58932\n",
      "1500 90 tt         2.58932\n",
      "1500 100 o          2.58932\n",
      "1500 110 ot      t  2.58932\n",
      "1500 120 tt         2.58932\n",
      "1500 130 ttt  t     2.58932\n",
      "1500 140 tt         2.58932\n",
      "1500 150 tttttt     2.58932\n",
      "1500 160 tt         2.58932\n",
      "1600 0 t          2.58583\n",
      "1600 10 t          2.58583\n",
      "1600 20 an         2.58583\n",
      "1600 30 tttt       2.58583\n",
      "1600 40 ttt  t  t  2.58583\n",
      "1600 50 t          2.58583\n",
      "1600 60 tttt t     2.58583\n",
      "1600 70 tttt       2.58583\n",
      "1600 80 tttt       2.58583\n",
      "1600 90 tt         2.58583\n",
      "1600 100 s          2.58583\n",
      "1600 110 st         2.58583\n",
      "1600 120 tt         2.58583\n",
      "1600 130 tt   t     2.58583\n",
      "1600 140 tt         2.58583\n",
      "1600 150 andtet     2.58583\n",
      "1600 160 ot         2.58583\n",
      "1700 0 tn o       2.5986\n",
      "1700 10 t o        2.5986\n",
      "1700 20 an         2.5986\n",
      "1700 30 ttt        2.5986\n",
      "1700 40 t          2.5986\n",
      "1700 50 t          2.5986\n",
      "1700 60 tt e       2.5986\n",
      "1700 70 tt t     o 2.5986\n",
      "1700 80 ttt        2.5986\n",
      "1700 90 t          2.5986\n",
      "1700 100 s  n       2.5986\n",
      "1700 110 s          2.5986\n",
      "1700 120 tt  o      2.5986\n",
      "1700 130 t          2.5986\n",
      "1700 140 t          2.5986\n",
      "1700 150 and e      2.5986\n",
      "1700 160 ot         2.5986\n",
      "1800 0 t          2.62636\n",
      "1800 10 t          2.62636\n",
      "1800 20 an  e      2.62636\n",
      "1800 30 o          2.62636\n",
      "1800 40 t          2.62636\n",
      "1800 50 t    e     2.62636\n",
      "1800 60 o          2.62636\n",
      "1800 70 tt         2.62636\n",
      "1800 80 o          2.62636\n",
      "1800 90 t          2.62636\n",
      "1800 100 s          2.62636\n",
      "1800 110 s          2.62636\n",
      "1800 120 tt         2.62636\n",
      "1800 130 t          2.62636\n",
      "1800 140 t          2.62636\n",
      "1800 150 and e      2.62636\n",
      "1800 160 t          2.62636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 0 tn oeo     2.61787\n",
      "1900 10 t          2.61787\n",
      "1900 20 tndn   o   2.61787\n",
      "1900 30 t          2.61787\n",
      "1900 40 ttt  e     2.61787\n",
      "1900 50 t e  e   o 2.61787\n",
      "1900 60 t    e     2.61787\n",
      "1900 70 toe  n     2.61787\n",
      "1900 80 t          2.61787\n",
      "1900 90 tt         2.61787\n",
      "1900 100 t  ndn on  2.61787\n",
      "1900 110 t          2.61787\n",
      "1900 120 t   o      2.61787\n",
      "1900 130 t          2.61787\n",
      "1900 140 t          2.61787\n",
      "1900 150 tnd        2.61787\n",
      "1900 160 tt         2.61787\n",
      "2000 0 t  o       2.60468\n",
      "2000 10 t o        2.60468\n",
      "2000 20 tn n   o o 2.60468\n",
      "2000 30 t  o o     2.60468\n",
      "2000 40 t    e     2.60468\n",
      "2000 50 t        o 2.60468\n",
      "2000 60 t          2.60468\n",
      "2000 70 tooe     o 2.60468\n",
      "2000 80 t  o       2.60468\n",
      "2000 90 tt         2.60468\n",
      "2000 100 t  ndn o   2.60468\n",
      "2000 110 t    o     2.60468\n",
      "2000 120 tt  o      2.60468\n",
      "2000 130 t          2.60468\n",
      "2000 140 t t        2.60468\n",
      "2000 150 tnd        2.60468\n",
      "2000 160 tt         2.60468\n",
      "2100 0 tn o       2.5857\n",
      "2100 10 t o        2.5857\n",
      "2100 20 tn n   o   2.5857\n",
      "2100 30 t          2.5857\n",
      "2100 40 t          2.5857\n",
      "2100 50 t        o 2.5857\n",
      "2100 60 t          2.5857\n",
      "2100 70 tt       o 2.5857\n",
      "2100 80 t        n 2.5857\n",
      "2100 90        o   2.5857\n",
      "2100 100 t  ndnd n  2.5857\n",
      "2100 110 tt   o   o 2.5857\n",
      "2100 120 t   o      2.5857\n",
      "2100 130 t          2.5857\n",
      "2100 140            2.5857\n",
      "2100 150 tn         2.5857\n",
      "2100 160 s          2.5857\n",
      "2200 0 tn oe  an  2.56974\n",
      "2200 10 t o        2.56974\n",
      "2200 20 tn n   n   2.56974\n",
      "2200 30 tt         2.56974\n",
      "2200 40 t          2.56974\n",
      "2200 50 t   o    o 2.56974\n",
      "2200 60 t          2.56974\n",
      "2200 70 toa      o 2.56974\n",
      "2200 80 tt   n     2.56974\n",
      "2200 90 tt     o   2.56974\n",
      "2200 100 t  n n     2.56974\n",
      "2200 110 t    o     2.56974\n",
      "2200 120 t   o      2.56974\n",
      "2200 130 t    o     2.56974\n",
      "2200 140 t      o   2.56974\n",
      "2200 150 tn  en     2.56974\n",
      "2200 160 t          2.56974\n",
      "2300 0 tn o   a   2.56007\n",
      "2300 10 t          2.56007\n",
      "2300 20 tn         2.56007\n",
      "2300 30 tt         2.56007\n",
      "2300 40 t          2.56007\n",
      "2300 50 t   o    o 2.56007\n",
      "2300 60 t          2.56007\n",
      "2300 70 t        o 2.56007\n",
      "2300 80 tt       n 2.56007\n",
      "2300 90 t      o   2.56007\n",
      "2300 100 tn ndndon  2.56007\n",
      "2300 110 t          2.56007\n",
      "2300 120 tt  o      2.56007\n",
      "2300 130 t    o     2.56007\n",
      "2300 140 t  o   o   2.56007\n",
      "2300 150 tn   n     2.56007\n",
      "2300 160 t          2.56007\n",
      "2400 0 tn o   an  2.59478\n",
      "2400 10 o      o   2.59478\n",
      "2400 20 tn n   ndo 2.59478\n",
      "2400 30 tt oeo     2.59478\n",
      "2400 40 t  a    n  2.59478\n",
      "2400 50 o e      o 2.59478\n",
      "2400 60 t   ttn    2.59478\n",
      "2400 70 ttaadndn o 2.59478\n",
      "2400 80 tt oen   n 2.59478\n",
      "2400 90 t      o   2.59478\n",
      "2400 100 tn ndndon  2.59478\n",
      "2400 110 tn   o     2.59478\n",
      "2400 120 tt  o      2.59478\n",
      "2400 130 o       o  2.59478\n",
      "2400 140 t  o   o   2.59478\n",
      "2400 150 tn   n     2.59478\n",
      "2400 160 t          2.59478\n",
      "2500 0 tn oe aand 2.56098\n",
      "2500 10 tdo teetoa 2.56098\n",
      "2500 20 tn n  endo 2.56098\n",
      "2500 30 t  oe n    2.56098\n",
      "2500 40 t  toe ete 2.56098\n",
      "2500 50 t e oe   o 2.56098\n",
      "2500 60 t oe entnd 2.56098\n",
      "2500 70 toa andndo 2.56098\n",
      "2500 80 t  oen   n 2.56098\n",
      "2500 90 t oe   o   2.56098\n",
      "2500 100 t  ndndon  2.56098\n",
      "2500 110 t   to a   2.56098\n",
      "2500 120 t  to    t 2.56098\n",
      "2500 130 te  to  on 2.56098\n",
      "2500 140 t  o a oe  2.56098\n",
      "2500 150 tnd en     2.56098\n",
      "2500 160 ttnd en e  2.56098\n",
      "2600 0 tndoa aan  2.53676\n",
      "2600 10 tdo   tto  2.53676\n",
      "2600 20 tn n   ndo 2.53676\n",
      "2600 30 t  oe      2.53676\n",
      "2600 40 t tt etttt 2.53676\n",
      "2600 50 t e oe  to 2.53676\n",
      "2600 60 t oe en  t 2.53676\n",
      "2600 70 toaaandndo 2.53676\n",
      "2600 80 t  oen   n 2.53676\n",
      "2600 90 ttoe  to   2.53676\n",
      "2600 100 t  ndndo   2.53676\n",
      "2600 110 t    o     2.53676\n",
      "2600 120 t  to    t 2.53676\n",
      "2600 130 te  to  on 2.53676\n",
      "2600 140 t to   oe  2.53676\n",
      "2600 150 tnd en     2.53676\n",
      "2600 160 ttnd en eo 2.53676\n",
      "2700 0 tn oa aan  2.52163\n",
      "2700 10 tdo   tto  2.52163\n",
      "2700 20 tn n   ndo 2.52163\n",
      "2700 30 t  oao     2.52163\n",
      "2700 40   t oete t 2.52163\n",
      "2700 50 t e oe  to 2.52163\n",
      "2700 60 t oe en  t 2.52163\n",
      "2700 70 toaatndndo 2.52163\n",
      "2700 80 t  oan   n 2.52163\n",
      "2700 90 ttoe   o   2.52163\n",
      "2700 100 t  ndndo   2.52163\n",
      "2700 110 t    o a   2.52163\n",
      "2700 120 t  to    t 2.52163\n",
      "2700 130 te  to  on 2.52163\n",
      "2700 140 t to  toe  2.52163\n",
      "2700 150 tnd en     2.52163\n",
      "2700 160 stnd en e  2.52163\n",
      "2800 0 tn oa  an  2.55895\n",
      "2800 10 s o     o  2.55895\n",
      "2800 20 tn n   n o 2.55895\n",
      "2800 30 tetodoa    2.55895\n",
      "2800 40 t  toeteoa 2.55895\n",
      "2800 50 s eooe  to 2.55895\n",
      "2800 60 t od en    2.55895\n",
      "2800 70 tod tndndo 2.55895\n",
      "2800 80 tetodn   n 2.55895\n",
      "2800 90 t oe   o   2.55895\n",
      "2800 100 t  ndndo a 2.55895\n",
      "2800 110 t    o a   2.55895\n",
      "2800 120 t  to    t 2.55895\n",
      "2800 130 se   o  on 2.55895\n",
      "2800 140 t  on toe  2.55895\n",
      "2800 150 tn   n     2.55895\n",
      "2800 160 sen  en en 2.55895\n",
      "2900 0 tn odttan  2.53723\n",
      "2900 10   o     en 2.53723\n",
      "2900 20 tn n   n o 2.53723\n",
      "2900 30 te odo     2.53723\n",
      "2900 40 t  eoe t e 2.53723\n",
      "2900 50   e oe   o 2.53723\n",
      "2900 60 t od en    2.53723\n",
      "2900 70 toa andndo 2.53723\n",
      "2900 80 te odn   n 2.53723\n",
      "2900 90 ttod  to   2.53723\n",
      "2900 100 t  ndndo   2.53723\n",
      "2900 110 t    o a   2.53723\n",
      "2900 120 t   o   tt 2.53723\n",
      "2900 130  e  to  on 2.53723\n",
      "2900 140 ttto   oe  2.53723\n",
      "2900 150 tn aon     2.53723\n",
      "2900 160 tend en en 2.53723\n",
      "tn oe tand to    tn an n   n on  odnd   teteoe e eo e oe  to  o een  too aa   don todn   n   e  to    and do       o    e  to     oe  to  on   o   oe end en   a end e  en toe en  "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(3000):\n",
    "        l, _, results = sess.run([loss, train, outputs], feed_dict = {X : dataX, Y : dataY})\n",
    "        for j, result in enumerate(results):\n",
    "            index = np.argmax(result, axis=1)\n",
    "            if i%100 == 0:\n",
    "                if j%10 == 0:\n",
    "                    print(i, j, ''.join([char_set[t] for t in index]), l)\n",
    "                    \n",
    "    for j, result in enumerate(results):\n",
    "        index = np.argmax(result, axis=1)\n",
    "        if j is 0:\n",
    "            print(''.join([char_set[t] for t in index]), end='')\n",
    "        else:\n",
    "            print(char_set[index[-1]], end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 여전히 학습이 잘 되지 않는다. 왜 그런 것일까? ㅠㅠ\n",
    "\n",
    "해답은 **fully connected layer**를 사용하지 않았기 때문이다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Stacked RNN + Softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"if you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = (\"if you want to build a ship, don't drum up people together to \"\n",
    "           \"collect wood and don't assign them tasks and work, but rather \"\n",
    "           \"teach them to long for the endless immensity of the sea.\")\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어를 벡터화시키는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_set = list(set(sentence))\n",
    "char_dic = {w : i for i, w in enumerate(char_set)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hyper parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dim = len(char_set)\n",
    "hidden_size = len(char_set)\n",
    "num_classes = len(char_set)\n",
    "sequence_length = 10 # 문장이 너무 길어서, 순차적으로 10개씩 골라서 batch size를 늘리려고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### batch 만드는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 if you wan -> f you want\n",
      "1 f you want ->  you want \n",
      "2  you want  -> you want t\n",
      "3 you want t -> ou want to\n",
      "4 ou want to -> u want to \n",
      "5 u want to  ->  want to b\n",
      "6  want to b -> want to bu\n",
      "7 want to bu -> ant to bui\n",
      "8 ant to bui -> nt to buil\n",
      "9 nt to buil -> t to build\n",
      "10 t to build ->  to build \n",
      "11  to build  -> to build a\n",
      "12 to build a -> o build a \n",
      "13 o build a  ->  build a s\n",
      "14  build a s -> build a sh\n",
      "15 build a sh -> uild a shi\n",
      "16 uild a shi -> ild a ship\n",
      "17 ild a ship -> ld a ship,\n",
      "18 ld a ship, -> d a ship, \n",
      "19 d a ship,  ->  a ship, d\n",
      "20  a ship, d -> a ship, do\n",
      "21 a ship, do ->  ship, don\n",
      "22  ship, don -> ship, don'\n",
      "23 ship, don' -> hip, don't\n",
      "24 hip, don't -> ip, don't \n",
      "25 ip, don't  -> p, don't d\n",
      "26 p, don't d -> , don't dr\n",
      "27 , don't dr ->  don't dru\n",
      "28  don't dru -> don't drum\n",
      "29 don't drum -> on't drum \n",
      "30 on't drum  -> n't drum u\n",
      "31 n't drum u -> 't drum up\n",
      "32 't drum up -> t drum up \n",
      "33 t drum up  ->  drum up p\n",
      "34  drum up p -> drum up pe\n",
      "35 drum up pe -> rum up peo\n",
      "36 rum up peo -> um up peop\n",
      "37 um up peop -> m up peopl\n",
      "38 m up peopl ->  up people\n",
      "39  up people -> up people \n",
      "40 up people  -> p people t\n",
      "41 p people t ->  people to\n",
      "42  people to -> people tog\n",
      "43 people tog -> eople toge\n",
      "44 eople toge -> ople toget\n",
      "45 ople toget -> ple togeth\n",
      "46 ple togeth -> le togethe\n",
      "47 le togethe -> e together\n",
      "48 e together ->  together \n",
      "49  together  -> together t\n",
      "50 together t -> ogether to\n",
      "51 ogether to -> gether to \n",
      "52 gether to  -> ether to c\n",
      "53 ether to c -> ther to co\n",
      "54 ther to co -> her to col\n",
      "55 her to col -> er to coll\n",
      "56 er to coll -> r to colle\n",
      "57 r to colle ->  to collec\n",
      "58  to collec -> to collect\n",
      "59 to collect -> o collect \n",
      "60 o collect  ->  collect w\n",
      "61  collect w -> collect wo\n",
      "62 collect wo -> ollect woo\n",
      "63 ollect woo -> llect wood\n",
      "64 llect wood -> lect wood \n",
      "65 lect wood  -> ect wood a\n",
      "66 ect wood a -> ct wood an\n",
      "67 ct wood an -> t wood and\n",
      "68 t wood and ->  wood and \n",
      "69  wood and  -> wood and d\n",
      "70 wood and d -> ood and do\n",
      "71 ood and do -> od and don\n",
      "72 od and don -> d and don'\n",
      "73 d and don' ->  and don't\n",
      "74  and don't -> and don't \n",
      "75 and don't  -> nd don't a\n",
      "76 nd don't a -> d don't as\n",
      "77 d don't as ->  don't ass\n",
      "78  don't ass -> don't assi\n",
      "79 don't assi -> on't assig\n",
      "80 on't assig -> n't assign\n",
      "81 n't assign -> 't assign \n",
      "82 't assign  -> t assign t\n",
      "83 t assign t ->  assign th\n",
      "84  assign th -> assign the\n",
      "85 assign the -> ssign them\n",
      "86 ssign them -> sign them \n",
      "87 sign them  -> ign them t\n",
      "88 ign them t -> gn them ta\n",
      "89 gn them ta -> n them tas\n",
      "90 n them tas ->  them task\n",
      "91  them task -> them tasks\n",
      "92 them tasks -> hem tasks \n",
      "93 hem tasks  -> em tasks a\n",
      "94 em tasks a -> m tasks an\n",
      "95 m tasks an ->  tasks and\n",
      "96  tasks and -> tasks and \n",
      "97 tasks and  -> asks and w\n",
      "98 asks and w -> sks and wo\n",
      "99 sks and wo -> ks and wor\n",
      "100 ks and wor -> s and work\n",
      "101 s and work ->  and work,\n",
      "102  and work, -> and work, \n",
      "103 and work,  -> nd work, b\n",
      "104 nd work, b -> d work, bu\n",
      "105 d work, bu ->  work, but\n",
      "106  work, but -> work, but \n",
      "107 work, but  -> ork, but r\n",
      "108 ork, but r -> rk, but ra\n",
      "109 rk, but ra -> k, but rat\n",
      "110 k, but rat -> , but rath\n",
      "111 , but rath ->  but rathe\n",
      "112  but rathe -> but rather\n",
      "113 but rather -> ut rather \n",
      "114 ut rather  -> t rather t\n",
      "115 t rather t ->  rather te\n",
      "116  rather te -> rather tea\n",
      "117 rather tea -> ather teac\n",
      "118 ather teac -> ther teach\n",
      "119 ther teach -> her teach \n",
      "120 her teach  -> er teach t\n",
      "121 er teach t -> r teach th\n",
      "122 r teach th ->  teach the\n",
      "123  teach the -> teach them\n",
      "124 teach them -> each them \n",
      "125 each them  -> ach them t\n",
      "126 ach them t -> ch them to\n",
      "127 ch them to -> h them to \n",
      "128 h them to  ->  them to l\n",
      "129  them to l -> them to lo\n",
      "130 them to lo -> hem to lon\n",
      "131 hem to lon -> em to long\n",
      "132 em to long -> m to long \n",
      "133 m to long  ->  to long f\n",
      "134  to long f -> to long fo\n",
      "135 to long fo -> o long for\n",
      "136 o long for ->  long for \n",
      "137  long for  -> long for t\n",
      "138 long for t -> ong for th\n",
      "139 ong for th -> ng for the\n",
      "140 ng for the -> g for the \n",
      "141 g for the  ->  for the e\n",
      "142  for the e -> for the en\n",
      "143 for the en -> or the end\n",
      "144 or the end -> r the endl\n",
      "145 r the endl ->  the endle\n",
      "146  the endle -> the endles\n",
      "147 the endles -> he endless\n",
      "148 he endless -> e endless \n",
      "149 e endless  ->  endless i\n",
      "150  endless i -> endless im\n",
      "151 endless im -> ndless imm\n",
      "152 ndless imm -> dless imme\n",
      "153 dless imme -> less immen\n",
      "154 less immen -> ess immens\n",
      "155 ess immens -> ss immensi\n",
      "156 ss immensi -> s immensit\n",
      "157 s immensit ->  immensity\n",
      "158  immensity -> immensity \n",
      "159 immensity  -> mmensity o\n",
      "160 mmensity o -> mensity of\n",
      "161 mensity of -> ensity of \n",
      "162 ensity of  -> nsity of t\n",
      "163 nsity of t -> sity of th\n",
      "164 sity of th -> ity of the\n",
      "165 ity of the -> ty of the \n",
      "166 ty of the  -> y of the s\n",
      "167 y of the s ->  of the se\n",
      "168  of the se -> of the sea\n",
      "169 of the sea -> f the sea.\n"
     ]
    }
   ],
   "source": [
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(sentence) - sequence_length): # 문장의 처음부터, 마지막 10개 단어 전까지\n",
    "    x_str = sentence[i : i+sequence_length]\n",
    "    y_str = sentence[i+1 : i+sequence_length+1] # y_label은 x_data의 하나 뒤\n",
    "    print(i, x_str, '->', y_str)\n",
    "    \n",
    "    x = [char_dic[c] for c in x_str]\n",
    "    y = [char_dic[c] for c in y_str]\n",
    "    \n",
    "    dataX.append(x)\n",
    "    dataY.append(y)\n",
    "    \n",
    "X = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "\n",
    "X_one_hot = tf.one_hot(X, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"one_hot_4:0\", shape=(?, 10, 25), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(X_one_hot) # batch : 주는대로 / sequence_length = 10, input_dimension = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[24, 15, 3, 18, 1, 22, 3, 8, 11, 13],\n",
       " [15, 3, 18, 1, 22, 3, 8, 11, 13, 9],\n",
       " [3, 18, 1, 22, 3, 8, 11, 13, 9, 3],\n",
       " [18, 1, 22, 3, 8, 11, 13, 9, 3, 9],\n",
       " [1, 22, 3, 8, 11, 13, 9, 3, 9, 1],\n",
       " [22, 3, 8, 11, 13, 9, 3, 9, 1, 3],\n",
       " [3, 8, 11, 13, 9, 3, 9, 1, 3, 21],\n",
       " [8, 11, 13, 9, 3, 9, 1, 3, 21, 22],\n",
       " [11, 13, 9, 3, 9, 1, 3, 21, 22, 24],\n",
       " [13, 9, 3, 9, 1, 3, 21, 22, 24, 6],\n",
       " [9, 3, 9, 1, 3, 21, 22, 24, 6, 16],\n",
       " [3, 9, 1, 3, 21, 22, 24, 6, 16, 3],\n",
       " [9, 1, 3, 21, 22, 24, 6, 16, 3, 11],\n",
       " [1, 3, 21, 22, 24, 6, 16, 3, 11, 3],\n",
       " [3, 21, 22, 24, 6, 16, 3, 11, 3, 7],\n",
       " [21, 22, 24, 6, 16, 3, 11, 3, 7, 5],\n",
       " [22, 24, 6, 16, 3, 11, 3, 7, 5, 24],\n",
       " [24, 6, 16, 3, 11, 3, 7, 5, 24, 17],\n",
       " [6, 16, 3, 11, 3, 7, 5, 24, 17, 20],\n",
       " [16, 3, 11, 3, 7, 5, 24, 17, 20, 3],\n",
       " [3, 11, 3, 7, 5, 24, 17, 20, 3, 16],\n",
       " [11, 3, 7, 5, 24, 17, 20, 3, 16, 1],\n",
       " [3, 7, 5, 24, 17, 20, 3, 16, 1, 13],\n",
       " [7, 5, 24, 17, 20, 3, 16, 1, 13, 14],\n",
       " [5, 24, 17, 20, 3, 16, 1, 13, 14, 9],\n",
       " [24, 17, 20, 3, 16, 1, 13, 14, 9, 3],\n",
       " [17, 20, 3, 16, 1, 13, 14, 9, 3, 16],\n",
       " [20, 3, 16, 1, 13, 14, 9, 3, 16, 2],\n",
       " [3, 16, 1, 13, 14, 9, 3, 16, 2, 22],\n",
       " [16, 1, 13, 14, 9, 3, 16, 2, 22, 19],\n",
       " [1, 13, 14, 9, 3, 16, 2, 22, 19, 3],\n",
       " [13, 14, 9, 3, 16, 2, 22, 19, 3, 22],\n",
       " [14, 9, 3, 16, 2, 22, 19, 3, 22, 17],\n",
       " [9, 3, 16, 2, 22, 19, 3, 22, 17, 3],\n",
       " [3, 16, 2, 22, 19, 3, 22, 17, 3, 17],\n",
       " [16, 2, 22, 19, 3, 22, 17, 3, 17, 23],\n",
       " [2, 22, 19, 3, 22, 17, 3, 17, 23, 1],\n",
       " [22, 19, 3, 22, 17, 3, 17, 23, 1, 17],\n",
       " [19, 3, 22, 17, 3, 17, 23, 1, 17, 6],\n",
       " [3, 22, 17, 3, 17, 23, 1, 17, 6, 23],\n",
       " [22, 17, 3, 17, 23, 1, 17, 6, 23, 3],\n",
       " [17, 3, 17, 23, 1, 17, 6, 23, 3, 9],\n",
       " [3, 17, 23, 1, 17, 6, 23, 3, 9, 1],\n",
       " [17, 23, 1, 17, 6, 23, 3, 9, 1, 12],\n",
       " [23, 1, 17, 6, 23, 3, 9, 1, 12, 23],\n",
       " [1, 17, 6, 23, 3, 9, 1, 12, 23, 9],\n",
       " [17, 6, 23, 3, 9, 1, 12, 23, 9, 5],\n",
       " [6, 23, 3, 9, 1, 12, 23, 9, 5, 23],\n",
       " [23, 3, 9, 1, 12, 23, 9, 5, 23, 2],\n",
       " [3, 9, 1, 12, 23, 9, 5, 23, 2, 3],\n",
       " [9, 1, 12, 23, 9, 5, 23, 2, 3, 9],\n",
       " [1, 12, 23, 9, 5, 23, 2, 3, 9, 1],\n",
       " [12, 23, 9, 5, 23, 2, 3, 9, 1, 3],\n",
       " [23, 9, 5, 23, 2, 3, 9, 1, 3, 4],\n",
       " [9, 5, 23, 2, 3, 9, 1, 3, 4, 1],\n",
       " [5, 23, 2, 3, 9, 1, 3, 4, 1, 6],\n",
       " [23, 2, 3, 9, 1, 3, 4, 1, 6, 6],\n",
       " [2, 3, 9, 1, 3, 4, 1, 6, 6, 23],\n",
       " [3, 9, 1, 3, 4, 1, 6, 6, 23, 4],\n",
       " [9, 1, 3, 4, 1, 6, 6, 23, 4, 9],\n",
       " [1, 3, 4, 1, 6, 6, 23, 4, 9, 3],\n",
       " [3, 4, 1, 6, 6, 23, 4, 9, 3, 8],\n",
       " [4, 1, 6, 6, 23, 4, 9, 3, 8, 1],\n",
       " [1, 6, 6, 23, 4, 9, 3, 8, 1, 1],\n",
       " [6, 6, 23, 4, 9, 3, 8, 1, 1, 16],\n",
       " [6, 23, 4, 9, 3, 8, 1, 1, 16, 3],\n",
       " [23, 4, 9, 3, 8, 1, 1, 16, 3, 11],\n",
       " [4, 9, 3, 8, 1, 1, 16, 3, 11, 13],\n",
       " [9, 3, 8, 1, 1, 16, 3, 11, 13, 16],\n",
       " [3, 8, 1, 1, 16, 3, 11, 13, 16, 3],\n",
       " [8, 1, 1, 16, 3, 11, 13, 16, 3, 16],\n",
       " [1, 1, 16, 3, 11, 13, 16, 3, 16, 1],\n",
       " [1, 16, 3, 11, 13, 16, 3, 16, 1, 13],\n",
       " [16, 3, 11, 13, 16, 3, 16, 1, 13, 14],\n",
       " [3, 11, 13, 16, 3, 16, 1, 13, 14, 9],\n",
       " [11, 13, 16, 3, 16, 1, 13, 14, 9, 3],\n",
       " [13, 16, 3, 16, 1, 13, 14, 9, 3, 11],\n",
       " [16, 3, 16, 1, 13, 14, 9, 3, 11, 7],\n",
       " [3, 16, 1, 13, 14, 9, 3, 11, 7, 7],\n",
       " [16, 1, 13, 14, 9, 3, 11, 7, 7, 24],\n",
       " [1, 13, 14, 9, 3, 11, 7, 7, 24, 12],\n",
       " [13, 14, 9, 3, 11, 7, 7, 24, 12, 13],\n",
       " [14, 9, 3, 11, 7, 7, 24, 12, 13, 3],\n",
       " [9, 3, 11, 7, 7, 24, 12, 13, 3, 9],\n",
       " [3, 11, 7, 7, 24, 12, 13, 3, 9, 5],\n",
       " [11, 7, 7, 24, 12, 13, 3, 9, 5, 23],\n",
       " [7, 7, 24, 12, 13, 3, 9, 5, 23, 19],\n",
       " [7, 24, 12, 13, 3, 9, 5, 23, 19, 3],\n",
       " [24, 12, 13, 3, 9, 5, 23, 19, 3, 9],\n",
       " [12, 13, 3, 9, 5, 23, 19, 3, 9, 11],\n",
       " [13, 3, 9, 5, 23, 19, 3, 9, 11, 7],\n",
       " [3, 9, 5, 23, 19, 3, 9, 11, 7, 0],\n",
       " [9, 5, 23, 19, 3, 9, 11, 7, 0, 7],\n",
       " [5, 23, 19, 3, 9, 11, 7, 0, 7, 3],\n",
       " [23, 19, 3, 9, 11, 7, 0, 7, 3, 11],\n",
       " [19, 3, 9, 11, 7, 0, 7, 3, 11, 13],\n",
       " [3, 9, 11, 7, 0, 7, 3, 11, 13, 16],\n",
       " [9, 11, 7, 0, 7, 3, 11, 13, 16, 3],\n",
       " [11, 7, 0, 7, 3, 11, 13, 16, 3, 8],\n",
       " [7, 0, 7, 3, 11, 13, 16, 3, 8, 1],\n",
       " [0, 7, 3, 11, 13, 16, 3, 8, 1, 2],\n",
       " [7, 3, 11, 13, 16, 3, 8, 1, 2, 0],\n",
       " [3, 11, 13, 16, 3, 8, 1, 2, 0, 20],\n",
       " [11, 13, 16, 3, 8, 1, 2, 0, 20, 3],\n",
       " [13, 16, 3, 8, 1, 2, 0, 20, 3, 21],\n",
       " [16, 3, 8, 1, 2, 0, 20, 3, 21, 22],\n",
       " [3, 8, 1, 2, 0, 20, 3, 21, 22, 9],\n",
       " [8, 1, 2, 0, 20, 3, 21, 22, 9, 3],\n",
       " [1, 2, 0, 20, 3, 21, 22, 9, 3, 2],\n",
       " [2, 0, 20, 3, 21, 22, 9, 3, 2, 11],\n",
       " [0, 20, 3, 21, 22, 9, 3, 2, 11, 9],\n",
       " [20, 3, 21, 22, 9, 3, 2, 11, 9, 5],\n",
       " [3, 21, 22, 9, 3, 2, 11, 9, 5, 23],\n",
       " [21, 22, 9, 3, 2, 11, 9, 5, 23, 2],\n",
       " [22, 9, 3, 2, 11, 9, 5, 23, 2, 3],\n",
       " [9, 3, 2, 11, 9, 5, 23, 2, 3, 9],\n",
       " [3, 2, 11, 9, 5, 23, 2, 3, 9, 23],\n",
       " [2, 11, 9, 5, 23, 2, 3, 9, 23, 11],\n",
       " [11, 9, 5, 23, 2, 3, 9, 23, 11, 4],\n",
       " [9, 5, 23, 2, 3, 9, 23, 11, 4, 5],\n",
       " [5, 23, 2, 3, 9, 23, 11, 4, 5, 3],\n",
       " [23, 2, 3, 9, 23, 11, 4, 5, 3, 9],\n",
       " [2, 3, 9, 23, 11, 4, 5, 3, 9, 5],\n",
       " [3, 9, 23, 11, 4, 5, 3, 9, 5, 23],\n",
       " [9, 23, 11, 4, 5, 3, 9, 5, 23, 19],\n",
       " [23, 11, 4, 5, 3, 9, 5, 23, 19, 3],\n",
       " [11, 4, 5, 3, 9, 5, 23, 19, 3, 9],\n",
       " [4, 5, 3, 9, 5, 23, 19, 3, 9, 1],\n",
       " [5, 3, 9, 5, 23, 19, 3, 9, 1, 3],\n",
       " [3, 9, 5, 23, 19, 3, 9, 1, 3, 6],\n",
       " [9, 5, 23, 19, 3, 9, 1, 3, 6, 1],\n",
       " [5, 23, 19, 3, 9, 1, 3, 6, 1, 13],\n",
       " [23, 19, 3, 9, 1, 3, 6, 1, 13, 12],\n",
       " [19, 3, 9, 1, 3, 6, 1, 13, 12, 3],\n",
       " [3, 9, 1, 3, 6, 1, 13, 12, 3, 15],\n",
       " [9, 1, 3, 6, 1, 13, 12, 3, 15, 1],\n",
       " [1, 3, 6, 1, 13, 12, 3, 15, 1, 2],\n",
       " [3, 6, 1, 13, 12, 3, 15, 1, 2, 3],\n",
       " [6, 1, 13, 12, 3, 15, 1, 2, 3, 9],\n",
       " [1, 13, 12, 3, 15, 1, 2, 3, 9, 5],\n",
       " [13, 12, 3, 15, 1, 2, 3, 9, 5, 23],\n",
       " [12, 3, 15, 1, 2, 3, 9, 5, 23, 3],\n",
       " [3, 15, 1, 2, 3, 9, 5, 23, 3, 23],\n",
       " [15, 1, 2, 3, 9, 5, 23, 3, 23, 13],\n",
       " [1, 2, 3, 9, 5, 23, 3, 23, 13, 16],\n",
       " [2, 3, 9, 5, 23, 3, 23, 13, 16, 6],\n",
       " [3, 9, 5, 23, 3, 23, 13, 16, 6, 23],\n",
       " [9, 5, 23, 3, 23, 13, 16, 6, 23, 7],\n",
       " [5, 23, 3, 23, 13, 16, 6, 23, 7, 7],\n",
       " [23, 3, 23, 13, 16, 6, 23, 7, 7, 3],\n",
       " [3, 23, 13, 16, 6, 23, 7, 7, 3, 24],\n",
       " [23, 13, 16, 6, 23, 7, 7, 3, 24, 19],\n",
       " [13, 16, 6, 23, 7, 7, 3, 24, 19, 19],\n",
       " [16, 6, 23, 7, 7, 3, 24, 19, 19, 23],\n",
       " [6, 23, 7, 7, 3, 24, 19, 19, 23, 13],\n",
       " [23, 7, 7, 3, 24, 19, 19, 23, 13, 7],\n",
       " [7, 7, 3, 24, 19, 19, 23, 13, 7, 24],\n",
       " [7, 3, 24, 19, 19, 23, 13, 7, 24, 9],\n",
       " [3, 24, 19, 19, 23, 13, 7, 24, 9, 18],\n",
       " [24, 19, 19, 23, 13, 7, 24, 9, 18, 3],\n",
       " [19, 19, 23, 13, 7, 24, 9, 18, 3, 1],\n",
       " [19, 23, 13, 7, 24, 9, 18, 3, 1, 15],\n",
       " [23, 13, 7, 24, 9, 18, 3, 1, 15, 3],\n",
       " [13, 7, 24, 9, 18, 3, 1, 15, 3, 9],\n",
       " [7, 24, 9, 18, 3, 1, 15, 3, 9, 5],\n",
       " [24, 9, 18, 3, 1, 15, 3, 9, 5, 23],\n",
       " [9, 18, 3, 1, 15, 3, 9, 5, 23, 3],\n",
       " [18, 3, 1, 15, 3, 9, 5, 23, 3, 7],\n",
       " [3, 1, 15, 3, 9, 5, 23, 3, 7, 23],\n",
       " [1, 15, 3, 9, 5, 23, 3, 7, 23, 11]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = len(dataX)\n",
    "dataX # batch 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell():\n",
    "    cell = rnn.BasicLSTMCell(hidden_size, state_is_tuple=True)\n",
    "    return cell\n",
    "\n",
    "multi_cells = rnn.MultiRNNCell([lstm_cell() for _ in range(5)], state_is_tuple=True)\n",
    "\n",
    "initial_state = multi_cells.zero_state(batch_size, tf.float32)\n",
    "with tf.variable_scope('fourth'):\n",
    "    outputs, _states = tf.nn.dynamic_rnn(multi_cells, X_one_hot, initial_state = initial_state, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = tf.reshape(outputs, [batch_size, sequence_length, num_classes]) # outputs의 형태를 변형\n",
    "\n",
    "X_for_softmax = tf.reshape(outputs, [-1, hidden_size]) # outputs의 형태를 softmax의 input에 알맞은 형태로 변형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax layer 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "softmax_W = tf.get_variable('softmax_W', [hidden_size, num_classes]) # input dim = hidden_size, output dim = num_classes(동일하다.) \n",
    "softmax_b = tf.get_variable('softmax_b', [num_classes]) # bias의 dim은 output dim과 같아야 한다.\n",
    "outputs = tf.matmul(X_for_softmax, softmax_W) + softmax_b\n",
    "\n",
    "outputs = tf.reshape(outputs, [batch_size, sequence_length, num_classes]) # softmax layer의 ouptut을 다시 sequence_loss 계산 형태로 변형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight, Loss, Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.ones([batch_size, sequence_length])\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits = outputs, targets=Y, weights=weights)\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0            3.24438\n",
      "0 10            3.24438\n",
      "0 20            3.24438\n",
      "0 30            3.24438\n",
      "0 40            3.24438\n",
      "0 50            3.24438\n",
      "0 60            3.24438\n",
      "0 70            3.24438\n",
      "0 80            3.24438\n",
      "0 90            3.24438\n",
      "0 100            3.24438\n",
      "0 110            3.24438\n",
      "0 120            3.24438\n",
      "0 130            3.24438\n",
      "0 140            3.24438\n",
      "0 150            3.24438\n",
      "0 160            3.24438\n",
      "100 0    ou want 0.80807\n",
      "100 10 hw  luild  0.80807\n",
      "100 20 t ship, do 0.80807\n",
      "100 30 n't dnum u 0.80807\n",
      "100 40 t people t 0.80807\n",
      "100 50 h ethen to 0.80807\n",
      "100 60 nlolleht w 0.80807\n",
      "100 70 ood and do 0.80807\n",
      "100 80 n't dhsign 0.80807\n",
      "100 90 dthe  to k 0.80807\n",
      "100 100 s and woo' 0.80807\n",
      "100 110 s lut r th 0.80807\n",
      "100 120 e  teahh t 0.80807\n",
      "100 130 hem to bon 0.80807\n",
      "100 140 dtfor the  0.80807\n",
      "100 150 tod ess im 0.80807\n",
      "100 160  ensity of 0.80807\n",
      "200 0 g you want 0.264466\n",
      "200 10 haa build  0.264466\n",
      "200 20 tnship, do 0.264466\n",
      "200 30  't drum u 0.264466\n",
      "200 40   people t 0.264466\n",
      "200 50 h ether to 0.264466\n",
      "200 60  lollect w 0.264466\n",
      "200 70 ood and do 0.264466\n",
      "200 80  't dssign 0.264466\n",
      "200 90 dthem task 0.264466\n",
      "200 100 , and work 0.264466\n",
      "200 110 , but rath 0.264466\n",
      "200 120 em teach t 0.264466\n",
      "200 130 her to lon 0.264466\n",
      "200 140 d for the  0.264466\n",
      "200 150 tndless im 0.264466\n",
      "200 160  ensity of 0.264466\n",
      "300 0 p you want 0.235413\n",
      "300 10 hao build  0.235413\n",
      "300 20 tnship, do 0.235413\n",
      "300 30  't arum u 0.235413\n",
      "300 40 m people t 0.235413\n",
      "300 50 h ether to 0.235413\n",
      "300 60  lollect w 0.235413\n",
      "300 70 ord and do 0.235413\n",
      "300 80  't assign 0.235413\n",
      "300 90 dthem task 0.235413\n",
      "300 100 s and work 0.235413\n",
      "300 110 s but rath 0.235413\n",
      "300 120 em teach t 0.235413\n",
      "300 130 hem ta lon 0.235413\n",
      "300 140 d for the  0.235413\n",
      "300 150 tndless im 0.235413\n",
      "300 160  ensity of 0.235413\n",
      "400 0 f you want 0.231493\n",
      "400 10 hro build  0.231493\n",
      "400 20 tnship, do 0.231493\n",
      "400 30 n't drum u 0.231493\n",
      "400 40 t people t 0.231493\n",
      "400 50 h ether to 0.231493\n",
      "400 60 ncollect w 0.231493\n",
      "400 70 ood and do 0.231493\n",
      "400 80 n't dssign 0.231493\n",
      "400 90 dthem task 0.231493\n",
      "400 100 , and work 0.231493\n",
      "400 110 , but rath 0.231493\n",
      "400 120 em teach t 0.231493\n",
      "400 130 hem ta lon 0.231493\n",
      "400 140 d for the  0.231493\n",
      "400 150 tndless im 0.231493\n",
      "400 160  ensity of 0.231493\n",
      "500 0 g you want 0.230306\n",
      "500 10 hao build  0.230306\n",
      "500 20 tnship, do 0.230306\n",
      "500 30 n't arum u 0.230306\n",
      "500 40   people t 0.230306\n",
      "500 50 h ether to 0.230306\n",
      "500 60 nbollect w 0.230306\n",
      "500 70 ord and do 0.230306\n",
      "500 80 n't assign 0.230306\n",
      "500 90 dthem task 0.230306\n",
      "500 100 s and work 0.230306\n",
      "500 110 s but rath 0.230306\n",
      "500 120 er toach t 0.230306\n",
      "500 130 her ta lon 0.230306\n",
      "500 140 d for the  0.230306\n",
      "500 150 tndless im 0.230306\n",
      "500 160  ensity of 0.230306\n",
      "600 0 l you want 0.229731\n",
      "600 10  ro build  0.229731\n",
      "600 20 tnship, do 0.229731\n",
      "600 30 n't drum u 0.229731\n",
      "600 40 p people t 0.229731\n",
      "600 50   ether to 0.229731\n",
      "600 60 ncollect w 0.229731\n",
      "600 70 ood and do 0.229731\n",
      "600 80 n't dssign 0.229731\n",
      "600 90 dthem task 0.229731\n",
      "600 100 , and work 0.229731\n",
      "600 110 , but rath 0.229731\n",
      "600 120 er toach t 0.229731\n",
      "600 130  em to lon 0.229731\n",
      "600 140 d for the  0.229731\n",
      "600 150 tndless im 0.229731\n",
      "600 160  ensity of 0.229731\n",
      "700 0 f you want 0.229364\n",
      "700 10 hao build  0.229364\n",
      "700 20 tnship, do 0.229364\n",
      "700 30 n't arum u 0.229364\n",
      "700 40 t people t 0.229364\n",
      "700 50 h ether to 0.229364\n",
      "700 60 nlollect w 0.229364\n",
      "700 70 ord and do 0.229364\n",
      "700 80 n't assign 0.229364\n",
      "700 90 dthem task 0.229364\n",
      "700 100 , and work 0.229364\n",
      "700 110 , but rath 0.229364\n",
      "700 120 er toach t 0.229364\n",
      "700 130 her to lon 0.229364\n",
      "700 140 d for the  0.229364\n",
      "700 150 tndless im 0.229364\n",
      "700 160  ensity of 0.229364\n",
      "800 0 l you want 0.229185\n",
      "800 10  ro build  0.229185\n",
      "800 20 tnship, do 0.229185\n",
      "800 30 n't drum u 0.229185\n",
      "800 40 m people t 0.229185\n",
      "800 50   ether to 0.229185\n",
      "800 60 ncollect w 0.229185\n",
      "800 70 ood and do 0.229185\n",
      "800 80 n't dssign 0.229185\n",
      "800 90 dthem task 0.229185\n",
      "800 100 , and work 0.229185\n",
      "800 110 , but rath 0.229185\n",
      "800 120 em toach t 0.229185\n",
      "800 130  em to lon 0.229185\n",
      "800 140 d for the  0.229185\n",
      "800 150 tndless im 0.229185\n",
      "800 160  ensity of 0.229185\n",
      "900 0 t you want 0.22917\n",
      "900 10  ro build  0.22917\n",
      "900 20 tnship, do 0.22917\n",
      "900 30  't arum u 0.22917\n",
      "900 40 i people t 0.22917\n",
      "900 50   ether to 0.22917\n",
      "900 60  bollect w 0.22917\n",
      "900 70 ood and do 0.22917\n",
      "900 80  't assign 0.22917\n",
      "900 90 dthem task 0.22917\n",
      "900 100 s and work 0.22917\n",
      "900 110 s but rath 0.22917\n",
      "900 120 em teach t 0.22917\n",
      "900 130  em to lon 0.22917\n",
      "900 140 d for the  0.22917\n",
      "900 150 tndless im 0.22917\n",
      "900 160  ensity of 0.22917\n",
      "1000 0 t you want 0.228974\n",
      "1000 10  wo build  0.228974\n",
      "1000 20 tnship, do 0.228974\n",
      "1000 30 n't arum u 0.228974\n",
      "1000 40   people t 0.228974\n",
      "1000 50   ether to 0.228974\n",
      "1000 60 nlollect w 0.228974\n",
      "1000 70 ord and do 0.228974\n",
      "1000 80 n't assign 0.228974\n",
      "1000 90 dthem task 0.228974\n",
      "1000 100 s and work 0.228974\n",
      "1000 110 s but rath 0.228974\n",
      "1000 120 er toach t 0.228974\n",
      "1000 130  er ta lon 0.228974\n",
      "1000 140 d for the  0.228974\n",
      "1000 150 tndless im 0.228974\n",
      "1000 160  ensity of 0.228974\n",
      "1100 0 g you want 0.228917\n",
      "1100 10 hao build  0.228917\n",
      "1100 20 tnship, do 0.228917\n",
      "1100 30  't arum u 0.228917\n",
      "1100 40 i people t 0.228917\n",
      "1100 50 h ether to 0.228917\n",
      "1100 60  lollect w 0.228917\n",
      "1100 70 ood and do 0.228917\n",
      "1100 80  't assign 0.228917\n",
      "1100 90 dthem task 0.228917\n",
      "1100 100 , and work 0.228917\n",
      "1100 110 , but rath 0.228917\n",
      "1100 120 em toach t 0.228917\n",
      "1100 130 her to lon 0.228917\n",
      "1100 140 d for the  0.228917\n",
      "1100 150 tndless im 0.228917\n",
      "1100 160  ensity of 0.228917\n",
      "1200 0 g you want 0.229012\n",
      "1200 10 hro build  0.229012\n",
      "1200 20 tnship, do 0.229012\n",
      "1200 30  't drum u 0.229012\n",
      "1200 40 i people t 0.229012\n",
      "1200 50 h ether to 0.229012\n",
      "1200 60  bollect w 0.229012\n",
      "1200 70 ood and do 0.229012\n",
      "1200 80  't dssign 0.229012\n",
      "1200 90 dthem task 0.229012\n",
      "1200 100 , and work 0.229012\n",
      "1200 110 , but rath 0.229012\n",
      "1200 120 er toach t 0.229012\n",
      "1200 130 hem to lon 0.229012\n",
      "1200 140 d for the  0.229012\n",
      "1200 150 tndless im 0.229012\n",
      "1200 160  ensity of 0.229012\n",
      "1300 0 t you want 0.228773\n",
      "1300 10 hdo build  0.228773\n",
      "1300 20 tnship, do 0.228773\n",
      "1300 30  't drum u 0.228773\n",
      "1300 40 i people t 0.228773\n",
      "1300 50 h ether to 0.228773\n",
      "1300 60  collect w 0.228773\n",
      "1300 70 ord and do 0.228773\n",
      "1300 80  't dssign 0.228773\n",
      "1300 90 dthem task 0.228773\n",
      "1300 100 s and work 0.228773\n",
      "1300 110 s but rath 0.228773\n",
      "1300 120 em teach t 0.228773\n",
      "1300 130 her ta lon 0.228773\n",
      "1300 140 d for the  0.228773\n",
      "1300 150 tndless im 0.228773\n",
      "1300 160  ensity of 0.228773\n",
      "1400 0 t you want 0.228768\n",
      "1400 10 hao build  0.228768\n",
      "1400 20 tnship, do 0.228768\n",
      "1400 30  't arum u 0.228768\n",
      "1400 40 t people t 0.228768\n",
      "1400 50 h ether to 0.228768\n",
      "1400 60  collect w 0.228768\n",
      "1400 70 ord and do 0.228768\n",
      "1400 80  't assign 0.228768\n",
      "1400 90 dthem task 0.228768\n",
      "1400 100 s and work 0.228768\n",
      "1400 110 s but rath 0.228768\n",
      "1400 120 em teach t 0.228768\n",
      "1400 130 hem ta lon 0.228768\n",
      "1400 140 d for the  0.228768\n",
      "1400 150 tndless im 0.228768\n",
      "1400 160  ensity of 0.228768\n",
      "1500 0 f you want 0.22872\n",
      "1500 10 hwo build  0.22872\n",
      "1500 20 tnship, do 0.22872\n",
      "1500 30 n't arum u 0.22872\n",
      "1500 40   people t 0.22872\n",
      "1500 50 h ether to 0.22872\n",
      "1500 60 ncollect w 0.22872\n",
      "1500 70 ord and do 0.22872\n",
      "1500 80 n't assign 0.22872\n",
      "1500 90 dthem task 0.22872\n",
      "1500 100 , and work 0.22872\n",
      "1500 110 , but rath 0.22872\n",
      "1500 120 er teach t 0.22872\n",
      "1500 130 her ta lon 0.22872\n",
      "1500 140 d for the  0.22872\n",
      "1500 150 tndless im 0.22872\n",
      "1500 160  ensity of 0.22872\n",
      "1600 0 g you want 0.228769\n",
      "1600 10 hao build  0.228769\n",
      "1600 20 tnship, do 0.228769\n",
      "1600 30  't drum u 0.228769\n",
      "1600 40   people t 0.228769\n",
      "1600 50 h ether to 0.228769\n",
      "1600 60  bollect w 0.228769\n",
      "1600 70 ood and do 0.228769\n",
      "1600 80  't dssign 0.228769\n",
      "1600 90 dthem task 0.228769\n",
      "1600 100 s and work 0.228769\n",
      "1600 110 s but rath 0.228769\n",
      "1600 120 em teach t 0.228769\n",
      "1600 130 her ta lon 0.228769\n",
      "1600 140 d for the  0.228769\n",
      "1600 150 tndless im 0.228769\n",
      "1600 160  ensity of 0.228769\n",
      "1700 0 g you want 0.228685\n",
      "1700 10 hdo build  0.228685\n",
      "1700 20 tnship, do 0.228685\n",
      "1700 30 n't drum u 0.228685\n",
      "1700 40 m people t 0.228685\n",
      "1700 50 h ether to 0.228685\n",
      "1700 60 nlollect w 0.228685\n",
      "1700 70 ord and do 0.228685\n",
      "1700 80 n't dssign 0.228685\n",
      "1700 90 dthem task 0.228685\n",
      "1700 100 , and work 0.228685\n",
      "1700 110 , but rath 0.228685\n",
      "1700 120 em teach t 0.228685\n",
      "1700 130 hem to lon 0.228685\n",
      "1700 140 d for the  0.228685\n",
      "1700 150 tndless im 0.228685\n",
      "1700 160  ensity of 0.228685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 0 t you want 0.228659\n",
      "1800 10  ro build  0.228659\n",
      "1800 20 tnship, do 0.228659\n",
      "1800 30  't drum u 0.228659\n",
      "1800 40 i people t 0.228659\n",
      "1800 50   ether to 0.228659\n",
      "1800 60  collect w 0.228659\n",
      "1800 70 ord and do 0.228659\n",
      "1800 80  't dssign 0.228659\n",
      "1800 90 dthem task 0.228659\n",
      "1800 100 s and work 0.228659\n",
      "1800 110 s but rath 0.228659\n",
      "1800 120 er toach t 0.228659\n",
      "1800 130  er to lon 0.228659\n",
      "1800 140 d for the  0.228659\n",
      "1800 150 tndless im 0.228659\n",
      "1800 160  ensity of 0.228659\n",
      "1900 0 t you want 0.228652\n",
      "1900 10 hao build  0.228652\n",
      "1900 20 tnship, do 0.228652\n",
      "1900 30  't arum u 0.228652\n",
      "1900 40 t people t 0.228652\n",
      "1900 50 h ether to 0.228652\n",
      "1900 60  collect w 0.228652\n",
      "1900 70 ord and do 0.228652\n",
      "1900 80  't assign 0.228652\n",
      "1900 90 dthem task 0.228652\n",
      "1900 100 s and work 0.228652\n",
      "1900 110 s but rath 0.228652\n",
      "1900 120 er teach t 0.228652\n",
      "1900 130 her ta lon 0.228652\n",
      "1900 140 d for the  0.228652\n",
      "1900 150 tndless im 0.228652\n",
      "1900 160  ensity of 0.228652\n",
      "2000 0 g you want 0.22879\n",
      "2000 10 hto build  0.22879\n",
      "2000 20 tnship, do 0.22879\n",
      "2000 30  't drum u 0.22879\n",
      "2000 40 t people t 0.22879\n",
      "2000 50 h ether to 0.22879\n",
      "2000 60  lollect w 0.22879\n",
      "2000 70 ord and do 0.22879\n",
      "2000 80  't dssign 0.22879\n",
      "2000 90 dthem task 0.22879\n",
      "2000 100 , and work 0.22879\n",
      "2000 110 , but rath 0.22879\n",
      "2000 120 em toach t 0.22879\n",
      "2000 130 hem to lon 0.22879\n",
      "2000 140 d for the  0.22879\n",
      "2000 150 tndless im 0.22879\n",
      "2000 160  ensity of 0.22879\n",
      "2100 0 f you want 0.228644\n",
      "2100 10 hro build  0.228644\n",
      "2100 20 tnship, do 0.228644\n",
      "2100 30  't drum u 0.228644\n",
      "2100 40 i people t 0.228644\n",
      "2100 50 h ether to 0.228644\n",
      "2100 60  collect w 0.228644\n",
      "2100 70 ord and do 0.228644\n",
      "2100 80  't dssign 0.228644\n",
      "2100 90 dthem task 0.228644\n",
      "2100 100 , and work 0.228644\n",
      "2100 110 , but rath 0.228644\n",
      "2100 120 er toach t 0.228644\n",
      "2100 130 her to lon 0.228644\n",
      "2100 140 d for the  0.228644\n",
      "2100 150 tndless im 0.228644\n",
      "2100 160  ensity of 0.228644\n",
      "2200 0 g you want 0.228793\n",
      "2200 10  ro build  0.228793\n",
      "2200 20 tnship, do 0.228793\n",
      "2200 30 n't drum u 0.228793\n",
      "2200 40 i people t 0.228793\n",
      "2200 50   ether to 0.228793\n",
      "2200 60 ncollect w 0.228793\n",
      "2200 70 ord and do 0.228793\n",
      "2200 80 n't dssign 0.228793\n",
      "2200 90 dthem task 0.228793\n",
      "2200 100 , and work 0.228793\n",
      "2200 110 , but rath 0.228793\n",
      "2200 120 er toach t 0.228793\n",
      "2200 130  em to lon 0.228793\n",
      "2200 140 d for the  0.228793\n",
      "2200 150 tndless im 0.228793\n",
      "2200 160  ensity of 0.228793\n",
      "2300 0 m you want 0.228596\n",
      "2300 10 hao build  0.228596\n",
      "2300 20 tnship, do 0.228596\n",
      "2300 30  't arum u 0.228596\n",
      "2300 40 m people t 0.228596\n",
      "2300 50 h ether to 0.228596\n",
      "2300 60  lollect w 0.228596\n",
      "2300 70 ood and do 0.228596\n",
      "2300 80  't assign 0.228596\n",
      "2300 90 dthem task 0.228596\n",
      "2300 100 , and work 0.228596\n",
      "2300 110 , but rath 0.228596\n",
      "2300 120 em teach t 0.228596\n",
      "2300 130 hem to lon 0.228596\n",
      "2300 140 d for the  0.228596\n",
      "2300 150 tndless im 0.228596\n",
      "2300 160  ensity of 0.228596\n",
      "2400 0 l you want 0.229112\n",
      "2400 10  ao build  0.229112\n",
      "2400 20 tnship, do 0.229112\n",
      "2400 30 n't arum u 0.229112\n",
      "2400 40 t people t 0.229112\n",
      "2400 50   ether to 0.229112\n",
      "2400 60 nlollect w 0.229112\n",
      "2400 70 ood and do 0.229112\n",
      "2400 80 n't assign 0.229112\n",
      "2400 90 'them task 0.229112\n",
      "2400 100 s and work 0.229112\n",
      "2400 110 s but rath 0.229112\n",
      "2400 120 em teach t 0.229112\n",
      "2400 130  em ta lon 0.229112\n",
      "2400 140 ' for the  0.229112\n",
      "2400 150 tndless im 0.229112\n",
      "2400 160  ensity of 0.229112\n",
      "2500 0 t you want 0.228829\n",
      "2500 10  wo build  0.228829\n",
      "2500 20 tnship, do 0.228829\n",
      "2500 30 n't arum u 0.228829\n",
      "2500 40 i people t 0.228829\n",
      "2500 50   ether to 0.228829\n",
      "2500 60 ncollect w 0.228829\n",
      "2500 70 ord and do 0.228829\n",
      "2500 80 n't assign 0.228829\n",
      "2500 90 dthem task 0.228829\n",
      "2500 100 s and work 0.228829\n",
      "2500 110 s but rath 0.228829\n",
      "2500 120 er teach t 0.228829\n",
      "2500 130  er ta lon 0.228829\n",
      "2500 140 d for the  0.228829\n",
      "2500 150 tndless im 0.228829\n",
      "2500 160  ensity of 0.228829\n",
      "2600 0 p you want 0.228575\n",
      "2600 10 hdo build  0.228575\n",
      "2600 20 tnship, do 0.228575\n",
      "2600 30  't drum u 0.228575\n",
      "2600 40 p people t 0.228575\n",
      "2600 50 h ether to 0.228575\n",
      "2600 60  bollect w 0.228575\n",
      "2600 70 ood and do 0.228575\n",
      "2600 80  't dssign 0.228575\n",
      "2600 90 dthem task 0.228575\n",
      "2600 100 s and work 0.228575\n",
      "2600 110 s but rath 0.228575\n",
      "2600 120 em toach t 0.228575\n",
      "2600 130 hem to lon 0.228575\n",
      "2600 140 d for the  0.228575\n",
      "2600 150 tndless im 0.228575\n",
      "2600 160  ensity of 0.228575\n",
      "2700 0            2.9056\n",
      "2700 10            2.9056\n",
      "2700 20            2.9056\n",
      "2700 30            2.9056\n",
      "2700 40            2.9056\n",
      "2700 50            2.9056\n",
      "2700 60            2.9056\n",
      "2700 70            2.9056\n",
      "2700 80            2.9056\n",
      "2700 90            2.9056\n",
      "2700 100            2.9056\n",
      "2700 110            2.9056\n",
      "2700 120            2.9056\n",
      "2700 130            2.9056\n",
      "2700 140            2.9056\n",
      "2700 150            2.9056\n",
      "2700 160            2.9056\n",
      "2800 0            2.82572\n",
      "2800 10            2.82572\n",
      "2800 20            2.82572\n",
      "2800 30            2.82572\n",
      "2800 40            2.82572\n",
      "2800 50            2.82572\n",
      "2800 60            2.82572\n",
      "2800 70            2.82572\n",
      "2800 80            2.82572\n",
      "2800 90            2.82572\n",
      "2800 100 r          2.82572\n",
      "2800 110 r          2.82572\n",
      "2800 120            2.82572\n",
      "2800 130            2.82572\n",
      "2800 140            2.82572\n",
      "2800 150            2.82572\n",
      "2800 160            2.82572\n",
      "2900 0            2.80249\n",
      "2900 10 o          2.80249\n",
      "2900 20            2.80249\n",
      "2900 30            2.80249\n",
      "2900 40            2.80249\n",
      "2900 50 o          2.80249\n",
      "2900 60            2.80249\n",
      "2900 70 oo         2.80249\n",
      "2900 80            2.80249\n",
      "2900 90            2.80249\n",
      "2900 100            2.80249\n",
      "2900 110            2.80249\n",
      "2900 120            2.80249\n",
      "2900 130 o          2.80249\n",
      "2900 140            2.80249\n",
      "2900 150            2.80249\n",
      "2900 160            2.80249\n",
      "                                                                                                                                                                                   "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(3000):\n",
    "        l, _, results = sess.run([loss, train, outputs], feed_dict = {X : dataX, Y : dataY})\n",
    "        for j, result in enumerate(results):\n",
    "            index = np.argmax(result, axis=1)\n",
    "            if i%100 == 0:\n",
    "                if j%10 == 0:\n",
    "                    print(i, j, ''.join([char_set[t] for t in index]), l)\n",
    "                    \n",
    "    for j, result in enumerate(results):\n",
    "        index = np.argmax(result, axis=1)\n",
    "        if j is 0:\n",
    "            print(''.join([char_set[t] for t in index]), end='')\n",
    "        else:\n",
    "            print(char_set[index[-1]], end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2700번을 넘어서면서 다시 loss가 증가하는 문제가 발생했다. \n",
    "\n",
    "반복 횟수를 2000번으로 줄여보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 ssssssssss 3.243\n",
      "0 10 ssssssssss 3.243\n",
      "0 20 ssssssssss 3.243\n",
      "0 30 ssssssssss 3.243\n",
      "0 40 ssssssssss 3.243\n",
      "0 50 ssssssssss 3.243\n",
      "0 60 ssssssssss 3.243\n",
      "0 70 ssssssssss 3.243\n",
      "0 80 ssssssssss 3.243\n",
      "0 90 ssssssssss 3.243\n",
      "0 100 ssssssssss 3.243\n",
      "0 110 ssssssssss 3.243\n",
      "0 120 ssssssssss 3.243\n",
      "0 130 ssssssssss 3.243\n",
      "0 140 ssssssssss 3.243\n",
      "0 150 ssssssssss 3.243\n",
      "0 160 ssssssssss 3.243\n",
      "100 0          t 2.69238\n",
      "100 10   t     t  2.69238\n",
      "100 20         t  2.69238\n",
      "100 30          t 2.69238\n",
      "100 40          t 2.69238\n",
      "100 50       t t  2.69238\n",
      "100 60   t t  t   2.69238\n",
      "100 70     t t t  2.69238\n",
      "100 80            2.69238\n",
      "100 90   t t    t 2.69238\n",
      "100 100       t    2.69238\n",
      "100 110   t t      2.69238\n",
      "100 120          t 2.69238\n",
      "100 130   t        2.69238\n",
      "100 140     t t  t 2.69238\n",
      "100 150     t t    2.69238\n",
      "100 160            2.69238\n",
      "200 0 t ton aont 1.34123\n",
      "200 10 hth but t  1.34123\n",
      "200 20 tnmhebo to 1.34123\n",
      "200 30 nst asut u 1.34123\n",
      "200 40   asodla t 1.34123\n",
      "200 50 hekthet to 1.34123\n",
      "200 60 nto lect a 1.34123\n",
      "200 70  rd asd to 1.34123\n",
      "200 80 nst assigs 1.34123\n",
      "200 90 nthet toek 1.34123\n",
      "200 100 t and tonk 1.34123\n",
      "200 110 t but auth 1.34123\n",
      "200 120  t toech t 1.34123\n",
      "200 130 het toecon 1.34123\n",
      "200 140 n ton thet 1.34123\n",
      "200 150 tod ans ig 1.34123\n",
      "200 160  ateeto by 1.34123\n",
      "300 0 t tor went 0.67628\n",
      "300 10 hwo budlt  0.67628\n",
      "300 20 tnmhip, do 0.67628\n",
      "300 30 n't arut u 0.67628\n",
      "300 40 i uoople t 0.67628\n",
      "300 50 h ethem to 0.67628\n",
      "300 60 nco lect w 0.67628\n",
      "300 70 hrd and to 0.67628\n",
      "300 80 n't assign 0.67628\n",
      "300 90 dthem tosk 0.67628\n",
      "300 100 t bnd tork 0.67628\n",
      "300 110 t but rath 0.67628\n",
      "300 120 em teach t 0.67628\n",
      "300 130 hem to lon 0.67628\n",
      "300 140 d tor them 0.67628\n",
      "300 150 topless im 0.67628\n",
      "300 160  mdsito o, 0.67628\n",
      "400 0 l pou want 0.366762\n",
      "400 10 owo build  0.366762\n",
      "400 20 tnship, do 0.366762\n",
      "400 30 r't drum u 0.366762\n",
      "400 40 p people t 0.366762\n",
      "400 50 o ether to 0.366762\n",
      "400 60 rcollect w 0.366762\n",
      "400 70 ood and ,o 0.366762\n",
      "400 80 r't dssign 0.366762\n",
      "400 90 dthem task 0.366762\n",
      "400 100 d and ,ork 0.366762\n",
      "400 110 d but rath 0.366762\n",
      "400 120 em toach t 0.366762\n",
      "400 130 oer to lon 0.366762\n",
      "400 140 d ,or the  0.366762\n",
      "400 150 todless im 0.366762\n",
      "400 160  ensity of 0.366762\n",
      "500 0 f you want 0.295209\n",
      "500 10  to build  0.295209\n",
      "500 20 tnship, do 0.295209\n",
      "500 30  't drum u 0.295209\n",
      "500 40 m people t 0.295209\n",
      "500 50   ether to 0.295209\n",
      "500 60  collect w 0.295209\n",
      "500 70 ord and wo 0.295209\n",
      "500 80  't dssign 0.295209\n",
      "500 90 dthem task 0.295209\n",
      "500 100 , and work 0.295209\n",
      "500 110 , but rath 0.295209\n",
      "500 120 em toach t 0.295209\n",
      "500 130  em to lon 0.295209\n",
      "500 140 d for the  0.295209\n",
      "500 150 todless im 0.295209\n",
      "500 160  ensity of 0.295209\n",
      "600 0 g tou want 0.439467\n",
      "600 10  wo build  0.439467\n",
      "600 20 tnship, do 0.439467\n",
      "600 30 n't arum u 0.439467\n",
      "600 40 i ueople t 0.439467\n",
      "600 50   ether te 0.439467\n",
      "600 60 ncollect w 0.439467\n",
      "600 70 rod and do 0.439467\n",
      "600 80 n't assign 0.439467\n",
      "600 90 dthem task 0.439467\n",
      "600 100 , bnd dork 0.439467\n",
      "600 110 , but rath 0.439467\n",
      "600 120 er teach t 0.439467\n",
      "600 130  e  ta lon 0.439467\n",
      "600 140 d dor dhem 0.439467\n",
      "600 150 todless im 0.439467\n",
      "600 160  ensity o, 0.439467\n",
      "700 0 p tou want 0.313092\n",
      "700 10 hao build  0.313092\n",
      "700 20 tnship, do 0.313092\n",
      "700 30  't drum u 0.313092\n",
      "700 40 p uaople t 0.313092\n",
      "700 50 h ether to 0.313092\n",
      "700 60  collect w 0.313092\n",
      "700 70 ood and do 0.313092\n",
      "700 80  't dssign 0.313092\n",
      "700 90 dthem task 0.313092\n",
      "700 100 , and dork 0.313092\n",
      "700 110 , but rath 0.313092\n",
      "700 120 er teach t 0.313092\n",
      "700 130 her to lon 0.313092\n",
      "700 140 d dor them 0.313092\n",
      "700 150 todless im 0.313092\n",
      "700 160  ensity of 0.313092\n",
      "800 0 g aou want 0.292098\n",
      "800 10  ao build  0.292098\n",
      "800 20 tnship, do 0.292098\n",
      "800 30  't drum u 0.292098\n",
      "800 40 m people t 0.292098\n",
      "800 50   ether to 0.292098\n",
      "800 60  collect w 0.292098\n",
      "800 70 ood and do 0.292098\n",
      "800 80  't dssign 0.292098\n",
      "800 90 dthem task 0.292098\n",
      "800 100 , and dork 0.292098\n",
      "800 110 , but rath 0.292098\n",
      "800 120 em toach t 0.292098\n",
      "800 130  em ta lon 0.292098\n",
      "800 140 d for the  0.292098\n",
      "800 150 todless im 0.292098\n",
      "800 160  ensity of 0.292098\n",
      "900 0 g aou want 0.276342\n",
      "900 10  ao build  0.276342\n",
      "900 20 tnship, do 0.276342\n",
      "900 30 n't drum u 0.276342\n",
      "900 40 t people t 0.276342\n",
      "900 50   ether to 0.276342\n",
      "900 60 ncollect w 0.276342\n",
      "900 70 ood and do 0.276342\n",
      "900 80 n't dssign 0.276342\n",
      "900 90 dthem task 0.276342\n",
      "900 100 , and dork 0.276342\n",
      "900 110 , but rath 0.276342\n",
      "900 120 em toach t 0.276342\n",
      "900 130  er to lon 0.276342\n",
      "900 140 d for the  0.276342\n",
      "900 150 tndless im 0.276342\n",
      "900 160  ensity of 0.276342\n",
      "1000 0 f aou want 0.259096\n",
      "1000 10  ao build  0.259096\n",
      "1000 20 tnship, do 0.259096\n",
      "1000 30 n't drum u 0.259096\n",
      "1000 40 i people t 0.259096\n",
      "1000 50   ether to 0.259096\n",
      "1000 60 ncollect w 0.259096\n",
      "1000 70 ood and do 0.259096\n",
      "1000 80 n't dssign 0.259096\n",
      "1000 90 dthem task 0.259096\n",
      "1000 100 , and work 0.259096\n",
      "1000 110 , but rath 0.259096\n",
      "1000 120 em toach t 0.259096\n",
      "1000 130  er ta lon 0.259096\n",
      "1000 140 d for the  0.259096\n",
      "1000 150 tndless im 0.259096\n",
      "1000 160  ensity of 0.259096\n",
      "1100 0 m you want 0.245761\n",
      "1100 10  wo build  0.245761\n",
      "1100 20 tnship, do 0.245761\n",
      "1100 30 n't drum u 0.245761\n",
      "1100 40 m people t 0.245761\n",
      "1100 50   ether to 0.245761\n",
      "1100 60 ncollect w 0.245761\n",
      "1100 70 ood and do 0.245761\n",
      "1100 80 n't dssign 0.245761\n",
      "1100 90 dthem task 0.245761\n",
      "1100 100 , and work 0.245761\n",
      "1100 110 , but rath 0.245761\n",
      "1100 120 er toach t 0.245761\n",
      "1100 130  er ta lon 0.245761\n",
      "1100 140 d for the  0.245761\n",
      "1100 150 tndless im 0.245761\n",
      "1100 160  ensity of 0.245761\n",
      "1200 0 g aon want 0.387256\n",
      "1200 10 hao build  0.387256\n",
      "1200 20 tnship, do 0.387256\n",
      "1200 30 n't arum u 0.387256\n",
      "1200 40 i ueople t 0.387256\n",
      "1200 50 h ether te 0.387256\n",
      "1200 60 ncollect w 0.387256\n",
      "1200 70 ord dnd do 0.387256\n",
      "1200 80 n't assign 0.387256\n",
      "1200 90 'them tosk 0.387256\n",
      "1200 100 e and dork 0.387256\n",
      "1200 110 e but rath 0.387256\n",
      "1200 120 em toach t 0.387256\n",
      "1200 130 hem ta lon 0.387256\n",
      "1200 140 ' dor them 0.387256\n",
      "1200 150 todless im 0.387256\n",
      "1200 160  ensity of 0.387256\n",
      "1300 0 m you want 0.301417\n",
      "1300 10  wo build  0.301417\n",
      "1300 20 tnship, do 0.301417\n",
      "1300 30 n't arum u 0.301417\n",
      "1300 40 m people t 0.301417\n",
      "1300 50   ether to 0.301417\n",
      "1300 60 ncollect w 0.301417\n",
      "1300 70 ord and do 0.301417\n",
      "1300 80 n't assign 0.301417\n",
      "1300 90 dthem task 0.301417\n",
      "1300 100 , and fork 0.301417\n",
      "1300 110 , but rath 0.301417\n",
      "1300 120 em toach t 0.301417\n",
      "1300 130  em ta lon 0.301417\n",
      "1300 140 d for them 0.301417\n",
      "1300 150 todless im 0.301417\n",
      "1300 160  ensity of 0.301417\n",
      "1400 0 g you want 0.275191\n",
      "1400 10 hao build  0.275191\n",
      "1400 20 tnship, do 0.275191\n",
      "1400 30  't drum u 0.275191\n",
      "1400 40 i people t 0.275191\n",
      "1400 50 h ether to 0.275191\n",
      "1400 60  collect w 0.275191\n",
      "1400 70 ord and do 0.275191\n",
      "1400 80  't dssign 0.275191\n",
      "1400 90 dthem task 0.275191\n",
      "1400 100 , and work 0.275191\n",
      "1400 110 , but rath 0.275191\n",
      "1400 120 er teach t 0.275191\n",
      "1400 130 her to lon 0.275191\n",
      "1400 140 d for them 0.275191\n",
      "1400 150 todless im 0.275191\n",
      "1400 160  ensity of 0.275191\n",
      "1500 0 t you want 0.296073\n",
      "1500 10 hdo build  0.296073\n",
      "1500 20 tnship, do 0.296073\n",
      "1500 30  't arum u 0.296073\n",
      "1500 40 p people t 0.296073\n",
      "1500 50 h ether to 0.296073\n",
      "1500 60  bollect w 0.296073\n",
      "1500 70 ord and do 0.296073\n",
      "1500 80  't assign 0.296073\n",
      "1500 90 dthem task 0.296073\n",
      "1500 100 , and fork 0.296073\n",
      "1500 110 , but rath 0.296073\n",
      "1500 120 em toach t 0.296073\n",
      "1500 130 her ta lon 0.296073\n",
      "1500 140 d for the  0.296073\n",
      "1500 150 todless im 0.296073\n",
      "1500 160  ensity of 0.296073\n",
      "1600 0 p you want 0.275282\n",
      "1600 10  ao build  0.275282\n",
      "1600 20 tnship, do 0.275282\n",
      "1600 30  't arum u 0.275282\n",
      "1600 40 m people t 0.275282\n",
      "1600 50   ether to 0.275282\n",
      "1600 60  collect w 0.275282\n",
      "1600 70 ord and do 0.275282\n",
      "1600 80  't assign 0.275282\n",
      "1600 90 dthe  task 0.275282\n",
      "1600 100 , and work 0.275282\n",
      "1600 110 , but rath 0.275282\n",
      "1600 120 er teach t 0.275282\n",
      "1600 130  er to lon 0.275282\n",
      "1600 140 d for the  0.275282\n",
      "1600 150 todless im 0.275282\n",
      "1600 160  ensity of 0.275282\n",
      "1700 0 m you want 0.25495\n",
      "1700 10  ao build  0.25495\n",
      "1700 20 tnship, do 0.25495\n",
      "1700 30 n't drum u 0.25495\n",
      "1700 40 t people t 0.25495\n",
      "1700 50   ether to 0.25495\n",
      "1700 60 ncollect w 0.25495\n",
      "1700 70 ood and do 0.25495\n",
      "1700 80 n't dssign 0.25495\n",
      "1700 90 dthe  task 0.25495\n",
      "1700 100 , and work 0.25495\n",
      "1700 110 , but rath 0.25495\n",
      "1700 120 er toach t 0.25495\n",
      "1700 130  er ta lon 0.25495\n",
      "1700 140 d for the  0.25495\n",
      "1700 150 todless im 0.25495\n",
      "1700 160  ensity of 0.25495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 0 g you want 0.25162\n",
      "1800 10 hwo build  0.25162\n",
      "1800 20 tnship, do 0.25162\n",
      "1800 30 n't drum u 0.25162\n",
      "1800 40 m people t 0.25162\n",
      "1800 50 h ether to 0.25162\n",
      "1800 60 ncollect w 0.25162\n",
      "1800 70 ood and do 0.25162\n",
      "1800 80 n't dssign 0.25162\n",
      "1800 90 dthem task 0.25162\n",
      "1800 100 , and work 0.25162\n",
      "1800 110 , but rath 0.25162\n",
      "1800 120 em toach t 0.25162\n",
      "1800 130 hem ta lon 0.25162\n",
      "1800 140 d for the  0.25162\n",
      "1800 150 todless im 0.25162\n",
      "1800 160  ensity of 0.25162\n",
      "1900 0 f you want 0.244033\n",
      "1900 10  wo build  0.244033\n",
      "1900 20 tnship, do 0.244033\n",
      "1900 30 n't drum u 0.244033\n",
      "1900 40 m people t 0.244033\n",
      "1900 50   ether to 0.244033\n",
      "1900 60 ncollect w 0.244033\n",
      "1900 70 ord and do 0.244033\n",
      "1900 80 n't dssign 0.244033\n",
      "1900 90 dthem task 0.244033\n",
      "1900 100 , and work 0.244033\n",
      "1900 110 , but rath 0.244033\n",
      "1900 120 em toach t 0.244033\n",
      "1900 130  em ta lon 0.244033\n",
      "1900 140 d for the  0.244033\n",
      "1900 150 todless im 0.244033\n",
      "1900 160  ensity of 0.244033\n",
      "f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea."
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(2000):\n",
    "        l, _, results = sess.run([loss, train, outputs], feed_dict = {X : dataX, Y : dataY})\n",
    "        for j, result in enumerate(results):\n",
    "            index = np.argmax(result, axis=1)\n",
    "            if i%100 == 0:\n",
    "                if j%10 == 0:\n",
    "                    print(i, j, ''.join([char_set[t] for t in index]), l)\n",
    "                    \n",
    "    for j, result in enumerate(results):\n",
    "        index = np.argmax(result, axis=1)\n",
    "        if j is 0:\n",
    "            print(''.join([char_set[t] for t in index]), end='')\n",
    "        else:\n",
    "            print(char_set[index[-1]], end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훌륭한 결과가 나왔다!\n",
    "\n",
    "하지만 계속 loss가 늘었다 줄었다 하는 문제는 어떻게 해결해야 할 것인가? \n",
    "\n",
    "**parameter 조정**이 답으로 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
