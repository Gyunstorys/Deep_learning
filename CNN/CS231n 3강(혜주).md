##  CS231n 3강(혜주)
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

다음은 스탠포드 대학 강의  [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/) 을 요약한 것입니다.

3강의 내용을 도식화해서 정리하면 다음과 같습니다. 

![default](https://user-images.githubusercontent.com/32008883/31015722-8d7ffcce-a55c-11e7-8607-14e75e1d3fe4.JPG)

## 1. Loss function

저번 시간에 배웠던 W가 기억하시나요? 처음에 W는 랜덤으로 정해지기 때문에,  Loss를 최소화해야 하는 W를 찾아야 합니다. 

그런데, Loss가 무엇일까요?

Loss는 모델에 의한 예측 이미지 라벨과, 실제 이미지의 라벨이 일치하지 않는 정도를 말합니다. 

전체 데이터 셋의 Loss는 다음과 같이 표현할 수 있습니다.

$L\quad =\frac { 1 }{ N } \sum _{ i }{ { L }_{ i }(f({ x }_{ i },W),{ y }_{ i }) } \quad$


$f({ x }_{ i },W)$는 모델에 의한 예측 이미지 라벨이며, ${ y }_{ i }$는 실제 이미지의 라벨입니다. Loss를 모두 합쳐 데이터의 개수로 나누면 전체 데이터 셋의 Loss를 구할 수 있습니다.



Loss 를 정량적으로 측정하는 방법에는 크게 두 가지가 있습니다.

### 1) SVM Loss

- **SVM Loss에 대한 이해**

$s\quad =\quad f({ x }_{ i },W)$

라고 표현하고, safety margin을 1이라고 합니다. 

예를 들어 고양이 이미지 데이터가 input값이라면 , 

${ s }_{ { y }_{ i } }$는 '고양이' 라벨에 대한 점수입니다.

${ s }_{ j }$는 '강아지','개구리'등 다른 잘못된 라벨에 대한 점수라고 할 수 있겠습니다. 그러므로 ${ s }_{ { y }_{ i } }$가 ${ s }_{ j }$보다 충분히 커야 잘 분류했다고 볼 수 있겠죠? 그런데 근사한 차이로 분류를 해버린다면 틀릴 경우가 생길 수도 있습니다.  safety margin이라는 것을 이용해서 더 큰 차이로 (안전빵)  분류를 해냈을 때 성공으로 정의합니다. 즉, Loss 가 0인 경우입니다. 잘못 분류한 경우는 Loss를   ${ s }_{ j } + 1$ 에서 ${ s }_{ { y }_{ i } }$를 뺀 값으로 정의 합니다. 이를 수식으로 정의하면 다음과 같습니다.

참고: safety margin은 반드시 1이 아니어도 된다. 어차피 상대적인 차이를 표시하는 것이기 때문에 상관없다.

![cs231n_week3_2](https://user-images.githubusercontent.com/32008883/31006647-76e12822-a538-11e7-85c2-5e9e6fd81b32.JPG)

![cs231n_week3_3](https://user-images.githubusercontent.com/32008883/31006711-cd3651de-a538-11e7-8f8a-02d7a85a3de0.JPG)

예를 들어, 고양이 이미지 데이터를 입력한 경우  ${ s }_{ { y }_{ i } }$는 3.2이다. car이미지 라벨로 분류했을 때의 점수(${ s }_{ j }$)는 5.1입니다. 고양이 이미지를 입력했을 때 car 라벨을 준 경우의 Loss는 $ max(0, 5.1 - 3.2 + 1) $ 입니다. frog 이미지 라벨로 분류했을 때의 점수(${ s }_{ j }$)는 -1.7입니다. 고양이 이미지를 입력했을 때 frog 라벨을 준 경우의 Loss는 $ max(0, -1.7  -3.2 + 1) $ 입니다. Loss를 합하면 2.9가 됩니다.

Loss의 총합을 구하려면 

![cs231n_week3_4_temp](https://user-images.githubusercontent.com/32008883/31006901-a7280bb2-a539-11e7-85f8-3f9216b9e045.JPG)

하단의 loss를 모두 더하면 됩니다.



- **Q & A를 통한 SVM Loss 이해하기**

Q1. Loss의 최솟값, 최댓값은 무엇인가?

A1. 최솟값은 0이며, 상단의 그래프에서 알 수 있듯이 최댓값은 Infinity이다.



Q2. 만약 상단에서 CAR 점수가 조금 올라간다면 Loss에 차이가 있는가?

A2. 어차피 CAR 점수가 가장 높기 때문에 Loss에는 차이가 없다.



Q3. Loss function을 조금 수정하여 다음과 같이 제곱을 하면 달라질까?

${ L }_{ i }=\sum _{ j \neq { y }_{ i } }{ max } { (0,{ s }_{ j }-{ s }_{ { y }_{ i } }+1) }^{ 2 }$

A3. 제곱을 하면 다르다. 제곱을 한다는 것은 그만큼 Loss에 의한 데미지 정도를 크게 취급한다는 것이다. 조금 나쁜 것과 많이 나쁜 것의 차이를 크게 하여 Loss의 중요도를 조절한다고도 볼 수 있다.



- **Loss function Example Code**

${ L }_{ i }=\sum _{ j \neq { y }_{ i } }{ max(0,{ s }_{ j }-{ s }_{ { y }_{ i } }+1) } $

```python
def L_i_vectorized(x, y, W):

	scores = W.dot(x) #내적

	margins =np.maximum(0, scores - scores[y] + 1)

	margins[y] = 0

	loss_i = np.sum(margins)

	return loss_i

```



- **Regularization : 모델 복잡도에 대한 패널티**

![cs231n_week3_12](https://user-images.githubusercontent.com/32008883/31008344-c463e8e0-a53e-11e7-96e3-d4116bb47aaa.JPG)

Loss Function은 loss를 최소화하려고 하면 Training data에 과적합(Overfitting)될 수 있습니다. 따라서 'Regularization'항을 넣어서, 모델 복잡도에 대한 패널티를 부여합니다다. 람다가 클 수록 모델 복잡도에 대한 중요도를 크게 봅니다.



### 2) Softmax Classifier

Softmax Classifier는 Loss를 다음과 같이 정의합니다.

log안에 있는 부분은 제대로 이미지를 분류할 확률이라고 보아도 됩니다. 이미지의 라벨을 올바르게 분류했을 경우 log에 들어가있는 부분은 1에 가까워집니다. 그러면 loss는 0이 나옵니다. 하지만 log에 들어가있는 부분이 0에 가까워지면 loss는 infinity를 보입니다.

![cs231n_week3_14](https://user-images.githubusercontent.com/32008883/31008842-71ae8874-a540-11e7-922d-c6e1ec142e55.JPG)



- **Recap**

여태까지 배운 loss function을 정리하면 다음과 같습니다.

![cs231n_week3_18](https://user-images.githubusercontent.com/32008883/31008992-f40ad50c-a540-11e7-8923-af7279cfc4d3.JPG)





## 2. Optimization

아까 언급했듯이 loss를 최소화해야 하는데, 어떻게 해야할까요? loss를 최소화하는 과정을  optimization이라고 합니다.

이해를 쉽게 하기 위해서, 여러분이 산 골짜기에서 내려가야 하는 상황이라고 해봅시다!



![cs231n_week3_19](https://user-images.githubusercontent.com/32008883/31009234-bf383d82-a541-11e7-8326-5cbeaeb36c54.JPG)

### 1) 첫번째 방법: 아무 길이나 무작정 내려간다.

당연히 결과가 안 좋겠죠? 길을 잃어버릴 거에요. loss도 커집니다.



### 2) 두번째 방법: 경사가 높은 쪽으로 내려가기!

지도에서 등고선 기억하시나요? 경사가 높은 쪽으로 내려가면 빨리 낮은 곳에 도착할 수 있습니다.

경사도는 미분을 하면 알 수 있는데요,

W를 미분한다면 다음과 같이 

![cs231n_week3_22](https://user-images.githubusercontent.com/32008883/31014708-4e984b6a-a557-11e7-8b84-9c581f385219.JPG)

계산할 수 있지만, 직접 계산할 필요가 없어요!



- **Gradient Descent**

컴퓨터가 Gradient Descent 알고리즘을 통해 경사도를 구해줍니다

```python
#Vanila Gradient Descent

while True:
	weights_grad = evaluate_gradient(loss_fun, data,weights)
	weights += -step_size * weights_grad
 #step_size = learning_rate
	
```



모든 데이터의 loss를 구하기 어려울 때는 일부분만 쓰는 

Stochastic Gradient Descent(SGD) 방법이 있다고 하니 참고하면 되겠습니다.  32 / 64/ 128개의 샘플(minibatch)을 주로 사용합니다. 

```python
#Vanila Minibatch Gradient Descent

while True:
  	data_batch = sample_training_data(data, 256)
	weights_grad = evaluate_gradient(loss_fun, data,weights)
	weights += -step_size * weights_grad
	
```



## 3. Image Features vs ConvNets

![cs231n_week3_32](https://user-images.githubusercontent.com/32008883/31015144-93a2dc82-a559-11e7-8751-04a2d8ed10aa.JPG)

뒤에서 더 자세히 배우겠지만 이미지를 학습시키는 것에는 두가지 방법이 있다고 볼 수 있습니다. 

Feature Extraction은 이미지에서 주요한 특징을 잡는 방법입니다.  이미지의 컬러, 가장자리 특성 등을 이용하거나, 이미지를 조각내서 특징을 파악하는 방법이 있습니다. 하지만 이 방법은 이미 특징이 결정되었기 때문에 유연하지 않습니다. 바꿀 수 있는 것은 linear classifier뿐입니다. 반면에, 앞으로 배울 ConvNets는 데이터로부터 직접 특징을 배우기 때문에 장점이 많습니다.(그 장점들은 다음 강의에 나올 것이라 생각합니다!)
