## CS231n 5강(혜주)

다음은 스탠포드 대학 강의  [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/) 을 요약한 것입니다.



5강의 내용을 도식화해서 정리하면 다음과 같습니다. 

![summary](https://user-images.githubusercontent.com/32008883/32101094-bfb00fa8-bb51-11e7-8c4f-dcf6f9e8c834.png)



### 0. Convolutional Neural Network(CNN)를 전체적으로 살펴보면

![cs231n_5_7](https://user-images.githubusercontent.com/32008883/32101164-fd84b09a-bb51-11e7-9438-8687194c9617.JPG)



convolutional layer에 들어가기전, 저번시간에 배웠던 기본적인 neural network의 구조 기억나시나요?

<img src="https://user-images.githubusercontent.com/32008883/32101217-443fdba4-bb52-11e7-8b11-a1cd0c75623f.JPG" width="50%">





### 1. Convolutional Layer

CNN의 가장 첫번째 단계인 convolutional layer를 살펴봅시다.

<img src="https://user-images.githubusercontent.com/32008883/32101219-446d1da8-bb52-11e7-921f-46e36c468f08.JPG" width="50%">



32x32x3 이미지에서, 5x5x3 filter 만큼의 이미지를 가져오는 것이 convolution layer의 역할입니다.

<img src="https://user-images.githubusercontent.com/32008883/32101221-449c875a-bb52-11e7-89df-678048101a50.JPG" width="50%">



filter는 이미지를 돌아다니며 이미지의 정보를 수집하여 activation map 으로 보여줍니다. 이 필터들을 여러개 사용하면 각자 다른 activation map을 갖게 됩니다. 

<img src="https://user-images.githubusercontent.com/32008883/32101215-43a916ec-bb52-11e7-922c-fcdac8885ca2.JPG" width="50%">





앞에서 배웠던 ConvNet은 이 convolutional layer들과 activation function을 합친 형태입니다.(ReLU는 뒤에서 배울 예정!)

<img src="https://user-images.githubusercontent.com/32008883/32101216-441240c2-bb52-11e7-8a57-e475055d1c46.JPG" width="50%">







* Filter에 대해서.

  - stride 란?

  아래와 같이 7x7 input에서 3x3filter를 적용하고 싶다면, 위 아래로 이동하겠죠? 그 이동하는 stepsize가 stride입니다. stride가 1이라면 오른쪽으로 5번 이동하고, 아래로 5번 이동할 수 있으므로 output size는 5x5가 나옵니다.  stride가 2라면 오른쪽으로 3번 이동하고, 아래로 3번 이동할 수 있으므로 output size는 3x3가 나옵니다. 하지만 만약 stride가 3이면, 오른쪽으로 두번 이동하려고 할 때 잘리는 것을 알 수 있습니다. 

  ​

  <img src="https://user-images.githubusercontent.com/32008883/32101885-f7533b4e-bb54-11e7-91cc-7d6df0c4711f.jpg" width="25%">

  ​

  이를 수식으로 정리하면 

  output size : **(N-F) / stride + 1 ** 

<img src="https://user-images.githubusercontent.com/32008883/32102027-a216c122-bb55-11e7-941e-9c64924f69af.jpg" width="25%">



- - zeropad

  그런데, image를 따라서 filter가 이동을 하면, output size는 이미지의 크기보다 작게 만들어지게 됩니다. 그래서 그 해결책으로 zeropad를 활용합니다. zeropad는 원래 이미지의 테두리에 0을 까는 것인데, 그렇게 하면 input size = output size가 되는 장점이 있습니다. 

  주의할 점은, zeropad의 테두리는 filter size(F x F) 에 따라 그 굵기가 달라집니다. **(F-1)/2** 로 제로패드를 만드는데, 예를 들어 filter가 5x5면 2줄로 0을 깔아야 제 기능을 할 수 있습니다.

<img src="https://user-images.githubusercontent.com/32008883/32102520-ac4816ee-bb57-11e7-8e37-547157a01d96.jpg" width="25%">



​      장점 : 이렇게 하면 filter로 인해 급격히 사이즈가 줄어들어 정보의 손실이 일어나는 것을 막을 수 있습니다!



- **QUIZ**

  <img src="https://user-images.githubusercontent.com/32008883/32102631-28779e74-bb58-11e7-91a3-d7c039322ecd.jpg" width="50%">

  ​



**1 . 위와 같이 input size가 주어졌을 경우 output volume size는? ** 

(activation map 의 size)

zero pad를 2개씩 깔았으므로 output size는 아까 언급했던 **(N-F) / stride + 1 ** 공식을 사용하지 않아도 사이즈가 **32x32**임을 알 수 있습니다. filter가 10개 이므로 **최종 output size는 32x32x10**



**2. 이 layer에 있는 모수(parameter)의 갯수는?**

filter하나에서 5x5x3 + 1(bias) = 76 개의 모수가 나오므로,  총 10개의 filter에서 **76x10 = 760 개의 모수 ** 나옴 





- **Convolution layer parameter에 대한 설정 tip**

  filter 개수 = 2의 n승(ex. 32,64,128,512)

  - filter 가로(세로) 길이 = 3, stride = 1, zero pad 테두리 굵기 = 1

  - filter 가로(세로) 길이 = 5, stride = 1, zero pad 테두리 굵기 = 2

  - filter 가로(세로) 길이 = 5, stride = 2, zero pad 테두리 굵기 = ?(맞는 것 아무거나)

  - filter 가로(세로) 길이 = 1, stride = 1, zero pad 테두리 굵기 = 0

    ​

<참고>

<img src="https://user-images.githubusercontent.com/32008883/32101740-69f084b4-bb54-11e7-9d6c-b42f342c6915.JPG" width="50%">







## 2. Pooling Layer

convolutation layer 와 relu function을 거친 뒤, 처리와 관리를 쉽게 하도록 만들어주는 것이 pooling layer입니다. downsampling이라고도 볼 수 있습니다.

<img src="https://user-images.githubusercontent.com/32008883/32103457-6e27a09c-bb5b-11e7-85d1-28abf3a5c056.jpg" width="50%">





- **Max pooling 방법 **

  가지고 있는 output에서 최대치만을 가져와서 pooling합니다. 

  Q: Average pooling을 쓸 수도 있는거 아닌가요? 

  output은 해당 feature이 어떤 위미체어 얼마나 활성화 되어 있는 것인지 보여주는 것이기 때문에 maxpooling을 주로 사용합니다. 

  <img src="https://user-images.githubusercontent.com/32008883/32103041-cb964898-bb59-11e7-9c4a-17040ab22921.JPG" width="50%">





- **pooling layer parameter 에 대한 설정 tip**
  - filter 가로(세로) 길이= 2, stride = 2

  - filter 가로(세로) 길이= 3, stride = 2

    ​


<참고>

<img src="https://user-images.githubusercontent.com/32008883/32103042-cbe24806-bb59-11e7-9446-d59b3e9d80ed.JPG" width="50%">







## 3. Fully Connected Layer(FC layer)

마지막에는, fully connected layer가 여태까지 모은 정보들을 다 합해서 score로 보여줍니다. 

<img src="https://user-images.githubusercontent.com/32008883/32101217-443fdba4-bb52-11e7-8b11-a1cd0c75623f.JPG" width="50%">









## 3줄 정리

1. ConvNet은 Convolutional layer, Pooling layer, Fully Connected layer로 이루어져 있다.
2. Convolutional layer에서는 filter가 정보를 모아 activation map 을 만든다. 
3. Pooling layer는 중간중간 정보를 다루기 쉽도록 압축해주고, FC layer는 최종정리하여 결과 산출 담당.









**참고 사이트 ** 

http://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html

activation map의 정체를 어렴풋이나마 알 수 있으니 궁금하면 ㄱㄱ